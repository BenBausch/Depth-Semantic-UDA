experiment_name: 'cityscapes_depth_semantic_test'

model:
    type: 'guda'

    encoder:
        params:
            nof_layers: 101
            weights_init: 'pretrained'

    pose_net:
        input: 'pairs' # 'all'
        params:
            nof_layers: 18
            weights_init: 'pretrained'

datasets:
    paths_to_configs : ['C:\Users\benba\Documents\University\Masterarbeit\Depth-Semantic-UDA\cfg\yaml_files\train\semantic_and_depth_unsupervised\cityscapes_semantic.yaml',
                        'C:\Users\benba\Documents\University\Masterarbeit\Depth-Semantic-UDA\cfg\yaml_files\train\semantic_and_depth_unsupervised\cityscapes_sequence.yaml',
                        'C:\Users\benba\Documents\University\Masterarbeit\Depth-Semantic-UDA\cfg\yaml_files\train\semantic_and_depth_unsupervised\cityscapes_semantic.yaml']
    loss_weights : [1, 1, 0]

train:
    nof_epochs: 40
    batch_size: 1
    nof_workers: 5

    optimizer:
        type: 'Adam'
        learning_rate: 0.0001
    scheduler:
        type: 'MultiStepLR'
        gamma: 0.5
        milestones: [50] # half the learning rate for the last 10 epochs

val:
    batch_size: 1
    nof_workers: 5

checkpoint:
    use_checkpoint: False


device:
    multiple_gpus: False

io:
    path_save: 'D:\Depth-Semantic-UDA\experiments\todelete'
