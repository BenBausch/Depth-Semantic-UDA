Length Target Train Loader: 44625
Length Target Validation Loader: 250
Length Source Train Loader: 44625
No checkpoint is used. Training from scratch!
[{'silog_depth': {'weight': 0.85}, 'bce': {'r': 0.3, 'ignore_index': 250}, 'snr': 'None'}]
[{'silog_depth': 1, 'bce': 0.001, 'snr': 0.01}]
Training supervised on source dataset using dense depth!
Training supervised on source dataset using semantic annotations!
Source ground truth scale is used for computing depth errors while training.
Source ground truth scale is used for computing depth errors while validating.
Training unsupervised on target dataset using self supervised depth!
Training started...
Training epoch 0 | batch 0
Batch on Device 0 computed in 3.3161978721618652 seconds.
tensor([10.3966], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 8.443020105361938
Time for Loss backward: 4.853315591812134
Training epoch 0 | batch 1
Batch on Device 0 computed in 0.7180061340332031 seconds.
tensor([11.1754], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.69970703125
Time for Loss backward: 1.5905282497406006
Training epoch 0 | batch 2
Batch on Device 0 computed in 0.711543083190918 seconds.
tensor([8.3659], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.66245436668396
Time for Loss backward: 1.588926076889038
Training epoch 0 | batch 3
Batch on Device 0 computed in 0.7115859985351562 seconds.
tensor([9.0052], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.6607706546783447
Time for Loss backward: 1.5870020389556885
Training epoch 0 | batch 4
Batch on Device 0 computed in 0.7114722728729248 seconds.
tensor([8.0499], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.671374797821045
Time for Loss backward: 1.5979642868041992
Training epoch 0 | batch 5
Batch on Device 0 computed in 0.7165424823760986 seconds.
tensor([7.5481], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.6761605739593506
Time for Loss backward: 1.5972108840942383
Training epoch 0 | batch 6
Batch on Device 0 computed in 0.7165336608886719 seconds.
tensor([10.9939], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.689340353012085
Time for Loss backward: 1.608813762664795
Training epoch 0 | batch 7
Batch on Device 0 computed in 0.7166481018066406 seconds.
tensor([7.9209], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.6817517280578613
Time for Loss backward: 1.5977296829223633
Training epoch 0 | batch 8
Batch on Device 0 computed in 0.7166461944580078 seconds.
tensor([10.3671], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.677978277206421
Time for Loss backward: 1.5972702503204346
Training epoch 0 | batch 9
Batch on Device 0 computed in 0.7164855003356934 seconds.
tensor([9.0632], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.677448272705078
Time for Loss backward: 1.597968578338623
Total time for 10 batches 59.47266745567322
Validation
set eval mode
set eval mode
set eval mode
set eval mode
set eval mode
/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/site-packages/torch/nn/functional.py:4003: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
WARNING:root:device cuda:0
WARNING:root:device cuda:0
WARNING:root:device cuda:0
WARNING:root:device cuda:0
