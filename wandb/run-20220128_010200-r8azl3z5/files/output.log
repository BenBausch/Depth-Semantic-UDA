Length Target Train Loader: 11157
Length Target Validation Loader: 63
Length Source Train Loader: 1175
No checkpoint is used. Training from scratch!
[{'silog_depth': {'weight': 0.85}, 'bce': {'r': 0.3, 'ignore_index': 250}, 'snr': 'None'}]
[{'silog_depth': 1, 'bce': 0.001, 'snr': 0.01}]
Training supervised on source dataset using dense depth!
Training supervised on source dataset using semantic annotations!
Source ground truth scale is used for computing depth errors while training.
Source ground truth scale is used for computing depth errors while validating.
Training unsupervised on target dataset using self supervised depth!
Training started...
Training epoch 0 | batch 0
Batch on Device 0 computed in 3.4598019123077393 seconds.
tensor([7.3919], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.04268360137939453
Time for loss calculation for target: 0.02107405662536621
Time for Loss backward: 5.179787635803223
Time needed for the batch 8.917277336120605
Time needed for logging 5.245208740234375e-05
Training epoch 0 | batch 1
Batch on Device 0 computed in 0.7366957664489746 seconds.
tensor([8.6336], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.359788179397583
Time for loss calculation for target: 0.11568665504455566
Time for Loss backward: 1.8009109497070312
Time needed for the batch 3.026712656021118
Time needed for logging 0.04610443115234375
Training epoch 0 | batch 2
Batch on Device 0 computed in 0.7365851402282715 seconds.
tensor([8.1386], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35246706008911133
Time for loss calculation for target: 0.011786699295043945
Time for Loss backward: 1.7842586040496826
Time needed for the batch 2.895643711090088
Time needed for logging 0.007035017013549805
Training epoch 0 | batch 3
Batch on Device 0 computed in 0.7368428707122803 seconds.
tensor([7.2034], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3523712158203125
Time for loss calculation for target: 0.012325763702392578
Time for Loss backward: 1.7830531597137451
Time needed for the batch 2.8921995162963867
Time needed for logging 0.007118701934814453
Training epoch 0 | batch 4
Batch on Device 0 computed in 0.7364537715911865 seconds.
tensor([8.2653], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3523728847503662
Time for loss calculation for target: 0.012055158615112305
Time for Loss backward: 1.7786953449249268
Time needed for the batch 2.8873398303985596
Time needed for logging 0.006965160369873047
Training epoch 0 | batch 5
Batch on Device 0 computed in 0.7414083480834961 seconds.
tensor([7.8402], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3523576259613037
Time for loss calculation for target: 0.011780023574829102
Time for Loss backward: 1.7792742252349854
Time needed for the batch 2.8927063941955566
Time needed for logging 0.007261991500854492
Training epoch 0 | batch 6
Batch on Device 0 computed in 0.7414495944976807 seconds.
tensor([8.7705], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35233545303344727
Time for loss calculation for target: 0.01182103157043457
Time for Loss backward: 1.7778172492980957
Time needed for the batch 2.891252040863037
Time needed for logging 0.0070476531982421875
Training epoch 0 | batch 7
Batch on Device 0 computed in 0.7409062385559082 seconds.
tensor([6.0817], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35254621505737305
Time for loss calculation for target: 0.011881828308105469
Time for Loss backward: 1.7790191173553467
Time needed for the batch 2.892392635345459
Time needed for logging 0.007086515426635742
Training epoch 0 | batch 8
Batch on Device 0 computed in 0.7400531768798828 seconds.
tensor([8.6554], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3524041175842285
Time for loss calculation for target: 0.012140989303588867
Time for Loss backward: 1.7836196422576904
Time needed for the batch 2.8961071968078613
Time needed for logging 0.007191658020019531
Training epoch 0 | batch 9
Batch on Device 0 computed in 0.736624002456665 seconds.
tensor([8.1050], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35234904289245605
Time for loss calculation for target: 0.011809349060058594
Time for Loss backward: 1.786811351776123
Time needed for the batch 2.8956286907196045
Time needed for logging 0.0070536136627197266
Total time for 10 batches 64.24661469459534
Training epoch 0 | batch 10
Batch on Device 0 computed in 0.7367088794708252 seconds.
tensor([6.7324], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35240912437438965
Time for loss calculation for target: 0.011764049530029297
Time for Loss backward: 1.77907395362854
Time needed for the batch 2.8891067504882812
Time needed for logging 0.007382869720458984
Training epoch 0 | batch 11
Batch on Device 0 computed in 0.7399964332580566 seconds.
tensor([7.0694], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35240793228149414
Time for loss calculation for target: 0.011784791946411133
Time for Loss backward: 1.7833235263824463
Time needed for the batch 2.8951656818389893
Time needed for logging 0.006932497024536133
Training epoch 0 | batch 12
Batch on Device 0 computed in 0.7365279197692871 seconds.
tensor([9.2375], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.352388858795166
Time for loss calculation for target: 0.011811971664428711
Time for Loss backward: 1.783656120300293
Time needed for the batch 2.8924736976623535
Time needed for logging 0.006903409957885742
Training epoch 0 | batch 13
Batch on Device 0 computed in 0.7366063594818115 seconds.
tensor([7.0004], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35237693786621094
Time for loss calculation for target: 0.011818408966064453
Time for Loss backward: 1.7839014530181885
Time needed for the batch 2.89241886138916
Time needed for logging 0.0069735050201416016
Training epoch 0 | batch 14
Batch on Device 0 computed in 0.7365884780883789 seconds.
tensor([10.7627], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3524744510650635
Time for loss calculation for target: 0.011780023574829102
Time for Loss backward: 1.7804865837097168
Time needed for the batch 2.889192819595337
Time needed for logging 0.007004499435424805
Training epoch 0 | batch 15
Batch on Device 0 computed in 0.7364776134490967 seconds.
tensor([6.2061], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3524811267852783
Time for loss calculation for target: 0.011819601058959961
Time for Loss backward: 1.7861275672912598
Time needed for the batch 2.8943099975585938
Time needed for logging 0.006795406341552734
Training epoch 0 | batch 16
Batch on Device 0 computed in 0.7446298599243164 seconds.
tensor([6.4143], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439014434814453
Time for loss calculation for target: 0.011865615844726562
Time for Loss backward: 1.791288137435913
Time needed for the batch 2.910156488418579
Time needed for logging 0.00676274299621582
Training epoch 0 | batch 17
Batch on Device 0 computed in 0.7398507595062256 seconds.
tensor([5.4398], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544192314147949
Time for loss calculation for target: 0.011855840682983398
Time for Loss backward: 1.7889220714569092
Time needed for the batch 2.902967691421509
Time needed for logging 0.0067293643951416016
Training epoch 0 | batch 18
Batch on Device 0 computed in 0.7398209571838379 seconds.
tensor([4.5361], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544955253601074
Time for loss calculation for target: 0.011913776397705078
Time for Loss backward: 1.7907073497772217
Time needed for the batch 2.9046692848205566
Time needed for logging 0.0070612430572509766
Training epoch 0 | batch 19
Batch on Device 0 computed in 0.7397897243499756 seconds.
tensor([4.2980], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544294834136963
Time for loss calculation for target: 0.011862039566040039
Time for Loss backward: 1.790464162826538
Time needed for the batch 2.904404878616333
Time needed for logging 0.007333993911743164
Training epoch 0 | batch 20
Batch on Device 0 computed in 0.7398214340209961 seconds.
tensor([4.0638], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437893867492676
Time for loss calculation for target: 0.011718511581420898
Time for Loss backward: 1.7905824184417725
Time needed for the batch 2.9040799140930176
Time needed for logging 0.007091045379638672
Training epoch 0 | batch 21
Batch on Device 0 computed in 0.7397415637969971 seconds.
tensor([4.5046], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543722629547119
Time for loss calculation for target: 0.012443065643310547
Time for Loss backward: 1.7898461818695068
Time needed for the batch 2.904310464859009
Time needed for logging 0.0070650577545166016
Training epoch 0 | batch 22
Batch on Device 0 computed in 0.7405157089233398 seconds.
tensor([4.0083], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35428595542907715
Time for loss calculation for target: 0.011784076690673828
Time for Loss backward: 1.7912814617156982
Time needed for the batch 2.905705451965332
Time needed for logging 0.006629228591918945
Training epoch 0 | batch 23
Batch on Device 0 computed in 0.7398998737335205 seconds.
tensor([2.9373], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35430073738098145
Time for loss calculation for target: 0.011785745620727539
Time for Loss backward: 1.789658784866333
Time needed for the batch 2.904808521270752
Time needed for logging 0.00709223747253418
Training epoch 0 | batch 24
Batch on Device 0 computed in 0.7398028373718262 seconds.
tensor([2.9178], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439586639404297
Time for loss calculation for target: 0.011796712875366211
Time for Loss backward: 1.7958991527557373
Time needed for the batch 2.9097914695739746
Time needed for logging 0.0069599151611328125
Training epoch 0 | batch 25
Batch on Device 0 computed in 0.7399098873138428 seconds.
tensor([2.9863], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543236255645752
Time for loss calculation for target: 0.012029647827148438
Time for Loss backward: 1.7860350608825684
Time needed for the batch 2.9002976417541504
Time needed for logging 0.00717616081237793
Training epoch 0 | batch 26
Batch on Device 0 computed in 0.7419531345367432 seconds.
tensor([2.5833], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35430026054382324
Time for loss calculation for target: 0.01217341423034668
Time for Loss backward: 1.7836112976074219
Time needed for the batch 2.8999955654144287
Time needed for logging 0.007469892501831055
Training epoch 0 | batch 27
Batch on Device 0 computed in 0.7419142723083496 seconds.
tensor([2.8346], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543534278869629
Time for loss calculation for target: 0.011872053146362305
Time for Loss backward: 1.7903592586517334
Time needed for the batch 2.906667709350586
Time needed for logging 0.00675654411315918
Training epoch 0 | batch 28
Batch on Device 0 computed in 0.7396974563598633 seconds.
tensor([1.9070], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35431909561157227
Time for loss calculation for target: 0.011829614639282227
Time for Loss backward: 1.7898283004760742
Time needed for the batch 2.904055118560791
Time needed for logging 0.007140159606933594
Training epoch 0 | batch 29
Batch on Device 0 computed in 0.7396461963653564 seconds.
tensor([2.1997], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434627532958984
Time for loss calculation for target: 0.012122154235839844
Time for Loss backward: 1.7909839153289795
Time needed for the batch 2.9047083854675293
Time needed for logging 0.007246494293212891
Training epoch 0 | batch 30
Batch on Device 0 computed in 0.739715576171875 seconds.
tensor([0.7882], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35430192947387695
Time for loss calculation for target: 0.01188969612121582
Time for Loss backward: 1.7902672290802002
Time needed for the batch 2.9041996002197266
Time needed for logging 0.006956338882446289
Training epoch 0 | batch 31
Batch on Device 0 computed in 0.7397468090057373 seconds.
tensor([1.3390], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3548901081085205
Time for loss calculation for target: 0.011737585067749023
Time for Loss backward: 1.7880566120147705
Time needed for the batch 2.90226149559021
Time needed for logging 0.0072515010833740234
Training epoch 0 | batch 32
Batch on Device 0 computed in 0.7422716617584229 seconds.
tensor([1.2835], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543553352355957
Time for loss calculation for target: 0.011783361434936523
Time for Loss backward: 1.7859318256378174
Time needed for the batch 2.9021096229553223
Time needed for logging 0.007248878479003906
Training epoch 0 | batch 33
Batch on Device 0 computed in 0.743309736251831 seconds.
tensor([1.4739], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443544387817383
Time for loss calculation for target: 0.011762142181396484
Time for Loss backward: 1.790940523147583
Time needed for the batch 2.9082868099212646
Time needed for logging 0.0070705413818359375
Training epoch 0 | batch 34
Batch on Device 0 computed in 0.7397525310516357 seconds.
tensor([1.0320], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35431385040283203
Time for loss calculation for target: 0.01174616813659668
Time for Loss backward: 1.8596160411834717
Time needed for the batch 2.9737298488616943
Time needed for logging 0.007119417190551758
Training epoch 0 | batch 35
Batch on Device 0 computed in 0.7430286407470703 seconds.
tensor([0.9563], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3542807102203369
Time for loss calculation for target: 0.011751413345336914
Time for Loss backward: 1.7880868911743164
Time needed for the batch 2.9053988456726074
Time needed for logging 0.0071277618408203125
Training epoch 0 | batch 36
Batch on Device 0 computed in 0.7396955490112305 seconds.
tensor([0.7486], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543553352355957
Time for loss calculation for target: 0.011760711669921875
Time for Loss backward: 1.7848572731018066
Time needed for the batch 2.8987114429473877
Time needed for logging 0.0071184635162353516
Training epoch 0 | batch 37
Batch on Device 0 computed in 0.7440152168273926 seconds.
tensor([0.7073], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547937870025635
Time for loss calculation for target: 0.011798620223999023
Time for Loss backward: 1.790642499923706
Time needed for the batch 2.908656120300293
Time needed for logging 0.0071489810943603516
Training epoch 0 | batch 38
Batch on Device 0 computed in 0.7397425174713135 seconds.
tensor([0.5898], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433316230773926
Time for loss calculation for target: 0.011673450469970703
Time for Loss backward: 1.7852771282196045
Time needed for the batch 2.8997368812561035
Time needed for logging 0.006708860397338867
Training epoch 0 | batch 39
Batch on Device 0 computed in 0.7453367710113525 seconds.
tensor([1.2791], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35427212715148926
Time for loss calculation for target: 0.011703252792358398
Time for Loss backward: 1.7831368446350098
Time needed for the batch 2.901979446411133
Time needed for logging 0.006657838821411133
Training epoch 0 | batch 40
Batch on Device 0 computed in 0.7455782890319824 seconds.
tensor([0.7307], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547649383544922
Time for loss calculation for target: 0.01182246208190918
Time for Loss backward: 1.789799451828003
Time needed for the batch 2.909418821334839
Time needed for logging 0.006695270538330078
Training epoch 0 | batch 41
Batch on Device 0 computed in 0.7398700714111328 seconds.
tensor([0.9536], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439062118530273
Time for loss calculation for target: 0.011770248413085938
Time for Loss backward: 1.7913389205932617
Time needed for the batch 2.905229330062866
Time needed for logging 0.006644487380981445
Training epoch 0 | batch 42
Batch on Device 0 computed in 0.7397868633270264 seconds.
tensor([0.8387], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354259729385376
Time for loss calculation for target: 0.011724710464477539
Time for Loss backward: 1.7922351360321045
Time needed for the batch 2.905623435974121
Time needed for logging 0.006647825241088867
Training epoch 0 | batch 43
Batch on Device 0 computed in 0.7398033142089844 seconds.
tensor([0.9021], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547632694244385
Time for loss calculation for target: 0.011797666549682617
Time for Loss backward: 1.791158676147461
Time needed for the batch 2.9051172733306885
Time needed for logging 0.006643772125244141
Training epoch 0 | batch 44
Batch on Device 0 computed in 0.7399296760559082 seconds.
tensor([0.8381], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439348220825195
Time for loss calculation for target: 0.01175999641418457
Time for Loss backward: 1.7920031547546387
Time needed for the batch 2.905867576599121
Time needed for logging 0.006577968597412109
Training epoch 0 | batch 45
Batch on Device 0 computed in 0.739842414855957 seconds.
tensor([0.4938], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448384284973145
Time for loss calculation for target: 0.011826515197753906
Time for Loss backward: 1.7947099208831787
Time needed for the batch 2.908355236053467
Time needed for logging 0.006583213806152344
Training epoch 0 | batch 46
Batch on Device 0 computed in 0.7398955821990967 seconds.
tensor([0.6131], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35477662086486816
Time for loss calculation for target: 0.011932611465454102
Time for Loss backward: 1.7895700931549072
Time needed for the batch 2.903754949569702
Time needed for logging 0.0065920352935791016
Training epoch 0 | batch 47
Batch on Device 0 computed in 0.7403688430786133 seconds.
tensor([0.8981], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35431456565856934
Time for loss calculation for target: 0.011698722839355469
Time for Loss backward: 1.7839272022247314
Time needed for the batch 2.8988215923309326
Time needed for logging 0.0066509246826171875
Training epoch 0 | batch 48
Batch on Device 0 computed in 0.7463734149932861 seconds.
tensor([0.8561], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543055057525635
Time for loss calculation for target: 0.01178288459777832
Time for Loss backward: 1.785595178604126
Time needed for the batch 2.905775547027588
Time needed for logging 0.006842136383056641
Training epoch 0 | batch 49
Batch on Device 0 computed in 0.7465753555297852 seconds.
tensor([0.5694], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545222282409668
Time for loss calculation for target: 0.011801958084106445
Time for Loss backward: 1.7847867012023926
Time needed for the batch 2.9052464962005615
Time needed for logging 0.007105588912963867
Training epoch 0 | batch 50
Batch on Device 0 computed in 0.7458157539367676 seconds.
tensor([0.4347], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543581962585449
Time for loss calculation for target: 0.011745929718017578
Time for Loss backward: 1.7845072746276855
Time needed for the batch 2.904203176498413
Time needed for logging 0.0065534114837646484
Training epoch 0 | batch 51
Batch on Device 0 computed in 0.7463726997375488 seconds.
tensor([0.5870], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436081886291504
Time for loss calculation for target: 0.0116729736328125
Time for Loss backward: 1.7853524684906006
Time needed for the batch 2.905418872833252
Time needed for logging 0.0064830780029296875
Training epoch 0 | batch 52
Batch on Device 0 computed in 0.7462978363037109 seconds.
tensor([0.4450], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35454368591308594
Time for loss calculation for target: 0.011825799942016602
Time for Loss backward: 1.784459114074707
Time needed for the batch 2.9048821926116943
Time needed for logging 0.00662541389465332
Training epoch 0 | batch 53
Batch on Device 0 computed in 0.7473475933074951 seconds.
tensor([0.5900], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544480800628662
Time for loss calculation for target: 0.011694669723510742
Time for Loss backward: 1.7846975326538086
Time needed for the batch 2.90582013130188
Time needed for logging 0.006577014923095703
Training epoch 0 | batch 54
Batch on Device 0 computed in 0.7452013492584229 seconds.
tensor([0.5850], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543682098388672
Time for loss calculation for target: 0.01168060302734375
Time for Loss backward: 1.7848782539367676
Time needed for the batch 2.9037554264068604
Time needed for logging 0.006508827209472656
Training epoch 0 | batch 55
Batch on Device 0 computed in 0.7411279678344727 seconds.
tensor([0.5008], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543984889984131
Time for loss calculation for target: 0.011710166931152344
Time for Loss backward: 1.7902171611785889
Time needed for the batch 2.9095516204833984
Time needed for logging 0.00638127326965332
Training epoch 0 | batch 56
Batch on Device 0 computed in 0.7402923107147217 seconds.
tensor([0.4961], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543813228607178
Time for loss calculation for target: 0.011698722839355469
Time for Loss backward: 1.787614107131958
Time needed for the batch 2.9016125202178955
Time needed for logging 0.006537199020385742
Training epoch 0 | batch 57
Batch on Device 0 computed in 0.740917444229126 seconds.
tensor([0.6157], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354386568069458
Time for loss calculation for target: 0.011735677719116211
Time for Loss backward: 1.7874066829681396
Time needed for the batch 2.90315318107605
Time needed for logging 0.006711721420288086
Training epoch 0 | batch 58
Batch on Device 0 computed in 0.7421360015869141 seconds.
tensor([0.2452], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440754890441895
Time for loss calculation for target: 0.011693954467773438
Time for Loss backward: 1.789506435394287
Time needed for the batch 2.9053571224212646
Time needed for logging 0.0066568851470947266
Training epoch 0 | batch 59
Batch on Device 0 computed in 0.7398233413696289 seconds.
tensor([0.8072], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544037342071533
Time for loss calculation for target: 0.01172637939453125
Time for Loss backward: 1.8172881603240967
Time needed for the batch 2.9312798976898193
Time needed for logging 0.00665736198425293
Training epoch 0 | batch 60
Batch on Device 0 computed in 0.7402582168579102 seconds.
tensor([0.5847], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543546199798584
Time for loss calculation for target: 0.011866092681884766
Time for Loss backward: 1.7918057441711426
Time needed for the batch 2.9065842628479004
Time needed for logging 0.006810665130615234
Training epoch 0 | batch 61
Batch on Device 0 computed in 0.7397756576538086 seconds.
tensor([0.7244], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354351282119751
Time for loss calculation for target: 0.011671066284179688
Time for Loss backward: 1.792182445526123
Time needed for the batch 2.9055519104003906
Time needed for logging 0.006654500961303711
Training epoch 0 | batch 62
Batch on Device 0 computed in 0.7423326969146729 seconds.
tensor([1.1826], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434651374816895
Time for loss calculation for target: 0.011707305908203125
Time for Loss backward: 1.7871859073638916
Time needed for the batch 2.9032375812530518
Time needed for logging 0.006899595260620117
Training epoch 0 | batch 63
Batch on Device 0 computed in 0.7403342723846436 seconds.
tensor([0.7728], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543851375579834
Time for loss calculation for target: 0.01166844367980957
Time for Loss backward: 1.7896277904510498
Time needed for the batch 2.90331768989563
Time needed for logging 0.006961822509765625
Training epoch 0 | batch 64
Batch on Device 0 computed in 0.7399370670318604 seconds.
tensor([0.8511], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543379306793213
Time for loss calculation for target: 0.011716365814208984
Time for Loss backward: 1.790712594985962
Time needed for the batch 2.904031276702881
Time needed for logging 0.006620645523071289
Training epoch 0 | batch 65
Batch on Device 0 computed in 0.7398865222930908 seconds.
tensor([0.5686], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433030128479004
Time for loss calculation for target: 0.011709928512573242
Time for Loss backward: 1.7913792133331299
Time needed for the batch 2.9048705101013184
Time needed for logging 0.006659984588623047
Training epoch 0 | batch 66
Batch on Device 0 computed in 0.7399649620056152 seconds.
tensor([1.3620], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448217391967773
Time for loss calculation for target: 0.01173853874206543
Time for Loss backward: 1.785679817199707
Time needed for the batch 2.8990962505340576
Time needed for logging 0.006571292877197266
Training epoch 0 | batch 67
Batch on Device 0 computed in 0.7448410987854004 seconds.
tensor([1.0534], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440754890441895
Time for loss calculation for target: 0.011742591857910156
Time for Loss backward: 1.785886287689209
Time needed for the batch 2.9045917987823486
Time needed for logging 0.0066416263580322266
Training epoch 0 | batch 68
Batch on Device 0 computed in 0.7451868057250977 seconds.
tensor([0.1316], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543679714202881
Time for loss calculation for target: 0.011693239212036133
Time for Loss backward: 1.7837774753570557
Time needed for the batch 2.9026615619659424
Time needed for logging 0.006519317626953125
Training epoch 0 | batch 69
Batch on Device 0 computed in 0.7466812133789062 seconds.
tensor([0.7054], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35438084602355957
Time for loss calculation for target: 0.011692523956298828
Time for Loss backward: 1.7845659255981445
Time needed for the batch 2.905069351196289
Time needed for logging 0.006628990173339844
Training epoch 0 | batch 70
Batch on Device 0 computed in 0.7459189891815186 seconds.
tensor([0.6335], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544003963470459
Time for loss calculation for target: 0.011725664138793945
Time for Loss backward: 1.789902687072754
Time needed for the batch 2.9108216762542725
Time needed for logging 0.006673097610473633
Training epoch 0 | batch 71
Batch on Device 0 computed in 0.7397944927215576 seconds.
tensor([0.6978], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35428667068481445
Time for loss calculation for target: 0.01166224479675293
Time for Loss backward: 1.7901530265808105
Time needed for the batch 2.904482126235962
Time needed for logging 0.006665945053100586
Training epoch 0 | batch 72
Batch on Device 0 computed in 0.7399172782897949 seconds.
tensor([0.5788], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354445219039917
Time for loss calculation for target: 0.011583328247070312
Time for Loss backward: 1.79148530960083
Time needed for the batch 2.9051690101623535
Time needed for logging 0.0066394805908203125
Training epoch 0 | batch 73
Batch on Device 0 computed in 0.7399957180023193 seconds.
tensor([0.6038], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544166088104248
Time for loss calculation for target: 0.011768102645874023
Time for Loss backward: 1.7939059734344482
Time needed for the batch 2.9077088832855225
Time needed for logging 0.0067484378814697266
Training epoch 0 | batch 74
Batch on Device 0 computed in 0.7398135662078857 seconds.
tensor([0.7236], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440921783447266
Time for loss calculation for target: 0.011712312698364258
Time for Loss backward: 1.7896671295166016
Time needed for the batch 2.903158664703369
Time needed for logging 0.006584882736206055
Training epoch 0 | batch 75
Batch on Device 0 computed in 0.7397994995117188 seconds.
tensor([1.1077], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35477328300476074
Time for loss calculation for target: 0.012030839920043945
Time for Loss backward: 1.7892816066741943
Time needed for the batch 2.90427827835083
Time needed for logging 0.00671839714050293
Training epoch 0 | batch 76
Batch on Device 0 computed in 0.7398345470428467 seconds.
tensor([0.5670], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543727397918701
Time for loss calculation for target: 0.011767148971557617
Time for Loss backward: 1.7869873046875
Time needed for the batch 2.9007575511932373
Time needed for logging 0.006964206695556641
Training epoch 0 | batch 77
Batch on Device 0 computed in 0.741692304611206 seconds.
tensor([1.4342], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543705940246582
Time for loss calculation for target: 0.011790990829467773
Time for Loss backward: 1.794508934020996
Time needed for the batch 2.9106380939483643
Time needed for logging 0.006896257400512695
Training epoch 0 | batch 78
Batch on Device 0 computed in 0.7399623394012451 seconds.
tensor([0.8281], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35447049140930176
Time for loss calculation for target: 0.011775016784667969
Time for Loss backward: 1.7913084030151367
Time needed for the batch 2.905395030975342
Time needed for logging 0.007161140441894531
Training epoch 0 | batch 79
Batch on Device 0 computed in 0.7398123741149902 seconds.
tensor([0.3775], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543822765350342
Time for loss calculation for target: 0.011759757995605469
Time for Loss backward: 1.789337396621704
Time needed for the batch 2.9027273654937744
Time needed for logging 0.006941318511962891
Training epoch 0 | batch 80
Batch on Device 0 computed in 0.7400341033935547 seconds.
tensor([0.5681], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543262481689453
Time for loss calculation for target: 0.01166844367980957
Time for Loss backward: 1.790675163269043
Time needed for the batch 2.905808210372925
Time needed for logging 0.007168769836425781
Training epoch 0 | batch 81
Batch on Device 0 computed in 0.7400009632110596 seconds.
tensor([0.5754], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440540313720703
Time for loss calculation for target: 0.011741161346435547
Time for Loss backward: 1.7891221046447754
Time needed for the batch 2.9043893814086914
Time needed for logging 0.0065195560455322266
Training epoch 0 | batch 82
Batch on Device 0 computed in 0.7408978939056396 seconds.
tensor([0.3703], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35493993759155273
Time for loss calculation for target: 0.012040138244628906
Time for Loss backward: 1.7873969078063965
Time needed for the batch 2.903862953186035
Time needed for logging 0.007220029830932617
Training epoch 0 | batch 83
Batch on Device 0 computed in 0.7398667335510254 seconds.
tensor([0.5955], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543968200683594
Time for loss calculation for target: 0.011759519577026367
Time for Loss backward: 1.7912817001342773
Time needed for the batch 2.9054677486419678
Time needed for logging 0.00730586051940918
Training epoch 0 | batch 84
Batch on Device 0 computed in 0.7400774955749512 seconds.
tensor([0.5379], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547656536102295
Time for loss calculation for target: 0.011894702911376953
Time for Loss backward: 1.7889690399169922
Time needed for the batch 2.9036498069763184
Time needed for logging 0.007238149642944336
Training epoch 0 | batch 85
Batch on Device 0 computed in 0.7398996353149414 seconds.
tensor([0.6012], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35428452491760254
Time for loss calculation for target: 0.011777162551879883
Time for Loss backward: 1.7906701564788818
Time needed for the batch 2.9047794342041016
Time needed for logging 0.007199764251708984
Training epoch 0 | batch 86
Batch on Device 0 computed in 0.7398784160614014 seconds.
tensor([0.4727], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436296463012695
Time for loss calculation for target: 0.011855363845825195
Time for Loss backward: 1.7906854152679443
Time needed for the batch 2.904648780822754
Time needed for logging 0.007361412048339844
Training epoch 0 | batch 87
Batch on Device 0 computed in 0.7420375347137451 seconds.
tensor([0.7309], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35474395751953125
Time for loss calculation for target: 0.011989831924438477
Time for Loss backward: 1.790569543838501
Time needed for the batch 2.9069247245788574
Time needed for logging 0.007071733474731445
Training epoch 0 | batch 88
Batch on Device 0 computed in 0.7404873371124268 seconds.
tensor([0.4444], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440921783447266
Time for loss calculation for target: 0.011828899383544922
Time for Loss backward: 1.790294885635376
Time needed for the batch 2.905150890350342
Time needed for logging 0.007050991058349609
Training epoch 0 | batch 89
Batch on Device 0 computed in 0.7398049831390381 seconds.
tensor([0.5475], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436201095581055
Time for loss calculation for target: 0.011746644973754883
Time for Loss backward: 1.790966272354126
Time needed for the batch 2.904766798019409
Time needed for logging 0.0071239471435546875
Training epoch 0 | batch 90
Batch on Device 0 computed in 0.7399389743804932 seconds.
tensor([0.5169], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35498666763305664
Time for loss calculation for target: 0.011912822723388672
Time for Loss backward: 1.8048222064971924
Time needed for the batch 2.920018196105957
Time needed for logging 0.0071256160736083984
Training epoch 0 | batch 91
Batch on Device 0 computed in 0.739891529083252 seconds.
tensor([0.3613], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434579849243164
Time for loss calculation for target: 0.011797666549682617
Time for Loss backward: 1.7910223007202148
Time needed for the batch 2.905179738998413
Time needed for logging 0.0071375370025634766
Training epoch 0 | batch 92
Batch on Device 0 computed in 0.7402293682098389 seconds.
tensor([0.7030], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442328453063965
Time for loss calculation for target: 0.011833667755126953
Time for Loss backward: 1.7866621017456055
Time needed for the batch 2.9008514881134033
Time needed for logging 0.007251262664794922
Training epoch 0 | batch 93
Batch on Device 0 computed in 0.7420029640197754 seconds.
tensor([0.5923], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543362617492676
Time for loss calculation for target: 0.011780500411987305
Time for Loss backward: 1.7912487983703613
Time needed for the batch 2.907529830932617
Time needed for logging 0.007270336151123047
Training epoch 0 | batch 94
Batch on Device 0 computed in 0.7398717403411865 seconds.
tensor([1.2128], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545265197753906
Time for loss calculation for target: 0.011817216873168945
Time for Loss backward: 1.7897753715515137
Time needed for the batch 2.903714656829834
Time needed for logging 0.007259845733642578
Training epoch 0 | batch 95
Batch on Device 0 computed in 0.7407419681549072 seconds.
tensor([0.2526], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434556007385254
Time for loss calculation for target: 0.011799335479736328
Time for Loss backward: 1.7889633178710938
Time needed for the batch 2.9043128490448
Time needed for logging 0.007425069808959961
Training epoch 0 | batch 96
Batch on Device 0 computed in 0.7396969795227051 seconds.
tensor([0.6187], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543426990509033
Time for loss calculation for target: 0.011828422546386719
Time for Loss backward: 1.7910265922546387
Time needed for the batch 2.9047369956970215
Time needed for logging 0.007197141647338867
Training epoch 0 | batch 97
Batch on Device 0 computed in 0.7398402690887451 seconds.
tensor([0.4444], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354372501373291
Time for loss calculation for target: 0.011766672134399414
Time for Loss backward: 1.7903437614440918
Time needed for the batch 2.9044082164764404
Time needed for logging 0.007044315338134766
Training epoch 0 | batch 98
Batch on Device 0 computed in 0.7398402690887451 seconds.
tensor([0.5347], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436534881591797
Time for loss calculation for target: 0.01187896728515625
Time for Loss backward: 1.7896308898925781
Time needed for the batch 2.904343605041504
Time needed for logging 0.007213115692138672
Training epoch 0 | batch 99
Batch on Device 0 computed in 0.7520809173583984 seconds.
tensor([0.6609], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3419005870819092
Time for loss calculation for target: 0.011693000793457031
Time for Loss backward: 1.7857954502105713
Time needed for the batch 2.8996925354003906
Time needed for logging 0.007220745086669922
Training epoch 0 | batch 100
Batch on Device 0 computed in 0.7424604892730713 seconds.
tensor([0.5178], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439562797546387
Time for loss calculation for target: 0.012415647506713867
Time for Loss backward: 1.7870895862579346
Time needed for the batch 2.9053523540496826
Time needed for logging 0.007047891616821289
Training epoch 0 | batch 101
Batch on Device 0 computed in 0.7398679256439209 seconds.
tensor([1.1421], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439133644104004
Time for loss calculation for target: 0.011822223663330078
Time for Loss backward: 1.7897679805755615
Time needed for the batch 2.903704881668091
Time needed for logging 0.007189750671386719
Training epoch 0 | batch 102
Batch on Device 0 computed in 0.7399592399597168 seconds.
tensor([0.2503], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440802574157715
Time for loss calculation for target: 0.011796951293945312
Time for Loss backward: 1.7912285327911377
Time needed for the batch 2.9052977561950684
Time needed for logging 0.00713801383972168
Training epoch 0 | batch 103
Batch on Device 0 computed in 0.7398734092712402 seconds.
tensor([0.2190], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543975353240967
Time for loss calculation for target: 0.011725425720214844
Time for Loss backward: 1.789893388748169
Time needed for the batch 2.904203176498413
Time needed for logging 0.0069980621337890625
Training epoch 0 | batch 104
Batch on Device 0 computed in 0.7396714687347412 seconds.
tensor([0.5000], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434818267822266
Time for loss calculation for target: 0.011990070343017578
Time for Loss backward: 1.791473627090454
Time needed for the batch 2.905334949493408
Time needed for logging 0.0071485042572021484
Training epoch 0 | batch 105
Batch on Device 0 computed in 0.7400078773498535 seconds.
tensor([0.3190], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543398380279541
Time for loss calculation for target: 0.011762380599975586
Time for Loss backward: 1.7894387245178223
Time needed for the batch 2.9033203125
Time needed for logging 0.00708770751953125
Training epoch 0 | batch 106
Batch on Device 0 computed in 0.7398233413696289 seconds.
tensor([0.7503], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545055389404297
Time for loss calculation for target: 0.011773824691772461
Time for Loss backward: 1.7893390655517578
Time needed for the batch 2.9031708240509033
Time needed for logging 0.007180690765380859
Training epoch 0 | batch 107
Batch on Device 0 computed in 0.7397782802581787 seconds.
tensor([0.3908], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543720245361328
Time for loss calculation for target: 0.011773824691772461
Time for Loss backward: 1.7875139713287354
Time needed for the batch 2.9011809825897217
Time needed for logging 0.007198333740234375
Training epoch 0 | batch 108
Batch on Device 0 computed in 0.739854097366333 seconds.
tensor([0.3628], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544347286224365
Time for loss calculation for target: 0.012044668197631836
Time for Loss backward: 1.7899580001831055
Time needed for the batch 2.904330253601074
Time needed for logging 0.007016897201538086
Training epoch 0 | batch 109
Batch on Device 0 computed in 0.7399468421936035 seconds.
tensor([0.5485], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543562889099121
Time for loss calculation for target: 0.011815547943115234
Time for Loss backward: 1.7908413410186768
Time needed for the batch 2.904771566390991
Time needed for logging 0.0070002079010009766
Training epoch 0 | batch 110
Batch on Device 0 computed in 0.7398161888122559 seconds.
tensor([0.4064], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547861576080322
Time for loss calculation for target: 0.011902809143066406
Time for Loss backward: 1.7895944118499756
Time needed for the batch 2.9036998748779297
Time needed for logging 0.007249116897583008
Training epoch 0 | batch 111
Batch on Device 0 computed in 0.7442939281463623 seconds.
tensor([0.5869], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35489439964294434
Time for loss calculation for target: 0.011859893798828125
Time for Loss backward: 1.787428379058838
Time needed for the batch 2.906383514404297
Time needed for logging 0.007069110870361328
Training epoch 0 | batch 112
Batch on Device 0 computed in 0.7397541999816895 seconds.
tensor([0.3606], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437464714050293
Time for loss calculation for target: 0.01207113265991211
Time for Loss backward: 1.7867858409881592
Time needed for the batch 2.908047914505005
Time needed for logging 0.007145881652832031
Training epoch 0 | batch 113
Batch on Device 0 computed in 0.7427294254302979 seconds.
tensor([0.5461], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442256927490234
Time for loss calculation for target: 0.01170039176940918
Time for Loss backward: 1.7852814197540283
Time needed for the batch 2.9021987915039062
Time needed for logging 0.007035255432128906
Training epoch 0 | batch 114
Batch on Device 0 computed in 0.7436704635620117 seconds.
tensor([0.5399], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543734550476074
Time for loss calculation for target: 0.01181936264038086
Time for Loss backward: 1.7901029586791992
Time needed for the batch 2.9078824520111084
Time needed for logging 0.007128000259399414
Training epoch 0 | batch 115
Batch on Device 0 computed in 0.7398762702941895 seconds.
tensor([0.5249], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442066192626953
Time for loss calculation for target: 0.011717796325683594
Time for Loss backward: 1.7899699211120605
Time needed for the batch 2.904088258743286
Time needed for logging 0.007130146026611328
Training epoch 0 | batch 116
Batch on Device 0 computed in 0.7398314476013184 seconds.
tensor([0.5243], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443997383117676
Time for loss calculation for target: 0.01168370246887207
Time for Loss backward: 1.790024757385254
Time needed for the batch 2.9038493633270264
Time needed for logging 0.007066011428833008
Training epoch 0 | batch 117
Batch on Device 0 computed in 0.7403757572174072 seconds.
tensor([0.5913], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544192314147949
Time for loss calculation for target: 0.01167154312133789
Time for Loss backward: 1.7885210514068604
Time needed for the batch 2.9035115242004395
Time needed for logging 0.007096290588378906
Training epoch 0 | batch 118
Batch on Device 0 computed in 0.7402780055999756 seconds.
tensor([0.4109], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543870449066162
Time for loss calculation for target: 0.011693239212036133
Time for Loss backward: 1.7900962829589844
Time needed for the batch 2.9045891761779785
Time needed for logging 0.007139682769775391
Training epoch 0 | batch 119
Batch on Device 0 computed in 0.7398688793182373 seconds.
tensor([0.6158], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35467028617858887
Time for loss calculation for target: 0.011798858642578125
Time for Loss backward: 1.7874951362609863
Time needed for the batch 2.901761531829834
Time needed for logging 0.007191896438598633
Training epoch 0 | batch 120
Batch on Device 0 computed in 0.7403078079223633 seconds.
tensor([0.4476], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543248176574707
Time for loss calculation for target: 0.01169896125793457
Time for Loss backward: 1.785489559173584
Time needed for the batch 2.899651527404785
Time needed for logging 0.007199287414550781
Training epoch 0 | batch 121
Batch on Device 0 computed in 0.743328332901001 seconds.
tensor([0.3688], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439395904541016
Time for loss calculation for target: 0.011728525161743164
Time for Loss backward: 1.7898616790771484
Time needed for the batch 2.90714693069458
Time needed for logging 0.00714564323425293
Training epoch 0 | batch 122
Batch on Device 0 computed in 0.7401540279388428 seconds.
tensor([0.7454], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543553352355957
Time for loss calculation for target: 0.011767864227294922
Time for Loss backward: 1.7882330417633057
Time needed for the batch 2.9023830890655518
Time needed for logging 0.007260560989379883
Training epoch 0 | batch 123
Batch on Device 0 computed in 0.7397603988647461 seconds.
tensor([0.5276], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433411598205566
Time for loss calculation for target: 0.01172018051147461
Time for Loss backward: 1.7898705005645752
Time needed for the batch 2.9034578800201416
Time needed for logging 0.007340908050537109
Training epoch 0 | batch 124
Batch on Device 0 computed in 0.7397892475128174 seconds.
tensor([0.5285], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433435440063477
Time for loss calculation for target: 0.011704206466674805
Time for Loss backward: 1.7897663116455078
Time needed for the batch 2.9035181999206543
Time needed for logging 0.007422447204589844
Training epoch 0 | batch 125
Batch on Device 0 computed in 0.7402522563934326 seconds.
tensor([0.4942], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544118404388428
Time for loss calculation for target: 0.011666297912597656
Time for Loss backward: 1.7867929935455322
Time needed for the batch 2.9012668132781982
Time needed for logging 0.007026195526123047
Training epoch 0 | batch 126
Batch on Device 0 computed in 0.7436323165893555 seconds.
tensor([0.3648], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543977737426758
Time for loss calculation for target: 0.011766672134399414
Time for Loss backward: 1.7896966934204102
Time needed for the batch 2.90738844871521
Time needed for logging 0.007138729095458984
Training epoch 0 | batch 127
Batch on Device 0 computed in 0.740546464920044 seconds.
tensor([0.7907], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543236255645752
Time for loss calculation for target: 0.01170969009399414
Time for Loss backward: 1.7855570316314697
Time needed for the batch 2.8999598026275635
Time needed for logging 0.006916999816894531
Training epoch 0 | batch 128
Batch on Device 0 computed in 0.7443671226501465 seconds.
tensor([0.7068], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543741703033447
Time for loss calculation for target: 0.01167607307434082
Time for Loss backward: 1.7886221408843994
Time needed for the batch 2.906567335128784
Time needed for logging 0.007080793380737305
Training epoch 0 | batch 129
Batch on Device 0 computed in 0.7398035526275635 seconds.
tensor([0.4903], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35430169105529785
Time for loss calculation for target: 0.011688947677612305
Time for Loss backward: 1.7898974418640137
Time needed for the batch 2.9034409523010254
Time needed for logging 0.007455110549926758
Training epoch 0 | batch 130
Batch on Device 0 computed in 0.7396609783172607 seconds.
tensor([0.2923], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543262481689453
Time for loss calculation for target: 0.011797189712524414
Time for Loss backward: 1.7911367416381836
Time needed for the batch 2.9049105644226074
Time needed for logging 0.0071260929107666016
Training epoch 0 | batch 131
Batch on Device 0 computed in 0.7398171424865723 seconds.
tensor([0.6000], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543877601623535
Time for loss calculation for target: 0.011774063110351562
Time for Loss backward: 1.7904434204101562
Time needed for the batch 2.9044952392578125
Time needed for logging 0.007022857666015625
Training epoch 0 | batch 132
Batch on Device 0 computed in 0.7398700714111328 seconds.
tensor([0.6127], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544321060180664
Time for loss calculation for target: 0.01179957389831543
Time for Loss backward: 1.7839789390563965
Time needed for the batch 2.8981595039367676
Time needed for logging 0.007253170013427734
Training epoch 0 | batch 133
Batch on Device 0 computed in 0.7462310791015625 seconds.
tensor([0.3354], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544321060180664
Time for loss calculation for target: 0.011709451675415039
Time for Loss backward: 1.7858471870422363
Time needed for the batch 2.906200408935547
Time needed for logging 0.007368803024291992
Training epoch 0 | batch 134
Batch on Device 0 computed in 0.7435142993927002 seconds.
tensor([0.3160], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543057441711426
Time for loss calculation for target: 0.011818647384643555
Time for Loss backward: 1.7901430130004883
Time needed for the batch 2.9079928398132324
Time needed for logging 0.007386445999145508
Training epoch 0 | batch 135
Batch on Device 0 computed in 0.7397646903991699 seconds.
tensor([0.4967], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35488462448120117
Time for loss calculation for target: 0.012018680572509766
Time for Loss backward: 1.7889482975006104
Time needed for the batch 2.903860330581665
Time needed for logging 0.007203578948974609
Training epoch 0 | batch 136
Batch on Device 0 computed in 0.7396340370178223 seconds.
tensor([0.3490], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3542912006378174
Time for loss calculation for target: 0.01174306869506836
Time for Loss backward: 1.7909214496612549
Time needed for the batch 2.904536724090576
Time needed for logging 0.007078886032104492
Training epoch 0 | batch 137
Batch on Device 0 computed in 0.7399311065673828 seconds.
tensor([0.4217], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35480237007141113
Time for loss calculation for target: 0.01217508316040039
Time for Loss backward: 1.7896568775177002
Time needed for the batch 2.9047255516052246
Time needed for logging 0.007151603698730469
Training epoch 0 | batch 138
Batch on Device 0 computed in 0.7398848533630371 seconds.
tensor([0.5510], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544604778289795
Time for loss calculation for target: 0.011720895767211914
Time for Loss backward: 1.790938138961792
Time needed for the batch 2.905029773712158
Time needed for logging 0.007333278656005859
Training epoch 0 | batch 139
Batch on Device 0 computed in 0.7399344444274902 seconds.
tensor([0.4356], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544168472290039
Time for loss calculation for target: 0.011685609817504883
Time for Loss backward: 1.7894904613494873
Time needed for the batch 2.9042000770568848
Time needed for logging 0.0072362422943115234
Training epoch 0 | batch 140
Batch on Device 0 computed in 0.7398829460144043 seconds.
tensor([0.5116], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440802574157715
Time for loss calculation for target: 0.011725187301635742
Time for Loss backward: 1.7849760055541992
Time needed for the batch 2.899019241333008
Time needed for logging 0.007163524627685547
Training epoch 0 | batch 141
Batch on Device 0 computed in 0.7437262535095215 seconds.
tensor([0.4639], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443615913391113
Time for loss calculation for target: 0.011803865432739258
Time for Loss backward: 1.791318655014038
Time needed for the batch 2.9095840454101562
Time needed for logging 0.007282733917236328
Training epoch 0 | batch 142
Batch on Device 0 computed in 0.7399108409881592 seconds.
tensor([0.2845], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35485363006591797
Time for loss calculation for target: 0.012498140335083008
Time for Loss backward: 1.789339542388916
Time needed for the batch 2.9046566486358643
Time needed for logging 0.0073108673095703125
Training epoch 0 | batch 143
Batch on Device 0 computed in 0.7399275302886963 seconds.
tensor([0.5509], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544125556945801
Time for loss calculation for target: 0.011781692504882812
Time for Loss backward: 1.790313482284546
Time needed for the batch 2.9044241905212402
Time needed for logging 0.007188320159912109
Training epoch 0 | batch 144
Batch on Device 0 computed in 0.7398037910461426 seconds.
tensor([0.9366], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543834686279297
Time for loss calculation for target: 0.011757850646972656
Time for Loss backward: 1.787172555923462
Time needed for the batch 2.901195526123047
Time needed for logging 0.00720977783203125
Training epoch 0 | batch 145
Batch on Device 0 computed in 0.741013765335083 seconds.
tensor([0.5444], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543548583984375
Time for loss calculation for target: 0.011797189712524414
Time for Loss backward: 1.7902770042419434
Time needed for the batch 2.9060404300689697
Time needed for logging 0.007105588912963867
Training epoch 0 | batch 146
Batch on Device 0 computed in 0.739753246307373 seconds.
tensor([0.7370], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440492630004883
Time for loss calculation for target: 0.012063026428222656
Time for Loss backward: 1.7862606048583984
Time needed for the batch 2.900670289993286
Time needed for logging 0.0071773529052734375
Training epoch 0 | batch 147
Batch on Device 0 computed in 0.7433779239654541 seconds.
tensor([0.9654], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544270992279053
Time for loss calculation for target: 0.011777162551879883
Time for Loss backward: 1.7874014377593994
Time needed for the batch 2.9050371646881104
Time needed for logging 0.007184267044067383
Training epoch 0 | batch 148
Batch on Device 0 computed in 0.7398364543914795 seconds.
tensor([0.4866], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544483184814453
Time for loss calculation for target: 0.011815547943115234
Time for Loss backward: 1.7894136905670166
Time needed for the batch 2.9033327102661133
Time needed for logging 0.007169008255004883
Training epoch 0 | batch 149
Batch on Device 0 computed in 0.7399373054504395 seconds.
tensor([0.3776], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543813228607178
Time for loss calculation for target: 0.011729717254638672
Time for Loss backward: 1.7898938655853271
Time needed for the batch 2.903975009918213
Time needed for logging 0.007094860076904297
Training epoch 0 | batch 150
Batch on Device 0 computed in 0.740044116973877 seconds.
tensor([0.6078], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543214797973633
Time for loss calculation for target: 0.012101411819458008
Time for Loss backward: 1.7840051651000977
Time needed for the batch 2.898386001586914
Time needed for logging 0.007138967514038086
Training epoch 0 | batch 151
Batch on Device 0 computed in 0.7428867816925049 seconds.
tensor([0.7309], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35489916801452637
Time for loss calculation for target: 0.011946678161621094
Time for Loss backward: 1.7897777557373047
Time needed for the batch 2.9075021743774414
Time needed for logging 0.007363557815551758
Training epoch 0 | batch 152
Batch on Device 0 computed in 0.7395756244659424 seconds.
tensor([0.4379], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544645309448242
Time for loss calculation for target: 0.011932373046875
Time for Loss backward: 1.7901368141174316
Time needed for the batch 2.90409779548645
Time needed for logging 0.007061004638671875
Training epoch 0 | batch 153
Batch on Device 0 computed in 0.739762544631958 seconds.
tensor([0.4525], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543272018432617
Time for loss calculation for target: 0.011818885803222656
Time for Loss backward: 1.7900564670562744
Time needed for the batch 2.9039206504821777
Time needed for logging 0.007280588150024414
Training epoch 0 | batch 154
Batch on Device 0 computed in 0.739675760269165 seconds.
tensor([0.3583], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434818267822266
Time for loss calculation for target: 0.011584758758544922
Time for Loss backward: 1.7874994277954102
Time needed for the batch 2.9009854793548584
Time needed for logging 0.0071258544921875
Training epoch 0 | batch 155
Batch on Device 0 computed in 0.7398638725280762 seconds.
tensor([0.4937], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547837734222412
Time for loss calculation for target: 0.01182699203491211
Time for Loss backward: 1.7902398109436035
Time needed for the batch 2.904620409011841
Time needed for logging 0.007169485092163086
Training epoch 0 | batch 156
Batch on Device 0 computed in 0.740117073059082 seconds.
tensor([0.4610], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35492396354675293
Time for loss calculation for target: 0.01201486587524414
Time for Loss backward: 1.7889699935913086
Time needed for the batch 2.9038002490997314
Time needed for logging 0.007170915603637695
Training epoch 0 | batch 157
Batch on Device 0 computed in 0.7399039268493652 seconds.
tensor([0.3840], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439038276672363
Time for loss calculation for target: 0.011718034744262695
Time for Loss backward: 1.7883107662200928
Time needed for the batch 2.9022600650787354
Time needed for logging 0.0070765018463134766
Training epoch 0 | batch 158
Batch on Device 0 computed in 0.7445816993713379 seconds.
tensor([0.7373], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436391830444336
Time for loss calculation for target: 0.011657953262329102
Time for Loss backward: 1.7837669849395752
Time needed for the batch 2.9259204864501953
Time needed for logging 0.007297992706298828
Training epoch 0 | batch 159
Batch on Device 0 computed in 0.742835283279419 seconds.
tensor([0.8934], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543858528137207
Time for loss calculation for target: 0.011905193328857422
Time for Loss backward: 1.7874584197998047
Time needed for the batch 2.9049980640411377
Time needed for logging 0.007120609283447266
Training epoch 0 | batch 160
Batch on Device 0 computed in 0.7398338317871094 seconds.
tensor([0.4124], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543875217437744
Time for loss calculation for target: 0.011731863021850586
Time for Loss backward: 1.7845580577850342
Time needed for the batch 2.8984227180480957
Time needed for logging 0.007135868072509766
Training epoch 0 | batch 161
Batch on Device 0 computed in 0.7442593574523926 seconds.
tensor([0.6938], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433435440063477
Time for loss calculation for target: 0.01178598403930664
Time for Loss backward: 1.784555435180664
Time needed for the batch 2.9033913612365723
Time needed for logging 0.0071125030517578125
Training epoch 0 | batch 162
Batch on Device 0 computed in 0.7430994510650635 seconds.
tensor([0.3712], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35431647300720215
Time for loss calculation for target: 0.011803150177001953
Time for Loss backward: 1.7897989749908447
Time needed for the batch 2.9067859649658203
Time needed for logging 0.00703120231628418
Training epoch 0 | batch 163
Batch on Device 0 computed in 0.7397258281707764 seconds.
tensor([0.4327], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543250560760498
Time for loss calculation for target: 0.011822223663330078
Time for Loss backward: 1.7878117561340332
Time needed for the batch 2.9015164375305176
Time needed for logging 0.0073375701904296875
Training epoch 0 | batch 164
Batch on Device 0 computed in 0.7400062084197998 seconds.
tensor([0.6125], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442233085632324
Time for loss calculation for target: 0.011776447296142578
Time for Loss backward: 1.7853105068206787
Time needed for the batch 2.899400472640991
Time needed for logging 0.006897449493408203
Training epoch 0 | batch 165
Batch on Device 0 computed in 0.7453610897064209 seconds.
tensor([0.4143], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544447422027588
Time for loss calculation for target: 0.011743307113647461
Time for Loss backward: 1.7899892330169678
Time needed for the batch 2.90920352935791
Time needed for logging 0.007024288177490234
Training epoch 0 | batch 166
Batch on Device 0 computed in 0.7410321235656738 seconds.
tensor([0.6397], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436081886291504
Time for loss calculation for target: 0.011773347854614258
Time for Loss backward: 1.790705919265747
Time needed for the batch 2.905407428741455
Time needed for logging 0.0070040225982666016
Training epoch 0 | batch 167
Batch on Device 0 computed in 0.7398202419281006 seconds.
tensor([0.4295], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543221950531006
Time for loss calculation for target: 0.011788129806518555
Time for Loss backward: 1.7869899272918701
Time needed for the batch 2.900730609893799
Time needed for logging 0.0068585872650146484
Training epoch 0 | batch 168
Batch on Device 0 computed in 0.7398495674133301 seconds.
tensor([0.4769], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3548858165740967
Time for loss calculation for target: 0.01196599006652832
Time for Loss backward: 1.8526086807250977
Time needed for the batch 2.9669835567474365
Time needed for logging 0.007010936737060547
Training epoch 0 | batch 169
Batch on Device 0 computed in 0.7398467063903809 seconds.
tensor([0.5596], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436177253723145
Time for loss calculation for target: 0.011718988418579102
Time for Loss backward: 1.7881207466125488
Time needed for the batch 2.9015281200408936
Time needed for logging 0.00707244873046875
Training epoch 0 | batch 170
Batch on Device 0 computed in 0.7398629188537598 seconds.
tensor([0.4395], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437440872192383
Time for loss calculation for target: 0.011774778366088867
Time for Loss backward: 1.7903344631195068
Time needed for the batch 2.904353380203247
Time needed for logging 0.0070493221282958984
Training epoch 0 | batch 171
Batch on Device 0 computed in 0.7399981021881104 seconds.
tensor([0.2383], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354372501373291
Time for loss calculation for target: 0.011790752410888672
Time for Loss backward: 1.7900793552398682
Time needed for the batch 2.9040780067443848
Time needed for logging 0.007086992263793945
Training epoch 0 | batch 172
Batch on Device 0 computed in 0.7397489547729492 seconds.
tensor([0.3995], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543868064880371
Time for loss calculation for target: 0.011731624603271484
Time for Loss backward: 1.7860713005065918
Time needed for the batch 2.899726390838623
Time needed for logging 0.00711512565612793
Training epoch 0 | batch 173
Batch on Device 0 computed in 0.7434003353118896 seconds.
tensor([0.4739], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434794425964355
Time for loss calculation for target: 0.011780500411987305
Time for Loss backward: 1.791029930114746
Time needed for the batch 2.908102512359619
Time needed for logging 0.007117271423339844
Training epoch 0 | batch 174
Batch on Device 0 computed in 0.7400758266448975 seconds.
tensor([0.3097], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544158935546875
Time for loss calculation for target: 0.011732339859008789
Time for Loss backward: 1.7914447784423828
Time needed for the batch 2.9055511951446533
Time needed for logging 0.007202863693237305
Training epoch 0 | batch 175
Batch on Device 0 computed in 0.7399864196777344 seconds.
tensor([0.1850], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443663597106934
Time for loss calculation for target: 0.011997699737548828
Time for Loss backward: 1.7897675037384033
Time needed for the batch 2.9040188789367676
Time needed for logging 0.007172346115112305
Training epoch 0 | batch 176
Batch on Device 0 computed in 0.7398173809051514 seconds.
tensor([1.0934], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544132709503174
Time for loss calculation for target: 0.01180887222290039
Time for Loss backward: 1.7861628532409668
Time needed for the batch 2.9000766277313232
Time needed for logging 0.007131338119506836
Training epoch 0 | batch 177
Batch on Device 0 computed in 0.7438700199127197 seconds.
tensor([0.4823], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543667793273926
Time for loss calculation for target: 0.011756420135498047
Time for Loss backward: 1.7857170104980469
Time needed for the batch 2.903494358062744
Time needed for logging 0.0072154998779296875
Training epoch 0 | batch 178
Batch on Device 0 computed in 0.7445752620697021 seconds.
tensor([1.1184], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354400634765625
Time for loss calculation for target: 0.011714935302734375
Time for Loss backward: 1.7915809154510498
Time needed for the batch 2.910224676132202
Time needed for logging 0.007136344909667969
Training epoch 0 | batch 179
Batch on Device 0 computed in 0.7402453422546387 seconds.
tensor([0.5407], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544776439666748
Time for loss calculation for target: 0.011803388595581055
Time for Loss backward: 1.7898032665252686
Time needed for the batch 2.904165744781494
Time needed for logging 0.007017850875854492
Training epoch 0 | batch 180
Batch on Device 0 computed in 0.7422118186950684 seconds.
tensor([0.5562], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547096252441406
Time for loss calculation for target: 0.012008190155029297
Time for Loss backward: 1.7908101081848145
Time needed for the batch 2.9079360961914062
Time needed for logging 0.007196903228759766
Training epoch 0 | batch 181
Batch on Device 0 computed in 0.7398467063903809 seconds.
tensor([0.5631], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439085960388184
Time for loss calculation for target: 0.011849641799926758
Time for Loss backward: 1.7915325164794922
Time needed for the batch 2.905513048171997
Time needed for logging 0.007081508636474609
Training epoch 0 | batch 182
Batch on Device 0 computed in 0.7401306629180908 seconds.
tensor([0.4859], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544156551361084
Time for loss calculation for target: 0.011764287948608398
Time for Loss backward: 1.7908482551574707
Time needed for the batch 2.904944658279419
Time needed for logging 0.006905555725097656
Training epoch 0 | batch 183
Batch on Device 0 computed in 0.7400155067443848 seconds.
tensor([0.8469], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544149398803711
Time for loss calculation for target: 0.011757135391235352
Time for Loss backward: 1.7893249988555908
Time needed for the batch 2.903418779373169
Time needed for logging 0.006974935531616211
Training epoch 0 | batch 184
Batch on Device 0 computed in 0.7402710914611816 seconds.
tensor([0.8291], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443758964538574
Time for loss calculation for target: 0.011770009994506836
Time for Loss backward: 1.7868988513946533
Time needed for the batch 2.901296615600586
Time needed for logging 0.007151603698730469
Training epoch 0 | batch 185
Batch on Device 0 computed in 0.7429208755493164 seconds.
tensor([0.4195], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437488555908203
Time for loss calculation for target: 0.011790275573730469
Time for Loss backward: 1.7858424186706543
Time needed for the batch 2.9027950763702393
Time needed for logging 0.007181882858276367
Training epoch 0 | batch 186
Batch on Device 0 computed in 0.7439806461334229 seconds.
tensor([0.4861], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441040992736816
Time for loss calculation for target: 0.01188349723815918
Time for Loss backward: 1.785266399383545
Time needed for the batch 2.903554677963257
Time needed for logging 0.0069732666015625
Training epoch 0 | batch 187
Batch on Device 0 computed in 0.7451081275939941 seconds.
tensor([0.6725], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441160202026367
Time for loss calculation for target: 0.011772394180297852
Time for Loss backward: 1.7844016551971436
Time needed for the batch 2.903103828430176
Time needed for logging 0.006498098373413086
Training epoch 0 | batch 188
Batch on Device 0 computed in 0.7432358264923096 seconds.
tensor([0.5024], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543891906738281
Time for loss calculation for target: 0.011839151382446289
Time for Loss backward: 1.7949597835540771
Time needed for the batch 2.9137375354766846
Time needed for logging 0.006217479705810547
Training epoch 0 | batch 189
Batch on Device 0 computed in 0.7444722652435303 seconds.
tensor([0.5857], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3548872470855713
Time for loss calculation for target: 0.012032508850097656
Time for Loss backward: 1.7896950244903564
Time needed for the batch 2.9091124534606934
Time needed for logging 0.006361484527587891
Training epoch 0 | batch 190
Batch on Device 0 computed in 0.7397665977478027 seconds.
tensor([0.2252], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434770584106445
Time for loss calculation for target: 0.011780977249145508
Time for Loss backward: 1.7897725105285645
Time needed for the batch 2.903703212738037
Time needed for logging 0.007251262664794922
Training epoch 0 | batch 191
Batch on Device 0 computed in 0.73988938331604 seconds.
tensor([0.5440], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3550295829772949
Time for loss calculation for target: 0.012041330337524414
Time for Loss backward: 1.7899634838104248
Time needed for the batch 2.9049651622772217
Time needed for logging 0.00734710693359375
Training epoch 0 | batch 192
Batch on Device 0 computed in 0.739823579788208 seconds.
tensor([0.3986], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543891906738281
Time for loss calculation for target: 0.011813640594482422
Time for Loss backward: 1.7923917770385742
Time needed for the batch 2.906566858291626
Time needed for logging 0.007053375244140625
Training epoch 0 | batch 193
Batch on Device 0 computed in 0.7398910522460938 seconds.
tensor([0.6661], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544430732727051
Time for loss calculation for target: 0.011754035949707031
Time for Loss backward: 1.7905094623565674
Time needed for the batch 2.904658079147339
Time needed for logging 0.007208347320556641
Training epoch 0 | batch 194
Batch on Device 0 computed in 0.7399716377258301 seconds.
tensor([0.3603], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544437885284424
Time for loss calculation for target: 0.011813640594482422
Time for Loss backward: 1.7915499210357666
Time needed for the batch 2.905799150466919
Time needed for logging 0.0072650909423828125
Training epoch 0 | batch 195
Batch on Device 0 computed in 0.7400493621826172 seconds.
tensor([0.3714], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445237159729004
Time for loss calculation for target: 0.011721134185791016
Time for Loss backward: 1.790205955505371
Time needed for the batch 2.904242753982544
Time needed for logging 0.007262468338012695
Training epoch 0 | batch 196
Batch on Device 0 computed in 0.739811897277832 seconds.
tensor([0.4511], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439419746398926
Time for loss calculation for target: 0.011918783187866211
Time for Loss backward: 1.7898483276367188
Time needed for the batch 2.903938055038452
Time needed for logging 0.00722503662109375
Training epoch 0 | batch 197
Batch on Device 0 computed in 0.7400031089782715 seconds.
tensor([0.3664], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443687438964844
Time for loss calculation for target: 0.011773824691772461
Time for Loss backward: 1.7907288074493408
Time needed for the batch 2.905050039291382
Time needed for logging 0.0072231292724609375
Training epoch 0 | batch 198
Batch on Device 0 computed in 0.739990234375 seconds.
tensor([0.6577], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445690155029297
Time for loss calculation for target: 0.01182699203491211
Time for Loss backward: 1.7900009155273438
Time needed for the batch 2.9042789936065674
Time needed for logging 0.0070323944091796875
Training epoch 0 | batch 199
Batch on Device 0 computed in 0.7399320602416992 seconds.
tensor([0.3995], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439014434814453
Time for loss calculation for target: 0.0117645263671875
Time for Loss backward: 1.7895331382751465
Time needed for the batch 2.903714895248413
Time needed for logging 0.007126331329345703
Training epoch 0 | batch 200
Batch on Device 0 computed in 0.7398850917816162 seconds.
tensor([0.9297], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439062118530273
Time for loss calculation for target: 0.012403011322021484
Time for Loss backward: 1.7860543727874756
Time needed for the batch 2.900726079940796
Time needed for logging 0.00732111930847168
Training epoch 0 | batch 201
Batch on Device 0 computed in 0.7420516014099121 seconds.
tensor([0.4389], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547401428222656
Time for loss calculation for target: 0.011968612670898438
Time for Loss backward: 1.790069580078125
Time needed for the batch 2.908130645751953
Time needed for logging 0.007167816162109375
Training epoch 0 | batch 202
Batch on Device 0 computed in 0.7399420738220215 seconds.
tensor([0.2296], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547630310058594
Time for loss calculation for target: 0.011932611465454102
Time for Loss backward: 1.7844834327697754
Time needed for the batch 2.8991847038269043
Time needed for logging 0.0072858333587646484
Training epoch 0 | batch 203
Batch on Device 0 computed in 0.7440927028656006 seconds.
tensor([0.5588], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35466790199279785
Time for loss calculation for target: 0.011908292770385742
Time for Loss backward: 1.7903721332550049
Time needed for the batch 2.909359931945801
Time needed for logging 0.007614612579345703
Training epoch 0 | batch 204
Batch on Device 0 computed in 0.7400782108306885 seconds.
tensor([0.4721], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3549835681915283
Time for loss calculation for target: 0.012331724166870117
Time for Loss backward: 1.7893173694610596
Time needed for the batch 2.9051730632781982
Time needed for logging 0.0070302486419677734
Training epoch 0 | batch 205
Batch on Device 0 computed in 0.740302562713623 seconds.
tensor([0.3964], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35432910919189453
Time for loss calculation for target: 0.011681079864501953
Time for Loss backward: 1.7906746864318848
Time needed for the batch 2.905017852783203
Time needed for logging 0.006525754928588867
Training epoch 0 | batch 206
Batch on Device 0 computed in 0.7400741577148438 seconds.
tensor([0.5083], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545093536376953
Time for loss calculation for target: 0.01175236701965332
Time for Loss backward: 1.7847020626068115
Time needed for the batch 2.8988800048828125
Time needed for logging 0.006489276885986328
Training epoch 0 | batch 207
Batch on Device 0 computed in 0.7458422183990479 seconds.
tensor([0.6656], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354386568069458
Time for loss calculation for target: 0.011947870254516602
Time for Loss backward: 1.7916085720062256
Time needed for the batch 2.911451816558838
Time needed for logging 0.006729841232299805
Training epoch 0 | batch 208
Batch on Device 0 computed in 0.7399988174438477 seconds.
tensor([0.5333], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544459342956543
Time for loss calculation for target: 0.011825084686279297
Time for Loss backward: 1.7836222648620605
Time needed for the batch 2.8973710536956787
Time needed for logging 0.006523847579956055
Training epoch 0 | batch 209
Batch on Device 0 computed in 0.7453150749206543 seconds.
tensor([0.4840], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35438966751098633
Time for loss calculation for target: 0.011785030364990234
Time for Loss backward: 1.7851872444152832
Time needed for the batch 2.905308723449707
Time needed for logging 0.006531715393066406
Training epoch 0 | batch 210
Batch on Device 0 computed in 0.7454805374145508 seconds.
tensor([0.3882], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3550276756286621
Time for loss calculation for target: 0.012022018432617188
Time for Loss backward: 1.7832090854644775
Time needed for the batch 2.9042861461639404
Time needed for logging 0.006732940673828125
Training epoch 0 | batch 211
Batch on Device 0 computed in 0.7462449073791504 seconds.
tensor([0.6826], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448646545410156
Time for loss calculation for target: 0.011844158172607422
Time for Loss backward: 1.7869760990142822
Time needed for the batch 2.907484292984009
Time needed for logging 0.00662994384765625
Training epoch 0 | batch 212
Batch on Device 0 computed in 0.7414562702178955 seconds.
tensor([0.4615], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544352054595947
Time for loss calculation for target: 0.011826753616333008
Time for Loss backward: 1.7842347621917725
Time needed for the batch 2.8994626998901367
Time needed for logging 0.006568193435668945
Training epoch 0 | batch 213
Batch on Device 0 computed in 0.744574785232544 seconds.
tensor([1.1886], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35462141036987305
Time for loss calculation for target: 0.011824846267700195
Time for Loss backward: 1.786240577697754
Time needed for the batch 2.90592622756958
Time needed for logging 0.006541728973388672
Training epoch 0 | batch 214
Batch on Device 0 computed in 0.7438182830810547 seconds.
tensor([0.2143], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543539047241211
Time for loss calculation for target: 0.01244664192199707
Time for Loss backward: 1.7903552055358887
Time needed for the batch 2.9097204208374023
Time needed for logging 0.006473064422607422
Training epoch 0 | batch 215
Batch on Device 0 computed in 0.7399275302886963 seconds.
tensor([0.2119], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443639755249023
Time for loss calculation for target: 0.01168370246887207
Time for Loss backward: 1.7892723083496094
Time needed for the batch 2.9030065536499023
Time needed for logging 0.006833076477050781
Training epoch 0 | batch 216
Batch on Device 0 computed in 0.7400634288787842 seconds.
tensor([0.4499], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354445219039917
Time for loss calculation for target: 0.011804580688476562
Time for Loss backward: 1.7878291606903076
Time needed for the batch 2.9020633697509766
Time needed for logging 0.006814479827880859
Training epoch 0 | batch 217
Batch on Device 0 computed in 0.7409143447875977 seconds.
tensor([0.5101], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544790744781494
Time for loss calculation for target: 0.01191258430480957
Time for Loss backward: 1.7871670722961426
Time needed for the batch 2.9019575119018555
Time needed for logging 0.007241010665893555
Training epoch 0 | batch 218
Batch on Device 0 computed in 0.7425744533538818 seconds.
tensor([0.7880], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443854331970215
Time for loss calculation for target: 0.011766910552978516
Time for Loss backward: 1.791619062423706
Time needed for the batch 2.9085159301757812
Time needed for logging 0.006928682327270508
Training epoch 0 | batch 219
Batch on Device 0 computed in 0.7399611473083496 seconds.
tensor([0.2485], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543739318847656
Time for loss calculation for target: 0.011781692504882812
Time for Loss backward: 1.788647174835205
Time needed for the batch 2.9024641513824463
Time needed for logging 0.006512641906738281
Training epoch 0 | batch 220
Batch on Device 0 computed in 0.7432279586791992 seconds.
tensor([0.7502], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543965816497803
Time for loss calculation for target: 0.0119476318359375
Time for Loss backward: 1.7831733226776123
Time needed for the batch 2.9011292457580566
Time needed for logging 0.006890058517456055
Training epoch 0 | batch 221
Batch on Device 0 computed in 0.743798017501831 seconds.
tensor([0.6137], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543875217437744
Time for loss calculation for target: 0.01182866096496582
Time for Loss backward: 1.7823553085327148
Time needed for the batch 2.9003031253814697
Time needed for logging 0.006611824035644531
Training epoch 0 | batch 222
Batch on Device 0 computed in 0.74458909034729 seconds.
tensor([0.1471], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543064594268799
Time for loss calculation for target: 0.011817216873168945
Time for Loss backward: 1.7837550640106201
Time needed for the batch 2.9023075103759766
Time needed for logging 0.0064547061920166016
Training epoch 0 | batch 223
Batch on Device 0 computed in 0.7469058036804199 seconds.
tensor([0.7433], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35384392738342285
Time for loss calculation for target: 0.011871337890625
Time for Loss backward: 1.7915618419647217
Time needed for the batch 2.9125921726226807
Time needed for logging 0.007149934768676758
Training epoch 0 | batch 224
Batch on Device 0 computed in 0.7399029731750488 seconds.
tensor([1.3479], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543260097503662
Time for loss calculation for target: 0.011740922927856445
Time for Loss backward: 1.7903943061828613
Time needed for the batch 2.9043428897857666
Time needed for logging 0.0072710514068603516
Training epoch 0 | batch 225
Batch on Device 0 computed in 0.7399654388427734 seconds.
tensor([0.8429], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544135093688965
Time for loss calculation for target: 0.011730670928955078
Time for Loss backward: 1.7894744873046875
Time needed for the batch 2.9036028385162354
Time needed for logging 0.007225751876831055
Training epoch 0 | batch 226
Batch on Device 0 computed in 0.739891767501831 seconds.
tensor([0.5366], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440778732299805
Time for loss calculation for target: 0.011763572692871094
Time for Loss backward: 1.7904419898986816
Time needed for the batch 2.904738664627075
Time needed for logging 0.007158994674682617
Training epoch 0 | batch 227
Batch on Device 0 computed in 0.739739179611206 seconds.
tensor([0.4949], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543541431427002
Time for loss calculation for target: 0.011765718460083008
Time for Loss backward: 1.7848567962646484
Time needed for the batch 2.8985722064971924
Time needed for logging 0.007121562957763672
Training epoch 0 | batch 228
Batch on Device 0 computed in 0.7422380447387695 seconds.
tensor([0.5091], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544321060180664
Time for loss calculation for target: 0.011783599853515625
Time for Loss backward: 1.790950059890747
Time needed for the batch 2.9074690341949463
Time needed for logging 0.007154703140258789
Training epoch 0 | batch 229
Batch on Device 0 computed in 0.7400152683258057 seconds.
tensor([0.5332], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442519187927246
Time for loss calculation for target: 0.011822938919067383
Time for Loss backward: 1.7908313274383545
Time needed for the batch 2.9049627780914307
Time needed for logging 0.007127523422241211
Training epoch 0 | batch 230
Batch on Device 0 computed in 0.7419795989990234 seconds.
tensor([0.3347], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445094108581543
Time for loss calculation for target: 0.011811017990112305
Time for Loss backward: 1.7839763164520264
Time needed for the batch 2.900222063064575
Time needed for logging 0.0072252750396728516
Training epoch 0 | batch 231
Batch on Device 0 computed in 0.7430005073547363 seconds.
tensor([0.4389], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442566871643066
Time for loss calculation for target: 0.011861085891723633
Time for Loss backward: 1.788893222808838
Time needed for the batch 2.9062094688415527
Time needed for logging 0.007198333740234375
Training epoch 0 | batch 232
Batch on Device 0 computed in 0.7399032115936279 seconds.
tensor([0.4351], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.355057954788208
Time for loss calculation for target: 0.012009859085083008
Time for Loss backward: 1.7901315689086914
Time needed for the batch 2.9058263301849365
Time needed for logging 0.007026195526123047
Training epoch 0 | batch 233
Batch on Device 0 computed in 0.739832878112793 seconds.
tensor([0.4069], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439586639404297
Time for loss calculation for target: 0.011723995208740234
Time for Loss backward: 1.7868549823760986
Time needed for the batch 2.90081787109375
Time needed for logging 0.006898164749145508
Training epoch 0 | batch 234
Batch on Device 0 computed in 0.7441344261169434 seconds.
tensor([0.3343], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544600009918213
Time for loss calculation for target: 0.011715888977050781
Time for Loss backward: 1.7868704795837402
Time needed for the batch 2.904874563217163
Time needed for logging 0.00728607177734375
Training epoch 0 | batch 235
Batch on Device 0 computed in 0.743750810623169 seconds.
tensor([0.3479], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441136360168457
Time for loss calculation for target: 0.011678695678710938
Time for Loss backward: 1.785529375076294
Time needed for the batch 2.903357744216919
Time needed for logging 0.007500886917114258
Training epoch 0 | batch 236
Batch on Device 0 computed in 0.7434816360473633 seconds.
tensor([0.4776], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445690155029297
Time for loss calculation for target: 0.011735916137695312
Time for Loss backward: 1.7850298881530762
Time needed for the batch 2.902738571166992
Time needed for logging 0.0077016353607177734
Training epoch 0 | batch 237
Batch on Device 0 computed in 0.7443673610687256 seconds.
tensor([0.9416], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439348220825195
Time for loss calculation for target: 0.012400150299072266
Time for Loss backward: 1.7849276065826416
Time needed for the batch 2.9043023586273193
Time needed for logging 0.007306814193725586
Training epoch 0 | batch 238
Batch on Device 0 computed in 0.7440276145935059 seconds.
tensor([0.4636], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35454821586608887
Time for loss calculation for target: 0.011791229248046875
Time for Loss backward: 1.7851648330688477
Time needed for the batch 2.903620481491089
Time needed for logging 0.007304668426513672
Training epoch 0 | batch 239
Batch on Device 0 computed in 0.7424745559692383 seconds.
tensor([0.4870], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544442653656006
Time for loss calculation for target: 0.011649608612060547
Time for Loss backward: 1.7863974571228027
Time needed for the batch 2.902848482131958
Time needed for logging 0.007302761077880859
Training epoch 0 | batch 240
Batch on Device 0 computed in 0.7420921325683594 seconds.
tensor([0.4570], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544342517852783
Time for loss calculation for target: 0.011705875396728516
Time for Loss backward: 1.7910854816436768
Time needed for the batch 2.907299280166626
Time needed for logging 0.007480144500732422
Training epoch 0 | batch 241
Batch on Device 0 computed in 0.7399945259094238 seconds.
tensor([0.8751], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3542921543121338
Time for loss calculation for target: 0.012035369873046875
Time for Loss backward: 1.78928542137146
Time needed for the batch 2.9037551879882812
Time needed for logging 0.007329702377319336
Training epoch 0 | batch 242
Batch on Device 0 computed in 0.7432363033294678 seconds.
tensor([0.6037], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544118404388428
Time for loss calculation for target: 0.011685848236083984
Time for Loss backward: 1.785470962524414
Time needed for the batch 2.9031951427459717
Time needed for logging 0.007213592529296875
Training epoch 0 | batch 243
Batch on Device 0 computed in 0.7443592548370361 seconds.
tensor([0.8769], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437679290771484
Time for loss calculation for target: 0.011672019958496094
Time for Loss backward: 1.7865910530090332
Time needed for the batch 2.9053192138671875
Time needed for logging 0.007340908050537109
Training epoch 0 | batch 244
Batch on Device 0 computed in 0.744518518447876 seconds.
tensor([0.4956], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443782806396484
Time for loss calculation for target: 0.011645078659057617
Time for Loss backward: 1.7880022525787354
Time needed for the batch 2.9065499305725098
Time needed for logging 0.007241487503051758
Training epoch 0 | batch 245
Batch on Device 0 computed in 0.7429196834564209 seconds.
tensor([0.6142], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433125495910645
Time for loss calculation for target: 0.012081146240234375
Time for Loss backward: 1.7902202606201172
Time needed for the batch 2.907510995864868
Time needed for logging 0.007349491119384766
Training epoch 0 | batch 246
Batch on Device 0 computed in 0.740058183670044 seconds.
tensor([0.3631], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35435938835144043
Time for loss calculation for target: 0.011696100234985352
Time for Loss backward: 1.7868993282318115
Time needed for the batch 2.900968074798584
Time needed for logging 0.007270336151123047
Training epoch 0 | batch 247
Batch on Device 0 computed in 0.7426774501800537 seconds.
tensor([0.4663], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439181327819824
Time for loss calculation for target: 0.011785745620727539
Time for Loss backward: 1.789926528930664
Time needed for the batch 2.9067771434783936
Time needed for logging 0.007239341735839844
Training epoch 0 | batch 248
Batch on Device 0 computed in 0.7401018142700195 seconds.
tensor([0.4516], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440564155578613
Time for loss calculation for target: 0.011661767959594727
Time for Loss backward: 1.791252613067627
Time needed for the batch 2.90558123588562
Time needed for logging 0.0072710514068603516
Training epoch 0 | batch 249
Batch on Device 0 computed in 0.7399909496307373 seconds.
tensor([0.3270], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35444188117980957
Time for loss calculation for target: 0.011982917785644531
Time for Loss backward: 1.7884976863861084
Time needed for the batch 2.9028844833374023
Time needed for logging 0.007269620895385742
Training epoch 0 | batch 250
Batch on Device 0 computed in 0.7450268268585205 seconds.
tensor([0.4134], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544037342071533
Time for loss calculation for target: 0.011738777160644531
Time for Loss backward: 1.7859039306640625
Time needed for the batch 2.9050686359405518
Time needed for logging 0.00751042366027832
Training epoch 0 | batch 251
Batch on Device 0 computed in 0.7425034046173096 seconds.
tensor([0.6080], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442018508911133
Time for loss calculation for target: 0.011815786361694336
Time for Loss backward: 1.7881193161010742
Time needed for the batch 2.9049277305603027
Time needed for logging 0.007234334945678711
Training epoch 0 | batch 252
Batch on Device 0 computed in 0.7414524555206299 seconds.
tensor([0.7303], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544454574584961
Time for loss calculation for target: 0.011707067489624023
Time for Loss backward: 1.7884340286254883
Time needed for the batch 2.904045820236206
Time needed for logging 0.0073359012603759766
Training epoch 0 | batch 253
Batch on Device 0 computed in 0.7419946193695068 seconds.
tensor([1.0080], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544278144836426
Time for loss calculation for target: 0.011975526809692383
Time for Loss backward: 1.7898156642913818
Time needed for the batch 2.9063618183135986
Time needed for logging 0.007230043411254883
Training epoch 0 | batch 254
Batch on Device 0 computed in 0.7400102615356445 seconds.
tensor([0.4601], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546011447906494
Time for loss calculation for target: 0.011950969696044922
Time for Loss backward: 1.7876641750335693
Time needed for the batch 2.9025721549987793
Time needed for logging 0.007251739501953125
Training epoch 0 | batch 255
Batch on Device 0 computed in 0.7399942874908447 seconds.
tensor([0.5744], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543870449066162
Time for loss calculation for target: 0.011682748794555664
Time for Loss backward: 1.789750576019287
Time needed for the batch 2.9039621353149414
Time needed for logging 0.0073282718658447266
Training epoch 0 | batch 256
Batch on Device 0 computed in 0.7399320602416992 seconds.
tensor([0.7354], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35444211959838867
Time for loss calculation for target: 0.011641979217529297
Time for Loss backward: 1.7859995365142822
Time needed for the batch 2.899976968765259
Time needed for logging 0.0072536468505859375
Training epoch 0 | batch 257
Batch on Device 0 computed in 0.7435238361358643 seconds.
tensor([0.7482], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35451579093933105
Time for loss calculation for target: 0.011684656143188477
Time for Loss backward: 1.7853929996490479
Time needed for the batch 2.90311336517334
Time needed for logging 0.007302284240722656
Training epoch 0 | batch 258
Batch on Device 0 computed in 0.7442035675048828 seconds.
tensor([0.5527], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439229011535645
Time for loss calculation for target: 0.01176142692565918
Time for Loss backward: 1.7908048629760742
Time needed for the batch 2.9091238975524902
Time needed for logging 0.007225513458251953
Training epoch 0 | batch 259
Batch on Device 0 computed in 0.7401947975158691 seconds.
tensor([0.5013], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544330596923828
Time for loss calculation for target: 0.011647701263427734
Time for Loss backward: 1.7904973030090332
Time needed for the batch 2.904750108718872
Time needed for logging 0.007284879684448242
Training epoch 0 | batch 260
Batch on Device 0 computed in 0.7399656772613525 seconds.
tensor([0.6082], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544325828552246
Time for loss calculation for target: 0.011740922927856445
Time for Loss backward: 1.7860722541809082
Time needed for the batch 2.9001638889312744
Time needed for logging 0.0073163509368896484
Training epoch 0 | batch 261
Batch on Device 0 computed in 0.7430689334869385 seconds.
tensor([0.7815], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544602394104004
Time for loss calculation for target: 0.011681079864501953
Time for Loss backward: 1.783719778060913
Time needed for the batch 2.900921583175659
Time needed for logging 0.0072748661041259766
Training epoch 0 | batch 262
Batch on Device 0 computed in 0.7433571815490723 seconds.
tensor([1.0446], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543581962585449
Time for loss calculation for target: 0.011713743209838867
Time for Loss backward: 1.7912819385528564
Time needed for the batch 2.908907651901245
Time needed for logging 0.0072956085205078125
Training epoch 0 | batch 263
Batch on Device 0 computed in 0.740001916885376 seconds.
tensor([0.4794], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544042110443115
Time for loss calculation for target: 0.011693000793457031
Time for Loss backward: 1.7902069091796875
Time needed for the batch 2.904088020324707
Time needed for logging 0.007280588150024414
Training epoch 0 | batch 264
Batch on Device 0 computed in 0.7400596141815186 seconds.
tensor([0.8066], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544192314147949
Time for loss calculation for target: 0.011747598648071289
Time for Loss backward: 1.7869470119476318
Time needed for the batch 2.9010238647460938
Time needed for logging 0.007296085357666016
Training epoch 0 | batch 265
Batch on Device 0 computed in 0.7422080039978027 seconds.
tensor([0.5539], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544132709503174
Time for loss calculation for target: 0.011657238006591797
Time for Loss backward: 1.7886312007904053
Time needed for the batch 2.9052796363830566
Time needed for logging 0.007338047027587891
Training epoch 0 | batch 266
Batch on Device 0 computed in 0.7433035373687744 seconds.
tensor([0.3587], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544166088104248
Time for loss calculation for target: 0.01168966293334961
Time for Loss backward: 1.7891507148742676
Time needed for the batch 2.9067862033843994
Time needed for logging 0.007264137268066406
Training epoch 0 | batch 267
Batch on Device 0 computed in 0.7400567531585693 seconds.
tensor([0.4576], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544011116027832
Time for loss calculation for target: 0.01171112060546875
Time for Loss backward: 1.789562463760376
Time needed for the batch 2.903614044189453
Time needed for logging 0.007294893264770508
Training epoch 0 | batch 268
Batch on Device 0 computed in 0.7399923801422119 seconds.
tensor([0.7427], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544468879699707
Time for loss calculation for target: 0.01169896125793457
Time for Loss backward: 1.7855291366577148
Time needed for the batch 2.8996200561523438
Time needed for logging 0.007339000701904297
Training epoch 0 | batch 269
Batch on Device 0 computed in 0.7431628704071045 seconds.
tensor([0.3410], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445213317871094
Time for loss calculation for target: 0.011675119400024414
Time for Loss backward: 1.7865924835205078
Time needed for the batch 2.9040887355804443
Time needed for logging 0.007253170013427734
Training epoch 0 | batch 270
Batch on Device 0 computed in 0.7432708740234375 seconds.
tensor([0.5905], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439372062683105
Time for loss calculation for target: 0.08106398582458496
Time for Loss backward: 1.7907028198242188
Time needed for the batch 2.9776549339294434
Time needed for logging 0.007145881652832031
Training epoch 0 | batch 271
Batch on Device 0 computed in 0.7399582862854004 seconds.
tensor([0.5076], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436010360717773
Time for loss calculation for target: 0.011606216430664062
Time for Loss backward: 1.789015769958496
Time needed for the batch 2.9029598236083984
Time needed for logging 0.007139921188354492
Training epoch 0 | batch 272
Batch on Device 0 computed in 0.7401762008666992 seconds.
tensor([0.9804], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448145866394043
Time for loss calculation for target: 0.011677980422973633
Time for Loss backward: 1.7861273288726807
Time needed for the batch 2.900372266769409
Time needed for logging 0.007204294204711914
Training epoch 0 | batch 273
Batch on Device 0 computed in 0.7436656951904297 seconds.
tensor([0.3734], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544578552246094
Time for loss calculation for target: 0.011705398559570312
Time for Loss backward: 1.7848906517028809
Time needed for the batch 2.902545213699341
Time needed for logging 0.007071733474731445
Training epoch 0 | batch 274
Batch on Device 0 computed in 0.7419629096984863 seconds.
tensor([0.4970], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544037342071533
Time for loss calculation for target: 0.01195836067199707
Time for Loss backward: 1.7875943183898926
Time needed for the batch 2.903740167617798
Time needed for logging 0.007186174392700195
Training epoch 0 | batch 275
Batch on Device 0 computed in 0.7399396896362305 seconds.
tensor([0.1968], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434699058532715
Time for loss calculation for target: 0.011680841445922852
Time for Loss backward: 1.790632724761963
Time needed for the batch 2.90446138381958
Time needed for logging 0.007184505462646484
Training epoch 0 | batch 276
Batch on Device 0 computed in 0.7401831150054932 seconds.
tensor([0.8985], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543829917907715
Time for loss calculation for target: 0.011710643768310547
Time for Loss backward: 1.789426326751709
Time needed for the batch 2.9032537937164307
Time needed for logging 0.007206916809082031
Training epoch 0 | batch 277
Batch on Device 0 computed in 0.740330696105957 seconds.
tensor([0.5488], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441112518310547
Time for loss calculation for target: 0.011751174926757812
Time for Loss backward: 1.7867107391357422
Time needed for the batch 2.901087760925293
Time needed for logging 0.007166147232055664
Training epoch 0 | batch 278
Batch on Device 0 computed in 0.742978572845459 seconds.
tensor([0.4995], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543519973754883
Time for loss calculation for target: 0.011690616607666016
Time for Loss backward: 1.7905569076538086
Time needed for the batch 2.907410144805908
Time needed for logging 0.007222175598144531
Training epoch 0 | batch 279
Batch on Device 0 computed in 0.7402429580688477 seconds.
tensor([0.6015], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439443588256836
Time for loss calculation for target: 0.011669635772705078
Time for Loss backward: 1.785954236984253
Time needed for the batch 2.9001340866088867
Time needed for logging 0.007146358489990234
Training epoch 0 | batch 280
Batch on Device 0 computed in 0.7434685230255127 seconds.
tensor([0.5788], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544578552246094
Time for loss calculation for target: 0.011697530746459961
Time for Loss backward: 1.7876403331756592
Time needed for the batch 2.9051594734191895
Time needed for logging 0.007189750671386719
Training epoch 0 | batch 281
Batch on Device 0 computed in 0.7402291297912598 seconds.
tensor([0.6223], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445165634155273
Time for loss calculation for target: 0.011669397354125977
Time for Loss backward: 1.7863855361938477
Time needed for the batch 2.9006950855255127
Time needed for logging 0.007169485092163086
Training epoch 0 | batch 282
Batch on Device 0 computed in 0.743584394454956 seconds.
tensor([0.3733], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35446715354919434
Time for loss calculation for target: 0.01183938980102539
Time for Loss backward: 1.7881402969360352
Time needed for the batch 2.9057042598724365
Time needed for logging 0.0074367523193359375
Training epoch 0 | batch 283
Batch on Device 0 computed in 0.7427399158477783 seconds.
tensor([0.4193], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443758964538574
Time for loss calculation for target: 0.011815547943115234
Time for Loss backward: 1.790313720703125
Time needed for the batch 2.9076037406921387
Time needed for logging 0.007380247116088867
Training epoch 0 | batch 284
Batch on Device 0 computed in 0.7400586605072021 seconds.
tensor([0.4624], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35450148582458496
Time for loss calculation for target: 0.011818647384643555
Time for Loss backward: 1.7860994338989258
Time needed for the batch 2.9001379013061523
Time needed for logging 0.007272958755493164
Training epoch 0 | batch 285
Batch on Device 0 computed in 0.7420446872711182 seconds.
tensor([1.1203], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439372062683105
Time for loss calculation for target: 0.011833906173706055
Time for Loss backward: 1.7933604717254639
Time needed for the batch 2.9102184772491455
Time needed for logging 0.007272005081176758
Training epoch 0 | batch 286
Batch on Device 0 computed in 0.7399518489837646 seconds.
tensor([0.5589], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35449838638305664
Time for loss calculation for target: 0.011797904968261719
Time for Loss backward: 1.7906053066253662
Time needed for the batch 2.904898166656494
Time needed for logging 0.007260560989379883
Training epoch 0 | batch 287
Batch on Device 0 computed in 0.7399601936340332 seconds.
tensor([0.5638], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35428833961486816
Time for loss calculation for target: 0.011750221252441406
Time for Loss backward: 1.7912194728851318
Time needed for the batch 2.905092239379883
Time needed for logging 0.0072858333587646484
Training epoch 0 | batch 288
Batch on Device 0 computed in 0.7399868965148926 seconds.
tensor([0.2339], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445523262023926
Time for loss calculation for target: 0.011777639389038086
Time for Loss backward: 1.7900359630584717
Time needed for the batch 2.904301404953003
Time needed for logging 0.007199764251708984
Training epoch 0 | batch 289
Batch on Device 0 computed in 0.7402184009552002 seconds.
tensor([0.3829], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544487953186035
Time for loss calculation for target: 0.011776924133300781
Time for Loss backward: 1.7927124500274658
Time needed for the batch 2.907282590866089
Time needed for logging 0.007275819778442383
Training epoch 0 | batch 290
Batch on Device 0 computed in 0.7399280071258545 seconds.
tensor([0.5868], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543891906738281
Time for loss calculation for target: 0.011761903762817383
Time for Loss backward: 1.7868118286132812
Time needed for the batch 2.9011175632476807
Time needed for logging 0.007303476333618164
Training epoch 0 | batch 291
Batch on Device 0 computed in 0.7426388263702393 seconds.
tensor([0.4164], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445427894592285
Time for loss calculation for target: 0.011761903762817383
Time for Loss backward: 1.7860422134399414
Time needed for the batch 2.902965784072876
Time needed for logging 0.007357358932495117
Training epoch 0 | batch 292
Batch on Device 0 computed in 0.7432084083557129 seconds.
tensor([0.5514], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544809818267822
Time for loss calculation for target: 0.011742115020751953
Time for Loss backward: 1.7883152961730957
Time needed for the batch 2.905728578567505
Time needed for logging 0.0073587894439697266
Training epoch 0 | batch 293
Batch on Device 0 computed in 0.7398641109466553 seconds.
tensor([0.4613], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437536239624023
Time for loss calculation for target: 0.011714935302734375
Time for Loss backward: 1.7865090370178223
Time needed for the batch 2.9005825519561768
Time needed for logging 0.007264852523803711
Training epoch 0 | batch 294
Batch on Device 0 computed in 0.7422471046447754 seconds.
tensor([1.0547], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543705940246582
Time for loss calculation for target: 0.011813879013061523
Time for Loss backward: 1.7868428230285645
Time needed for the batch 2.903237819671631
Time needed for logging 0.007094383239746094
Training epoch 0 | batch 295
Batch on Device 0 computed in 0.7415459156036377 seconds.
tensor([0.4272], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543834686279297
Time for loss calculation for target: 0.01180577278137207
Time for Loss backward: 1.788947343826294
Time needed for the batch 2.9046332836151123
Time needed for logging 0.007159709930419922
Training epoch 0 | batch 296
Batch on Device 0 computed in 0.7398571968078613 seconds.
tensor([0.5721], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434818267822266
Time for loss calculation for target: 0.011823177337646484
Time for Loss backward: 1.7868306636810303
Time needed for the batch 2.9008336067199707
Time needed for logging 0.0072858333587646484
Training epoch 0 | batch 297
Batch on Device 0 computed in 0.7425954341888428 seconds.
tensor([0.4966], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35431861877441406
Time for loss calculation for target: 0.011711835861206055
Time for Loss backward: 1.7872779369354248
Time needed for the batch 2.90400767326355
Time needed for logging 0.007357597351074219
Training epoch 0 | batch 298
Batch on Device 0 computed in 0.7426934242248535 seconds.
tensor([0.3681], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440492630004883
Time for loss calculation for target: 0.011783599853515625
Time for Loss backward: 1.786559820175171
Time needed for the batch 2.903696060180664
Time needed for logging 0.007199525833129883
Training epoch 0 | batch 299
Batch on Device 0 computed in 0.7429897785186768 seconds.
tensor([0.4586], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443854331970215
Time for loss calculation for target: 0.011823415756225586
Time for Loss backward: 1.790632724761963
Time needed for the batch 2.9080352783203125
Time needed for logging 0.00724029541015625
Training epoch 0 | batch 300
Batch on Device 0 computed in 0.7399697303771973 seconds.
tensor([0.4438], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544027805328369
Time for loss calculation for target: 0.011901378631591797
Time for Loss backward: 1.7864060401916504
Time needed for the batch 2.901094913482666
Time needed for logging 0.007227897644042969
Training epoch 0 | batch 301
Batch on Device 0 computed in 0.743474006652832 seconds.
tensor([0.3898], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544650077819824
Time for loss calculation for target: 0.011750936508178711
Time for Loss backward: 1.7866108417510986
Time needed for the batch 2.9042606353759766
Time needed for logging 0.0072972774505615234
Training epoch 0 | batch 302
Batch on Device 0 computed in 0.7432706356048584 seconds.
tensor([0.3886], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543837070465088
Time for loss calculation for target: 0.01177072525024414
Time for Loss backward: 1.7853999137878418
Time needed for the batch 2.902803659439087
Time needed for logging 0.007264852523803711
Training epoch 0 | batch 303
Batch on Device 0 computed in 0.743992805480957 seconds.
tensor([0.3698], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445642471313477
Time for loss calculation for target: 0.011792182922363281
Time for Loss backward: 1.7902073860168457
Time needed for the batch 2.908717632293701
Time needed for logging 0.007306575775146484
Training epoch 0 | batch 304
Batch on Device 0 computed in 0.7398955821990967 seconds.
tensor([0.5235], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544342517852783
Time for loss calculation for target: 0.01177215576171875
Time for Loss backward: 1.7858829498291016
Time needed for the batch 2.900144577026367
Time needed for logging 0.007212162017822266
Training epoch 0 | batch 305
Batch on Device 0 computed in 0.7436544895172119 seconds.
tensor([0.7439], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437989234924316
Time for loss calculation for target: 0.011765718460083008
Time for Loss backward: 1.7872180938720703
Time needed for the batch 2.9046504497528076
Time needed for logging 0.0073697566986083984
Training epoch 0 | batch 306
Batch on Device 0 computed in 0.7423813343048096 seconds.
tensor([0.7082], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442304611206055
Time for loss calculation for target: 0.011840105056762695
Time for Loss backward: 1.7914276123046875
Time needed for the batch 2.908308506011963
Time needed for logging 0.007298707962036133
Training epoch 0 | batch 307
Batch on Device 0 computed in 0.7400774955749512 seconds.
tensor([0.4912], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544459342956543
Time for loss calculation for target: 0.011847496032714844
Time for Loss backward: 1.7911121845245361
Time needed for the batch 2.9055335521698
Time needed for logging 0.007225751876831055
Training epoch 0 | batch 308
Batch on Device 0 computed in 0.7426722049713135 seconds.
tensor([0.4059], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434818267822266
Time for loss calculation for target: 0.011844158172607422
Time for Loss backward: 1.7858655452728271
Time needed for the batch 2.9028160572052
Time needed for logging 0.007221698760986328
Training epoch 0 | batch 309
Batch on Device 0 computed in 0.7398810386657715 seconds.
tensor([0.6483], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354341983795166
Time for loss calculation for target: 0.011765003204345703
Time for Loss backward: 1.7906172275543213
Time needed for the batch 2.9086151123046875
Time needed for logging 0.007291555404663086
Training epoch 0 | batch 310
Batch on Device 0 computed in 0.740349292755127 seconds.
tensor([0.2986], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35446977615356445
Time for loss calculation for target: 0.011785745620727539
Time for Loss backward: 1.7912890911102295
Time needed for the batch 2.9059829711914062
Time needed for logging 0.007241010665893555
Training epoch 0 | batch 311
Batch on Device 0 computed in 0.7399866580963135 seconds.
tensor([0.7152], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544290065765381
Time for loss calculation for target: 0.011768817901611328
Time for Loss backward: 1.8576855659484863
Time needed for the batch 2.971993923187256
Time needed for logging 0.00732874870300293
Training epoch 0 | batch 312
Batch on Device 0 computed in 0.7399072647094727 seconds.
tensor([0.2875], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35430359840393066
Time for loss calculation for target: 0.01178884506225586
Time for Loss backward: 1.7856528759002686
Time needed for the batch 2.8997368812561035
Time needed for logging 0.007280826568603516
Training epoch 0 | batch 313
Batch on Device 0 computed in 0.7429771423339844 seconds.
tensor([0.4098], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543891906738281
Time for loss calculation for target: 0.011733293533325195
Time for Loss backward: 1.7876238822937012
Time needed for the batch 2.904909610748291
Time needed for logging 0.007180213928222656
Training epoch 0 | batch 314
Batch on Device 0 computed in 0.7398681640625 seconds.
tensor([0.5021], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546791076660156
Time for loss calculation for target: 0.011947154998779297
Time for Loss backward: 1.7894539833068848
Time needed for the batch 2.9040727615356445
Time needed for logging 0.007164955139160156
Training epoch 0 | batch 315
Batch on Device 0 computed in 0.7400596141815186 seconds.
tensor([0.6858], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442471504211426
Time for loss calculation for target: 0.01179361343383789
Time for Loss backward: 1.789327621459961
Time needed for the batch 2.903918504714966
Time needed for logging 0.007278919219970703
Training epoch 0 | batch 316
Batch on Device 0 computed in 0.7396998405456543 seconds.
tensor([0.5339], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547649383544922
Time for loss calculation for target: 0.011897802352905273
Time for Loss backward: 1.7893562316894531
Time needed for the batch 2.903963088989258
Time needed for logging 0.006784915924072266
Training epoch 0 | batch 317
Batch on Device 0 computed in 0.7437400817871094 seconds.
tensor([0.4697], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354323148727417
Time for loss calculation for target: 0.011862754821777344
Time for Loss backward: 1.7909581661224365
Time needed for the batch 2.909061908721924
Time needed for logging 0.007248401641845703
Training epoch 0 | batch 318
Batch on Device 0 computed in 0.739983320236206 seconds.
tensor([0.3377], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437464714050293
Time for loss calculation for target: 0.011644363403320312
Time for Loss backward: 1.788182258605957
Time needed for the batch 2.9022090435028076
Time needed for logging 0.007216691970825195
Training epoch 0 | batch 319
Batch on Device 0 computed in 0.7403035163879395 seconds.
tensor([0.3192], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441112518310547
Time for loss calculation for target: 0.011749267578125
Time for Loss backward: 1.7870171070098877
Time needed for the batch 2.9015052318573
Time needed for logging 0.006963491439819336
Training epoch 0 | batch 320
Batch on Device 0 computed in 0.7435550689697266 seconds.
tensor([0.4181], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434603691101074
Time for loss calculation for target: 0.011778116226196289
Time for Loss backward: 1.792299509048462
Time needed for the batch 2.9098997116088867
Time needed for logging 0.0072803497314453125
Training epoch 0 | batch 321
Batch on Device 0 computed in 0.739863395690918 seconds.
tensor([0.3551], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35427188873291016
Time for loss calculation for target: 0.011787176132202148
Time for Loss backward: 1.7899892330169678
Time needed for the batch 2.9039716720581055
Time needed for logging 0.0073168277740478516
Training epoch 0 | batch 322
Batch on Device 0 computed in 0.73990797996521 seconds.
tensor([0.4358], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35485148429870605
Time for loss calculation for target: 0.011945724487304688
Time for Loss backward: 1.7889418601989746
Time needed for the batch 2.9032058715820312
Time needed for logging 0.007311820983886719
Training epoch 0 | batch 323
Batch on Device 0 computed in 0.7399470806121826 seconds.
tensor([0.3768], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544628620147705
Time for loss calculation for target: 0.011797904968261719
Time for Loss backward: 1.7903971672058105
Time needed for the batch 2.9045968055725098
Time needed for logging 0.007365226745605469
Training epoch 0 | batch 324
Batch on Device 0 computed in 0.7401912212371826 seconds.
tensor([0.6287], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543727397918701
Time for loss calculation for target: 0.011833906173706055
Time for Loss backward: 1.790235996246338
Time needed for the batch 2.9044923782348633
Time needed for logging 0.0073544979095458984
Training epoch 0 | batch 325
Batch on Device 0 computed in 0.7433042526245117 seconds.
tensor([0.3830], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354381799697876
Time for loss calculation for target: 0.011780977249145508
Time for Loss backward: 1.7902183532714844
Time needed for the batch 2.9084835052490234
Time needed for logging 0.007222652435302734
Training epoch 0 | batch 326
Batch on Device 0 computed in 0.740088939666748 seconds.
tensor([0.4201], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543071746826172
Time for loss calculation for target: 0.011764287948608398
Time for Loss backward: 1.7940545082092285
Time needed for the batch 2.908278465270996
Time needed for logging 0.0069963932037353516
Training epoch 0 | batch 327
Batch on Device 0 computed in 0.7401936054229736 seconds.
tensor([0.3627], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544025421142578
Time for loss calculation for target: 0.011742591857910156
Time for Loss backward: 1.790595293045044
Time needed for the batch 2.906444549560547
Time needed for logging 0.007014274597167969
Training epoch 0 | batch 328
Batch on Device 0 computed in 0.7399942874908447 seconds.
tensor([0.6504], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544285297393799
Time for loss calculation for target: 0.011729240417480469
Time for Loss backward: 1.7886054515838623
Time needed for the batch 2.902550220489502
Time needed for logging 0.006609439849853516
Training epoch 0 | batch 329
Batch on Device 0 computed in 0.7405545711517334 seconds.
tensor([0.1831], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440587997436523
Time for loss calculation for target: 0.011824846267700195
Time for Loss backward: 1.792268991470337
Time needed for the batch 2.907010078430176
Time needed for logging 0.006676673889160156
Training epoch 0 | batch 330
Batch on Device 0 computed in 0.740149736404419 seconds.
tensor([0.4087], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439014434814453
Time for loss calculation for target: 0.011757850646972656
Time for Loss backward: 1.7916274070739746
Time needed for the batch 2.905656576156616
Time needed for logging 0.00655817985534668
Training epoch 0 | batch 331
Batch on Device 0 computed in 0.7413754463195801 seconds.
tensor([0.3921], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354447603225708
Time for loss calculation for target: 0.011747360229492188
Time for Loss backward: 1.7854022979736328
Time needed for the batch 2.9006030559539795
Time needed for logging 0.006667613983154297
Training epoch 0 | batch 332
Batch on Device 0 computed in 0.7454347610473633 seconds.
tensor([0.4750], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35446691513061523
Time for loss calculation for target: 0.011741161346435547
Time for Loss backward: 1.788600206375122
Time needed for the batch 2.908018112182617
Time needed for logging 0.00672149658203125
Training epoch 0 | batch 333
Batch on Device 0 computed in 0.7399373054504395 seconds.
tensor([0.6867], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440683364868164
Time for loss calculation for target: 0.011791467666625977
Time for Loss backward: 1.7899372577667236
Time needed for the batch 2.90372371673584
Time needed for logging 0.00653839111328125
Training epoch 0 | batch 334
Batch on Device 0 computed in 0.7401418685913086 seconds.
tensor([0.3855], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544447422027588
Time for loss calculation for target: 0.01173543930053711
Time for Loss backward: 1.7892515659332275
Time needed for the batch 2.9031007289886475
Time needed for logging 0.006575584411621094
Training epoch 0 | batch 335
Batch on Device 0 computed in 0.7407619953155518 seconds.
tensor([0.1441], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543553352355957
Time for loss calculation for target: 0.011704444885253906
Time for Loss backward: 1.7895755767822266
Time needed for the batch 2.90371036529541
Time needed for logging 0.006647586822509766
Training epoch 0 | batch 336
Batch on Device 0 computed in 0.7421491146087646 seconds.
tensor([0.1612], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436582565307617
Time for loss calculation for target: 0.08095574378967285
Time for Loss backward: 1.7936046123504639
Time needed for the batch 2.978842258453369
Time needed for logging 0.005604982376098633
Training epoch 0 | batch 337
Batch on Device 0 computed in 0.7398419380187988 seconds.
tensor([0.5373], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543415069580078
Time for loss calculation for target: 0.011676549911499023
Time for Loss backward: 1.7883598804473877
Time needed for the batch 2.9021189212799072
Time needed for logging 0.006577491760253906
Training epoch 0 | batch 338
Batch on Device 0 computed in 0.7409877777099609 seconds.
tensor([0.5085], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439491271972656
Time for loss calculation for target: 0.011700153350830078
Time for Loss backward: 1.7917368412017822
Time needed for the batch 2.9069740772247314
Time needed for logging 0.006603240966796875
Training epoch 0 | batch 339
Batch on Device 0 computed in 0.7400393486022949 seconds.
tensor([0.6444], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543715476989746
Time for loss calculation for target: 0.011800050735473633
Time for Loss backward: 1.784447431564331
Time needed for the batch 2.898432970046997
Time needed for logging 0.0066127777099609375
Training epoch 0 | batch 340
Batch on Device 0 computed in 0.7458422183990479 seconds.
tensor([0.4741], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544285297393799
Time for loss calculation for target: 0.011873960494995117
Time for Loss backward: 1.7895586490631104
Time needed for the batch 2.9094700813293457
Time needed for logging 0.006547451019287109
Training epoch 0 | batch 341
Batch on Device 0 computed in 0.7452833652496338 seconds.
tensor([0.7016], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543221950531006
Time for loss calculation for target: 0.01174616813659668
Time for Loss backward: 1.7860972881317139
Time needed for the batch 2.9059722423553467
Time needed for logging 0.006541728973388672
Training epoch 0 | batch 342
Batch on Device 0 computed in 0.7465023994445801 seconds.
tensor([0.3299], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543872833251953
Time for loss calculation for target: 0.011858463287353516
Time for Loss backward: 1.7931506633758545
Time needed for the batch 2.913679361343384
Time needed for logging 0.006159782409667969
Training epoch 0 | batch 343
Batch on Device 0 computed in 0.7398927211761475 seconds.
tensor([0.4859], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436511039733887
Time for loss calculation for target: 0.011821985244750977
Time for Loss backward: 1.7913315296173096
Time needed for the batch 2.9046950340270996
Time needed for logging 0.0065097808837890625
Training epoch 0 | batch 344
Batch on Device 0 computed in 0.7398090362548828 seconds.
tensor([0.4785], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354339599609375
Time for loss calculation for target: 0.011810302734375
Time for Loss backward: 1.7903144359588623
Time needed for the batch 2.9040703773498535
Time needed for logging 0.006970405578613281
Training epoch 0 | batch 345
Batch on Device 0 computed in 0.7398877143859863 seconds.
tensor([0.4700], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543219566345215
Time for loss calculation for target: 0.011696577072143555
Time for Loss backward: 1.7851746082305908
Time needed for the batch 2.899010181427002
Time needed for logging 0.0070896148681640625
Training epoch 0 | batch 346
Batch on Device 0 computed in 0.7440969944000244 seconds.
tensor([0.2098], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434842109680176
Time for loss calculation for target: 0.011743545532226562
Time for Loss backward: 1.7840993404388428
Time needed for the batch 2.9021873474121094
Time needed for logging 0.007075071334838867
Training epoch 0 | batch 347
Batch on Device 0 computed in 0.7452528476715088 seconds.
tensor([0.3565], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543417453765869
Time for loss calculation for target: 0.01185917854309082
Time needed for the batch 2.909400701522827
Time needed for logging 0.007036924362182617
Training epoch 0 | batch 348
Batch on Device 0 computed in 0.740053653717041 seconds.
tensor([0.2328], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436129570007324
Time for loss calculation for target: 0.011750459671020508
Time for Loss backward: 1.7845656871795654
Time needed for the batch 2.8982717990875244
Time needed for logging 0.007142066955566406
Training epoch 0 | batch 349
Batch on Device 0 computed in 0.7441868782043457 seconds.
tensor([0.4547], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436367988586426
Time for loss calculation for target: 0.011749029159545898
Time for Loss backward: 1.7915492057800293
Time needed for the batch 2.909771203994751
Time needed for logging 0.0071103572845458984
Training epoch 0 | batch 350
Batch on Device 0 computed in 0.7399570941925049 seconds.
tensor([0.3458], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544576168060303
Time for loss calculation for target: 0.011860847473144531
Time for Loss backward: 1.7848584651947021
Time needed for the batch 2.8985517024993896
Time needed for logging 0.007092714309692383
Training epoch 0 | batch 351
Batch on Device 0 computed in 0.7454006671905518 seconds.
tensor([0.7459], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543369770050049
Time for loss calculation for target: 0.011936664581298828
Time for Loss backward: 1.7897930145263672
Time needed for the batch 2.9093751907348633
Time needed for logging 0.00709986686706543
Training epoch 0 | batch 352
Batch on Device 0 computed in 0.7400400638580322 seconds.
tensor([0.4590], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545258045196533
Time for loss calculation for target: 0.011956214904785156
Time for Loss backward: 1.7903316020965576
Time needed for the batch 2.904642343521118
Time needed for logging 0.007019996643066406
Training epoch 0 | batch 353
Batch on Device 0 computed in 0.7401754856109619 seconds.
tensor([0.2306], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35494232177734375
Time for loss calculation for target: 0.011949777603149414
Time for Loss backward: 1.7906229496002197
Time needed for the batch 2.9056005477905273
Time needed for logging 0.007142066955566406
Training epoch 0 | batch 354
Batch on Device 0 computed in 0.7401118278503418 seconds.
tensor([0.2936], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544280529022217
Time for loss calculation for target: 0.011800765991210938
Time for Loss backward: 1.7901430130004883
Time needed for the batch 2.904409646987915
Time needed for logging 0.007207393646240234
Training epoch 0 | batch 355
Batch on Device 0 computed in 0.7399699687957764 seconds.
tensor([0.5051], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543844223022461
Time for loss calculation for target: 0.011706352233886719
Time for Loss backward: 1.7896277904510498
Time needed for the batch 2.9034745693206787
Time needed for logging 0.007073402404785156
Training epoch 0 | batch 356
Batch on Device 0 computed in 0.7399859428405762 seconds.
tensor([0.5371], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545055389404297
Time for loss calculation for target: 0.011760711669921875
Time for Loss backward: 1.790412187576294
Time needed for the batch 2.904494524002075
Time needed for logging 0.0070607662200927734
Training epoch 0 | batch 357
Batch on Device 0 computed in 0.7399530410766602 seconds.
tensor([1.3220], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443949699401855
Time for loss calculation for target: 0.011749744415283203
Time for Loss backward: 1.7903289794921875
Time needed for the batch 2.904273271560669
Time needed for logging 0.007155895233154297
Training epoch 0 | batch 358
Batch on Device 0 computed in 0.7401061058044434 seconds.
tensor([0.4462], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544609546661377
Time for loss calculation for target: 0.011810302734375
Time for Loss backward: 1.7875404357910156
Time needed for the batch 2.901761770248413
Time needed for logging 0.007093906402587891
Training epoch 0 | batch 359
Batch on Device 0 computed in 0.7401735782623291 seconds.
tensor([0.3099], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436487197875977
Time for loss calculation for target: 0.011783599853515625
Time for Loss backward: 1.7893633842468262
Time needed for the batch 2.9034314155578613
Time needed for logging 0.0070455074310302734
Training epoch 0 | batch 360
Batch on Device 0 computed in 0.7399420738220215 seconds.
tensor([0.3171], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543875217437744
Time for loss calculation for target: 0.011821985244750977
Time for Loss backward: 1.791339635848999
Time needed for the batch 2.905440092086792
Time needed for logging 0.006971597671508789
Training epoch 0 | batch 361
Batch on Device 0 computed in 0.740062952041626 seconds.
tensor([0.4806], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439205169677734
Time for loss calculation for target: 0.012145042419433594
Time for Loss backward: 1.7895145416259766
Time needed for the batch 2.9038820266723633
Time needed for logging 0.007113456726074219
Training epoch 0 | batch 362
Batch on Device 0 computed in 0.7398743629455566 seconds.
tensor([0.9525], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543436527252197
Time for loss calculation for target: 0.011814117431640625
Time for Loss backward: 1.7898404598236084
Time needed for the batch 2.9040420055389404
Time needed for logging 0.0070819854736328125
Training epoch 0 | batch 363
Batch on Device 0 computed in 0.7400743961334229 seconds.
tensor([0.3364], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543839454650879
Time for loss calculation for target: 0.011756658554077148
Time for Loss backward: 1.7867207527160645
Time needed for the batch 2.901024341583252
Time needed for logging 0.007073402404785156
Training epoch 0 | batch 364
Batch on Device 0 computed in 0.7427103519439697 seconds.
tensor([0.4139], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544013500213623
Time for loss calculation for target: 0.011939287185668945
Time for Loss backward: 1.7844970226287842
Time needed for the batch 2.9014337062835693
Time needed for logging 0.007269144058227539
Training epoch 0 | batch 365
Batch on Device 0 computed in 0.7426986694335938 seconds.
tensor([0.6085], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35444211959838867
Time for loss calculation for target: 0.011973381042480469
Time for Loss backward: 1.7909843921661377
Time needed for the batch 2.908298969268799
Time needed for logging 0.007143735885620117
Training epoch 0 | batch 366
Batch on Device 0 computed in 0.7403533458709717 seconds.
tensor([0.4589], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439157485961914
Time for loss calculation for target: 0.01166081428527832
Time for Loss backward: 1.7893364429473877
Time needed for the batch 2.9035956859588623
Time needed for logging 0.007184028625488281
Training epoch 0 | batch 367
Batch on Device 0 computed in 0.740018367767334 seconds.
tensor([0.7473], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543522357940674
Time for loss calculation for target: 0.01168966293334961
Time for Loss backward: 1.7903993129730225
Time needed for the batch 2.904693126678467
Time needed for logging 0.007290363311767578
Training epoch 0 | batch 368
Batch on Device 0 computed in 0.739851713180542 seconds.
tensor([0.3121], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543882369995117
Time for loss calculation for target: 0.011664152145385742
Time for Loss backward: 1.7855935096740723
Time needed for the batch 2.899399995803833
Time needed for logging 0.007369279861450195
Training epoch 0 | batch 369
Batch on Device 0 computed in 0.7420282363891602 seconds.
tensor([0.5033], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354508638381958
Time for loss calculation for target: 0.012086153030395508
Time for Loss backward: 1.7889575958251953
Time needed for the batch 2.9057254791259766
Time needed for logging 0.007005453109741211
Training epoch 0 | batch 370
Batch on Device 0 computed in 0.7398877143859863 seconds.
tensor([0.3500], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443115234375
Time for loss calculation for target: 0.011800289154052734
Time for Loss backward: 1.7890050411224365
Time needed for the batch 2.9033026695251465
Time needed for logging 0.0070645809173583984
Training epoch 0 | batch 371
Batch on Device 0 computed in 0.7399489879608154 seconds.
tensor([0.2721], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448551177978516
Time for loss calculation for target: 0.011838912963867188
Time for Loss backward: 1.7900691032409668
Time needed for the batch 2.9041953086853027
Time needed for logging 0.007187843322753906
Training epoch 0 | batch 372
Batch on Device 0 computed in 0.7399387359619141 seconds.
tensor([0.3958], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442090034484863
Time for loss calculation for target: 0.01179814338684082
Time for Loss backward: 1.7904260158538818
Time needed for the batch 2.904359817504883
Time needed for logging 0.007127046585083008
Training epoch 0 | batch 373
Batch on Device 0 computed in 0.739870548248291 seconds.
tensor([0.8353], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544797897338867
Time for loss calculation for target: 0.012047052383422852
Time for Loss backward: 1.7901661396026611
Time needed for the batch 2.9043753147125244
Time needed for logging 0.0070972442626953125
Training epoch 0 | batch 374
Batch on Device 0 computed in 0.7398970127105713 seconds.
tensor([0.4563], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543815612792969
Time for loss calculation for target: 0.01182866096496582
Time for Loss backward: 1.790557861328125
Time needed for the batch 2.9046521186828613
Time needed for logging 0.007123470306396484
Training epoch 0 | batch 375
Batch on Device 0 computed in 0.7399377822875977 seconds.
tensor([0.3684], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436177253723145
Time for loss calculation for target: 0.011718988418579102
Time for Loss backward: 1.7883670330047607
Time needed for the batch 2.927248954772949
Time needed for logging 0.007109165191650391
Training epoch 0 | batch 376
Batch on Device 0 computed in 0.739919900894165 seconds.
tensor([0.3302], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543736934661865
Time for loss calculation for target: 0.011802911758422852
Time for Loss backward: 1.7860019207000732
Time needed for the batch 2.900087594985962
Time needed for logging 0.007133007049560547
Training epoch 0 | batch 377
Batch on Device 0 computed in 0.7434639930725098 seconds.
tensor([0.8533], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543739318847656
Time for loss calculation for target: 0.011819601058959961
Time for Loss backward: 1.7912559509277344
Time needed for the batch 2.908888816833496
Time needed for logging 0.007172822952270508
Training epoch 0 | batch 378
Batch on Device 0 computed in 0.739886999130249 seconds.
tensor([0.5680], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544173240661621
Time for loss calculation for target: 0.011808156967163086
Time for Loss backward: 1.7894978523254395
Time needed for the batch 2.903705358505249
Time needed for logging 0.0071566104888916016
Training epoch 0 | batch 379
Batch on Device 0 computed in 0.7400074005126953 seconds.
tensor([0.5440], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437583923339844
Time for loss calculation for target: 0.011678934097290039
Time for Loss backward: 1.790889024734497
Time needed for the batch 2.9048616886138916
Time needed for logging 0.007154226303100586
Training epoch 0 | batch 380
Batch on Device 0 computed in 0.7399859428405762 seconds.
tensor([0.2270], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545224666595459
Time for loss calculation for target: 0.011761665344238281
Time for Loss backward: 1.7904117107391357
Time needed for the batch 2.9045662879943848
Time needed for logging 0.00711512565612793
Training epoch 0 | batch 381
Batch on Device 0 computed in 0.7400286197662354 seconds.
tensor([0.3795], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543822765350342
Time for loss calculation for target: 0.011731624603271484
Time for Loss backward: 1.7851815223693848
Time needed for the batch 2.899359941482544
Time needed for logging 0.00717616081237793
Training epoch 0 | batch 382
Batch on Device 0 computed in 0.7426083087921143 seconds.
tensor([0.5062], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437726974487305
Time for loss calculation for target: 0.011784791946411133
Time for Loss backward: 1.7858779430389404
Time needed for the batch 2.9026682376861572
Time needed for logging 0.007120609283447266
Training epoch 0 | batch 383
Batch on Device 0 computed in 0.7420527935028076 seconds.
tensor([0.4140], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544139862060547
Time for loss calculation for target: 0.011865854263305664
Time for Loss backward: 1.7867014408111572
Time needed for the batch 2.903186082839966
Time needed for logging 0.007223844528198242
Training epoch 0 | batch 384
Batch on Device 0 computed in 0.7421255111694336 seconds.
tensor([0.4162], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544297218322754
Time for loss calculation for target: 0.0117645263671875
Time for Loss backward: 1.7878317832946777
Time needed for the batch 2.9044711589813232
Time needed for logging 0.007090330123901367
Training epoch 0 | batch 385
Batch on Device 0 computed in 0.7493565082550049 seconds.
tensor([0.3813], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354372501373291
Time for loss calculation for target: 0.011860370635986328
Time for Loss backward: 1.7918157577514648
Time needed for the batch 2.915355920791626
Time needed for logging 0.007086515426635742
Training epoch 0 | batch 386
Batch on Device 0 computed in 0.73996901512146 seconds.
tensor([0.7056], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443544387817383
Time for loss calculation for target: 0.011980056762695312
Time for Loss backward: 1.7876112461090088
Time needed for the batch 2.9018516540527344
Time needed for logging 0.007155895233154297
Training epoch 0 | batch 387
Batch on Device 0 computed in 0.7428390979766846 seconds.
tensor([0.1805], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544001579284668
Time for loss calculation for target: 0.011791229248046875
Time for Loss backward: 1.7901246547698975
Time needed for the batch 2.9071407318115234
Time needed for logging 0.007291555404663086
Training epoch 0 | batch 388
Batch on Device 0 computed in 0.7398412227630615 seconds.
tensor([0.2591], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439324378967285
Time for loss calculation for target: 0.011823415756225586
Time for Loss backward: 1.7908682823181152
Time needed for the batch 2.9051804542541504
Time needed for logging 0.0072765350341796875
Training epoch 0 | batch 389
Batch on Device 0 computed in 0.7397196292877197 seconds.
tensor([0.3997], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543417453765869
Time for loss calculation for target: 0.011922836303710938
Time for Loss backward: 1.792813777923584
Time needed for the batch 2.906928777694702
Time needed for logging 0.007291316986083984
Training epoch 0 | batch 390
Batch on Device 0 computed in 0.7407875061035156 seconds.
tensor([0.5266], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546254634857178
Time for loss calculation for target: 0.011872529983520508
Time for Loss backward: 1.7929322719573975
Time needed for the batch 2.9083638191223145
Time needed for logging 0.007172822952270508
Training epoch 0 | batch 391
Batch on Device 0 computed in 0.7398264408111572 seconds.
tensor([0.5061], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354755163192749
Time for loss calculation for target: 0.012105464935302734
Time for Loss backward: 1.7876379489898682
Time needed for the batch 2.9025070667266846
Time needed for logging 0.007430315017700195
Training epoch 0 | batch 392
Batch on Device 0 computed in 0.7399759292602539 seconds.
tensor([0.4833], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546299934387207
Time for loss calculation for target: 0.011873006820678711
Time for Loss backward: 1.7883656024932861
Time needed for the batch 2.903069496154785
Time needed for logging 0.007394313812255859
Training epoch 0 | batch 393
Batch on Device 0 computed in 0.7399210929870605 seconds.
tensor([0.4055], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442113876342773
Time for loss calculation for target: 0.011811494827270508
Time for Loss backward: 1.7902848720550537
Time needed for the batch 2.9045629501342773
Time needed for logging 0.007340908050537109
Training epoch 0 | batch 394
Batch on Device 0 computed in 0.7414753437042236 seconds.
tensor([0.9010], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544018268585205
Time for loss calculation for target: 0.011824607849121094
Time for Loss backward: 1.7843620777130127
Time needed for the batch 2.90023136138916
Time needed for logging 0.007293701171875
Training epoch 0 | batch 395
Batch on Device 0 computed in 0.7412276268005371 seconds.
tensor([0.4211], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439634323120117
Time for loss calculation for target: 0.01186370849609375
Time for Loss backward: 1.7881560325622559
Time needed for the batch 2.9037368297576904
Time needed for logging 0.00722956657409668
Training epoch 0 | batch 396
Batch on Device 0 computed in 0.7427573204040527 seconds.
tensor([0.2893], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543522357940674
Time for loss calculation for target: 0.011847496032714844
Time for Loss backward: 1.7925469875335693
Time needed for the batch 2.909391164779663
Time needed for logging 0.0068471431732177734
Training epoch 0 | batch 397
Batch on Device 0 computed in 0.7399847507476807 seconds.
tensor([0.3392], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543426990509033
Time for loss calculation for target: 0.011782169342041016
Time for Loss backward: 1.7921385765075684
Time needed for the batch 2.9072091579437256
Time needed for logging 0.007180452346801758
Training epoch 0 | batch 398
Batch on Device 0 computed in 0.7399625778198242 seconds.
tensor([0.5835], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543989658355713
Time for loss calculation for target: 0.012186050415039062
Time for Loss backward: 1.7900893688201904
Time needed for the batch 2.904871940612793
Time needed for logging 0.007189750671386719
Training epoch 0 | batch 399
Batch on Device 0 computed in 0.7399351596832275 seconds.
tensor([0.4518], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543739318847656
Time for loss calculation for target: 0.011777639389038086
Time for Loss backward: 1.7863891124725342
Time needed for the batch 2.900557041168213
Time needed for logging 0.007201433181762695
Training epoch 0 | batch 400
Batch on Device 0 computed in 0.7431168556213379 seconds.
tensor([0.6587], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543269634246826
Time for loss calculation for target: 0.011725902557373047
Time for Loss backward: 1.786339282989502
Time needed for the batch 2.9035003185272217
Time needed for logging 0.0072057247161865234
Training epoch 0 | batch 401
Batch on Device 0 computed in 0.7399632930755615 seconds.
tensor([0.8811], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354412317276001
Time for loss calculation for target: 0.011781454086303711
Time for Loss backward: 1.7908031940460205
Time needed for the batch 2.9089243412017822
Time needed for logging 0.007403373718261719
Training epoch 0 | batch 402
Batch on Device 0 computed in 0.73996901512146 seconds.
tensor([0.5391], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433363914489746
Time for loss calculation for target: 0.011742353439331055
Time for Loss backward: 1.7894017696380615
Time needed for the batch 2.9038119316101074
Time needed for logging 0.006806850433349609
Training epoch 0 | batch 403
Batch on Device 0 computed in 0.7431931495666504 seconds.
tensor([0.4054], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443687438964844
Time for loss calculation for target: 0.011764764785766602
Time for Loss backward: 1.786226511001587
Time needed for the batch 2.903738260269165
Time needed for logging 0.007208824157714844
Training epoch 0 | batch 404
Batch on Device 0 computed in 0.7442781925201416 seconds.
tensor([0.5217], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543589115142822
Time for loss calculation for target: 0.011725187301635742
Time for Loss backward: 1.7859199047088623
Time needed for the batch 2.904287338256836
Time needed for logging 0.007097005844116211
Training epoch 0 | batch 405
Batch on Device 0 computed in 0.7430000305175781 seconds.
tensor([0.2747], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354489803314209
Time for loss calculation for target: 0.011817455291748047
Time for Loss backward: 1.7879753112792969
Time needed for the batch 2.90556001663208
Time needed for logging 0.006946563720703125
Training epoch 0 | batch 406
Batch on Device 0 computed in 0.7400562763214111 seconds.
tensor([0.3406], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543589115142822
Time for loss calculation for target: 0.011795282363891602
Time for Loss backward: 1.7863216400146484
Time needed for the batch 2.9006903171539307
Time needed for logging 0.0072019100189208984
Training epoch 0 | batch 407
Batch on Device 0 computed in 0.7427916526794434 seconds.
tensor([0.3126], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543856143951416
Time for loss calculation for target: 0.011732339859008789
Time for Loss backward: 1.7868671417236328
Time needed for the batch 2.904405117034912
Time needed for logging 0.00727081298828125
Training epoch 0 | batch 408
Batch on Device 0 computed in 0.7431340217590332 seconds.
tensor([0.3715], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544480800628662
Time for loss calculation for target: 0.011667251586914062
Time for Loss backward: 1.7874739170074463
Time needed for the batch 2.9048218727111816
Time needed for logging 0.007137298583984375
Training epoch 0 | batch 409
Batch on Device 0 computed in 0.7429330348968506 seconds.
tensor([0.5509], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543701171875
Time for loss calculation for target: 0.011841058731079102
Time for Loss backward: 1.7866499423980713
Time needed for the batch 2.9038279056549072
Time needed for logging 0.007138967514038086
Training epoch 0 | batch 410
Batch on Device 0 computed in 0.7426638603210449 seconds.
tensor([0.4684], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543875217437744
Time for loss calculation for target: 0.011738777160644531
Time for Loss backward: 1.7844479084014893
Time needed for the batch 2.90151309967041
Time needed for logging 0.007272481918334961
Training epoch 0 | batch 411
Batch on Device 0 computed in 0.7413370609283447 seconds.
tensor([0.3384], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35454463958740234
Time for loss calculation for target: 0.011874914169311523
Time for Loss backward: 1.7863941192626953
Time needed for the batch 2.902892827987671
Time needed for logging 0.007054328918457031
Training epoch 0 | batch 412
Batch on Device 0 computed in 0.742377519607544 seconds.
tensor([0.3050], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3548166751861572
Time for loss calculation for target: 0.011964797973632812
Time for Loss backward: 1.787018060684204
Time needed for the batch 2.9043867588043213
Time needed for logging 0.007061004638671875
Training epoch 0 | batch 413
Batch on Device 0 computed in 0.739739179611206 seconds.
tensor([0.4933], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35472774505615234
Time for loss calculation for target: 0.011866331100463867
Time for Loss backward: 1.7894976139068604
Time needed for the batch 2.9039037227630615
Time needed for logging 0.007154941558837891
Training epoch 0 | batch 414
Batch on Device 0 computed in 0.741032600402832 seconds.
tensor([0.6471], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543510437011719
Time for loss calculation for target: 0.01168060302734375
Time for Loss backward: 1.7901661396026611
Time needed for the batch 2.9053611755371094
Time needed for logging 0.0070459842681884766
Training epoch 0 | batch 415
Batch on Device 0 computed in 0.7399380207061768 seconds.
tensor([0.5647], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543846607208252
Time for loss calculation for target: 0.01247406005859375
Time for Loss backward: 1.789721965789795
Time needed for the batch 2.90478253364563
Time needed for logging 0.007194995880126953
Training epoch 0 | batch 416
Batch on Device 0 computed in 0.7398967742919922 seconds.
tensor([0.3765], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442137718200684
Time for loss calculation for target: 0.011803150177001953
Time for Loss backward: 1.7842442989349365
Time needed for the batch 2.898646116256714
Time needed for logging 0.007279872894287109
Training epoch 0 | batch 417
Batch on Device 0 computed in 0.7443356513977051 seconds.
tensor([0.2115], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543515205383301
Time for loss calculation for target: 0.01179051399230957
Time for Loss backward: 1.7913899421691895
Time needed for the batch 2.9103472232818604
Time needed for logging 0.0071239471435546875
Training epoch 0 | batch 418
Batch on Device 0 computed in 0.7400155067443848 seconds.
tensor([0.4923], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543686866760254
Time for loss calculation for target: 0.01172494888305664
Time for Loss backward: 1.7893872261047363
Time needed for the batch 2.90340256690979
Time needed for logging 0.007028818130493164
Training epoch 0 | batch 419
Batch on Device 0 computed in 0.740426778793335 seconds.
tensor([0.5512], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35451793670654297
Time for loss calculation for target: 0.012128353118896484
Time for Loss backward: 1.7941269874572754
Time needed for the batch 2.909043550491333
Time needed for logging 0.007070779800415039
Training epoch 0 | batch 420
Batch on Device 0 computed in 0.7399134635925293 seconds.
tensor([0.2801], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443735122680664
Time for loss calculation for target: 0.011781930923461914
Time for Loss backward: 1.7920372486114502
Time needed for the batch 2.905989170074463
Time needed for logging 0.007054567337036133
Training epoch 0 | batch 421
Batch on Device 0 computed in 0.7399976253509521 seconds.
tensor([0.3916], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436439514160156
Time for loss calculation for target: 0.011780500411987305
Time for Loss backward: 1.7904610633850098
Time needed for the batch 2.904578924179077
Time needed for logging 0.007149696350097656
Training epoch 0 | batch 422
Batch on Device 0 computed in 0.7400007247924805 seconds.
tensor([0.3364], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434889793395996
Time for loss calculation for target: 0.011734485626220703
Time for Loss backward: 1.7856462001800537
Time needed for the batch 2.899945020675659
Time needed for logging 0.007189035415649414
Training epoch 0 | batch 423
Batch on Device 0 computed in 0.7437601089477539 seconds.
tensor([0.8523], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439109802246094
Time for loss calculation for target: 0.011797189712524414
Time for Loss backward: 1.7860383987426758
Time needed for the batch 2.9038257598876953
Time needed for logging 0.007269620895385742
Training epoch 0 | batch 424
Batch on Device 0 computed in 0.7433934211730957 seconds.
tensor([0.5723], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544576168060303
Time for loss calculation for target: 0.011795759201049805
Time for Loss backward: 1.7850046157836914
Time needed for the batch 2.902843713760376
Time needed for logging 0.00719904899597168
Training epoch 0 | batch 425
Batch on Device 0 computed in 0.7443439960479736 seconds.
tensor([0.2905], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547821044921875
Time for loss calculation for target: 0.011951684951782227
Time for Loss backward: 1.7869288921356201
Time needed for the batch 2.90602970123291
Time needed for logging 0.007097005844116211
Training epoch 0 | batch 426
Batch on Device 0 computed in 0.74019455909729 seconds.
tensor([0.4348], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543734550476074
Time for loss calculation for target: 0.011693239212036133
Time for Loss backward: 1.7885968685150146
Time needed for the batch 2.902754783630371
Time needed for logging 0.007084369659423828
Training epoch 0 | batch 427
Batch on Device 0 computed in 0.7400100231170654 seconds.
tensor([0.5256], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354358434677124
Time for loss calculation for target: 0.011754274368286133
Time for Loss backward: 1.7871341705322266
Time needed for the batch 2.901857376098633
Time needed for logging 0.007107257843017578
Training epoch 0 | batch 428
Batch on Device 0 computed in 0.7398867607116699 seconds.
tensor([0.2626], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547399044036865
Time for loss calculation for target: 0.011831283569335938
Time for Loss backward: 1.7868971824645996
Time needed for the batch 2.9014828205108643
Time needed for logging 0.007197141647338867
Training epoch 0 | batch 429
Batch on Device 0 computed in 0.7397959232330322 seconds.
tensor([0.6217], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436558723449707
Time for loss calculation for target: 0.011809349060058594
Time for Loss backward: 1.7908036708831787
Time needed for the batch 2.904719829559326
Time needed for logging 0.007363557815551758
Training epoch 0 | batch 430
Batch on Device 0 computed in 0.7416985034942627 seconds.
tensor([0.4786], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442543029785156
Time for loss calculation for target: 0.011857032775878906
Time for Loss backward: 1.7875432968139648
Time needed for the batch 2.904017925262451
Time needed for logging 0.0072078704833984375
Training epoch 0 | batch 431
Batch on Device 0 computed in 0.7401123046875 seconds.
tensor([0.1326], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544046878814697
Time for loss calculation for target: 0.011713027954101562
Time for Loss backward: 1.7895421981811523
Time needed for the batch 2.903402328491211
Time needed for logging 0.007247209548950195
Training epoch 0 | batch 432
Batch on Device 0 computed in 0.7399992942810059 seconds.
tensor([0.5485], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437726974487305
Time for loss calculation for target: 0.01182246208190918
Time for Loss backward: 1.7906486988067627
Time needed for the batch 2.905139684677124
Time needed for logging 0.007186412811279297
Training epoch 0 | batch 433
Batch on Device 0 computed in 0.7400567531585693 seconds.
tensor([0.3510], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543863296508789
Time for loss calculation for target: 0.01181340217590332
Time for Loss backward: 1.7904174327850342
Time needed for the batch 2.9046905040740967
Time needed for logging 0.0071353912353515625
Training epoch 0 | batch 434
Batch on Device 0 computed in 0.7399966716766357 seconds.
tensor([0.4383], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543829917907715
Time for loss calculation for target: 0.012030601501464844
Time for Loss backward: 1.7891395092010498
Time needed for the batch 2.9035420417785645
Time needed for logging 0.007178783416748047
Training epoch 0 | batch 435
Batch on Device 0 computed in 0.7399935722351074 seconds.
tensor([0.6812], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442256927490234
Time for loss calculation for target: 0.011772871017456055
Time for Loss backward: 1.7904291152954102
Time needed for the batch 2.9046311378479004
Time needed for logging 0.007258415222167969
Training epoch 0 | batch 436
Batch on Device 0 computed in 0.7398285865783691 seconds.
tensor([0.3019], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439300537109375
Time for loss calculation for target: 0.011874198913574219
Time for Loss backward: 1.789315938949585
Time needed for the batch 2.903536319732666
Time needed for logging 0.0072367191314697266
Training epoch 0 | batch 437
Batch on Device 0 computed in 0.739936351776123 seconds.
tensor([0.7527], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440659523010254
Time for loss calculation for target: 0.011788368225097656
Time for Loss backward: 1.7865183353424072
Time needed for the batch 2.9006786346435547
Time needed for logging 0.007252216339111328
Training epoch 0 | batch 438
Batch on Device 0 computed in 0.7428719997406006 seconds.
tensor([0.3333], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547403812408447
Time for loss calculation for target: 0.012046098709106445
Time for Loss backward: 1.7899975776672363
Time needed for the batch 2.907918691635132
Time needed for logging 0.0072519779205322266
Training epoch 0 | batch 439
Batch on Device 0 computed in 0.7400326728820801 seconds.
tensor([0.4088], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544290065765381
Time for loss calculation for target: 0.011717557907104492
Time for Loss backward: 1.789297103881836
Time needed for the batch 2.9035844802856445
Time needed for logging 0.00713801383972168
Training epoch 0 | batch 440
Batch on Device 0 computed in 0.7399630546569824 seconds.
tensor([0.5094], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439181327819824
Time for loss calculation for target: 0.011800527572631836
Time for Loss backward: 1.79056978225708
Time needed for the batch 2.904923915863037
Time needed for logging 0.0074214935302734375
Training epoch 0 | batch 441
Batch on Device 0 computed in 0.7409586906433105 seconds.
tensor([0.5266], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445070266723633
Time for loss calculation for target: 0.011742115020751953
Time for Loss backward: 1.786506175994873
Time needed for the batch 2.901902914047241
Time needed for logging 0.007235050201416016
Training epoch 0 | batch 442
Batch on Device 0 computed in 0.7432358264923096 seconds.
tensor([0.3118], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3542783260345459
Time for loss calculation for target: 0.011855363845825195
Time for Loss backward: 1.7895820140838623
Time needed for the batch 2.907116174697876
Time needed for logging 0.007143974304199219
Training epoch 0 | batch 443
Batch on Device 0 computed in 0.7399756908416748 seconds.
tensor([0.4459], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543405532836914
Time for loss calculation for target: 0.011809825897216797
Time for Loss backward: 1.791184425354004
Time needed for the batch 2.9048283100128174
Time needed for logging 0.007182121276855469
Training epoch 0 | batch 444
Batch on Device 0 computed in 0.7397534847259521 seconds.
tensor([0.6599], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354388952255249
Time for loss calculation for target: 0.011827945709228516
Time for Loss backward: 1.7854585647583008
Time needed for the batch 2.899395227432251
Time needed for logging 0.00719451904296875
Training epoch 0 | batch 445
Batch on Device 0 computed in 0.7441892623901367 seconds.
tensor([0.5430], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3548257350921631
Time for loss calculation for target: 0.01191401481628418
Time for Loss backward: 1.789726734161377
Time needed for the batch 2.9086625576019287
Time needed for logging 0.007253408432006836
Training epoch 0 | batch 446
Batch on Device 0 computed in 0.7398357391357422 seconds.
tensor([0.9166], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543686866760254
Time for loss calculation for target: 0.011753082275390625
Time for Loss backward: 1.789670705795288
Time needed for the batch 2.9035754203796387
Time needed for logging 0.007222414016723633
Training epoch 0 | batch 447
Batch on Device 0 computed in 0.7399439811706543 seconds.
tensor([0.3891], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543665409088135
Time for loss calculation for target: 0.011763334274291992
Time for Loss backward: 1.7900068759918213
Time needed for the batch 2.904176712036133
Time needed for logging 0.007109165191650391
Training epoch 0 | batch 448
Batch on Device 0 computed in 0.7399160861968994 seconds.
tensor([0.1413], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433506965637207
Time for loss calculation for target: 0.011820316314697266
Time for Loss backward: 1.7879571914672852
Time needed for the batch 2.9018797874450684
Time needed for logging 0.007087230682373047
Training epoch 0 | batch 449
Batch on Device 0 computed in 0.7398848533630371 seconds.
tensor([0.6864], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354428768157959
Time for loss calculation for target: 0.011801004409790039
Time for Loss backward: 1.8530199527740479
Time needed for the batch 2.9671220779418945
Time needed for logging 0.007068634033203125
Training epoch 0 | batch 450
Batch on Device 0 computed in 0.7405383586883545 seconds.
tensor([1.0852], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436034202575684
Time for loss calculation for target: 0.011768817901611328
Time for Loss backward: 1.7909116744995117
Time needed for the batch 2.9054818153381348
Time needed for logging 0.007105112075805664
Training epoch 0 | batch 451
Batch on Device 0 computed in 0.7400460243225098 seconds.
tensor([0.5349], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437583923339844
Time for loss calculation for target: 0.011759281158447266
Time for Loss backward: 1.7895498275756836
Time needed for the batch 2.903475046157837
Time needed for logging 0.007241010665893555
Training epoch 0 | batch 452
Batch on Device 0 computed in 0.7398700714111328 seconds.
tensor([0.4673], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439586639404297
Time for loss calculation for target: 0.011796236038208008
Time for Loss backward: 1.783921718597412
Time needed for the batch 2.8979272842407227
Time needed for logging 0.0071065425872802734
Training epoch 0 | batch 453
Batch on Device 0 computed in 0.7431762218475342 seconds.
tensor([0.4397], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543679714202881
Time for loss calculation for target: 0.012053489685058594
Time for Loss backward: 1.7837979793548584
Time needed for the batch 2.901505470275879
Time needed for logging 0.007186412811279297
Training epoch 0 | batch 454
Batch on Device 0 computed in 0.744922399520874 seconds.
tensor([0.6116], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442447662353516
Time for loss calculation for target: 0.011862516403198242
Time for Loss backward: 1.7890727519989014
Time needed for the batch 2.908268451690674
Time needed for logging 0.007213115692138672
Training epoch 0 | batch 455
Batch on Device 0 computed in 0.7399909496307373 seconds.
tensor([0.4419], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433006286621094
Time for loss calculation for target: 0.011780500411987305
Time for Loss backward: 1.789670467376709
Time needed for the batch 2.9041085243225098
Time needed for logging 0.007166862487792969
Training epoch 0 | batch 456
Batch on Device 0 computed in 0.7399313449859619 seconds.
tensor([0.4090], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354337215423584
Time for loss calculation for target: 0.012295246124267578
Time for Loss backward: 1.7895843982696533
Time needed for the batch 2.9044606685638428
Time needed for logging 0.007221698760986328
Training epoch 0 | batch 457
Batch on Device 0 computed in 0.739922046661377 seconds.
tensor([0.4786], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439276695251465
Time for loss calculation for target: 0.011895895004272461
Time for Loss backward: 1.790069341659546
Time needed for the batch 2.9043736457824707
Time needed for logging 0.0071675777435302734
Training epoch 0 | batch 458
Batch on Device 0 computed in 0.7398507595062256 seconds.
tensor([0.6488], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434436798095703
Time for loss calculation for target: 0.011800050735473633
Time for Loss backward: 1.790374517440796
Time needed for the batch 2.9043924808502197
Time needed for logging 0.0072329044342041016
Training epoch 0 | batch 459
Batch on Device 0 computed in 0.7400918006896973 seconds.
tensor([0.5476], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544933795928955
Time for loss calculation for target: 0.011968851089477539
Time for Loss backward: 1.7898917198181152
Time needed for the batch 2.9044694900512695
Time needed for logging 0.007164478302001953
Training epoch 0 | batch 460
Batch on Device 0 computed in 0.7399091720581055 seconds.
tensor([0.4197], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35468411445617676
Time for loss calculation for target: 0.012195587158203125
Time for Loss backward: 1.7918193340301514
Time needed for the batch 2.906738758087158
Time needed for logging 0.007280826568603516
Training epoch 0 | batch 461
Batch on Device 0 computed in 0.7399172782897949 seconds.
tensor([0.4514], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544025421142578
Time for loss calculation for target: 0.01167750358581543
Time for Loss backward: 1.7940471172332764
Time needed for the batch 2.9081642627716064
Time needed for logging 0.007458925247192383
Training epoch 0 | batch 462
Batch on Device 0 computed in 0.7410900592803955 seconds.
tensor([0.5554], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3538205623626709
Time for loss calculation for target: 0.01195836067199707
Time for Loss backward: 1.7894768714904785
Time needed for the batch 2.9052093029022217
Time needed for logging 0.007213592529296875
Training epoch 0 | batch 463
Batch on Device 0 computed in 0.7399179935455322 seconds.
tensor([0.4118], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543970584869385
Time for loss calculation for target: 0.011798381805419922
Time for Loss backward: 1.7897148132324219
Time needed for the batch 2.903921604156494
Time needed for logging 0.007136106491088867
Training epoch 0 | batch 464
Batch on Device 0 computed in 0.7400202751159668 seconds.
tensor([0.5098], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436582565307617
Time for loss calculation for target: 0.011890888214111328
Time for Loss backward: 1.78951096534729
Time needed for the batch 2.9040677547454834
Time needed for logging 0.007082462310791016
Training epoch 0 | batch 465
Batch on Device 0 computed in 0.7398529052734375 seconds.
tensor([0.3859], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35432958602905273
Time for loss calculation for target: 0.01182699203491211
Time for Loss backward: 1.7905256748199463
Time needed for the batch 2.9046549797058105
Time needed for logging 0.007222175598144531
Training epoch 0 | batch 466
Batch on Device 0 computed in 0.7399716377258301 seconds.
tensor([0.8490], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433435440063477
Time for loss calculation for target: 0.011851310729980469
Time for Loss backward: 1.7907543182373047
Time needed for the batch 2.904890775680542
Time needed for logging 0.007338047027587891
Training epoch 0 | batch 467
Batch on Device 0 computed in 0.7399182319641113 seconds.
tensor([0.3788], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440707206726074
Time for loss calculation for target: 0.011812448501586914
Time for Loss backward: 1.7853615283966064
Time needed for the batch 2.8996405601501465
Time needed for logging 0.00724339485168457
Training epoch 0 | batch 468
Batch on Device 0 computed in 0.7436304092407227 seconds.
tensor([0.3772], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439133644104004
Time for loss calculation for target: 0.01192021369934082
Time for Loss backward: 1.7900934219360352
Time needed for the batch 2.908474922180176
Time needed for logging 0.007232666015625
Training epoch 0 | batch 469
Batch on Device 0 computed in 0.739851713180542 seconds.
tensor([0.6928], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543412685394287
Time for loss calculation for target: 0.011810779571533203
Time for Loss backward: 1.7908494472503662
Time needed for the batch 2.9048404693603516
Time needed for logging 0.007127285003662109
Training epoch 0 | batch 470
Batch on Device 0 computed in 0.739840030670166 seconds.
tensor([0.4369], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35431432723999023
Time for loss calculation for target: 0.011947154998779297
Time for Loss backward: 1.78607177734375
Time needed for the batch 2.900268077850342
Time needed for logging 0.00722813606262207
Training epoch 0 | batch 471
Batch on Device 0 computed in 0.743128776550293 seconds.
tensor([0.1972], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543238639831543
Time for loss calculation for target: 0.011787176132202148
Time for Loss backward: 1.788123607635498
Time needed for the batch 2.905562162399292
Time needed for logging 0.00723576545715332
Training epoch 0 | batch 472
Batch on Device 0 computed in 0.739861249923706 seconds.
tensor([0.4317], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543694019317627
Time for loss calculation for target: 0.011815547943115234
Time for Loss backward: 1.7901511192321777
Time needed for the batch 2.9042856693267822
Time needed for logging 0.007684946060180664
Training epoch 0 | batch 473
Batch on Device 0 computed in 0.7399356365203857 seconds.
tensor([0.4696], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543705940246582
Time for loss calculation for target: 0.011692285537719727
Time for Loss backward: 1.7921130657196045
Time needed for the batch 2.905949831008911
Time needed for logging 0.0071752071380615234
Training epoch 0 | batch 474
Batch on Device 0 computed in 0.7430469989776611 seconds.
tensor([0.7679], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35428857803344727
Time for loss calculation for target: 0.011776208877563477
Time for Loss backward: 1.789198875427246
Time needed for the batch 2.906344413757324
Time needed for logging 0.007030010223388672
Training epoch 0 | batch 475
Batch on Device 0 computed in 0.7399663925170898 seconds.
tensor([0.6430], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439515113830566
Time for loss calculation for target: 0.011755228042602539
Time for Loss backward: 1.7887206077575684
Time needed for the batch 2.903031349182129
Time needed for logging 0.007192134857177734
Training epoch 0 | batch 476
Batch on Device 0 computed in 0.7400081157684326 seconds.
tensor([0.2705], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434770584106445
Time for loss calculation for target: 0.011888265609741211
Time for Loss backward: 1.7896952629089355
Time needed for the batch 2.9042139053344727
Time needed for logging 0.007149219512939453
Training epoch 0 | batch 477
Batch on Device 0 computed in 0.7399442195892334 seconds.
tensor([0.3921], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35438084602355957
Time for loss calculation for target: 0.012012481689453125
Time for Loss backward: 1.7862944602966309
Time needed for the batch 2.900623083114624
Time needed for logging 0.007318258285522461
Training epoch 0 | batch 478
Batch on Device 0 computed in 0.742729902267456 seconds.
tensor([0.4431], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35428667068481445
Time for loss calculation for target: 0.011786937713623047
Time for Loss backward: 1.7839298248291016
Time needed for the batch 2.900951623916626
Time needed for logging 0.007231235504150391
Training epoch 0 | batch 479
Batch on Device 0 computed in 0.7413344383239746 seconds.
tensor([0.9833], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35429930686950684
Time for loss calculation for target: 0.011843204498291016
Time for Loss backward: 1.7888121604919434
Time needed for the batch 2.9046096801757812
Time needed for logging 0.0072252750396728516
Training epoch 0 | batch 480
Batch on Device 0 computed in 0.7398514747619629 seconds.
tensor([0.3506], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3542907238006592
Time for loss calculation for target: 0.011879920959472656
Time for Loss backward: 1.7889952659606934
Time needed for the batch 2.90291166305542
Time needed for logging 0.007227182388305664
Training epoch 0 | batch 481
Batch on Device 0 computed in 0.7398984432220459 seconds.
tensor([0.4081], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543055057525635
Time for loss calculation for target: 0.01217961311340332
Time for Loss backward: 1.7848899364471436
Time needed for the batch 2.899303913116455
Time needed for logging 0.007387876510620117
Training epoch 0 | batch 482
Batch on Device 0 computed in 0.7435903549194336 seconds.
tensor([0.6805], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35469841957092285
Time for loss calculation for target: 0.011842727661132812
Time for Loss backward: 1.7849020957946777
Time needed for the batch 2.9035959243774414
Time needed for logging 0.007192850112915039
Training epoch 0 | batch 483
Batch on Device 0 computed in 0.7441451549530029 seconds.
tensor([0.4230], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546924591064453
Time for loss calculation for target: 0.011932134628295898
Time for Loss backward: 1.791151523590088
Time needed for the batch 2.91017746925354
Time needed for logging 0.007196187973022461
Training epoch 0 | batch 484
Batch on Device 0 computed in 0.7399852275848389 seconds.
tensor([0.4405], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35438013076782227
Time for loss calculation for target: 0.011773824691772461
Time for Loss backward: 1.793973445892334
Time needed for the batch 2.9081203937530518
Time needed for logging 0.0072383880615234375
Training epoch 0 | batch 485
Batch on Device 0 computed in 0.7398898601531982 seconds.
tensor([0.3566], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436391830444336
Time for loss calculation for target: 0.011804342269897461
Time for Loss backward: 1.7910258769989014
Time needed for the batch 2.905042886734009
Time needed for logging 0.0071561336517333984
Training epoch 0 | batch 486
Batch on Device 0 computed in 0.73988938331604 seconds.
tensor([0.4641], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543894290924072
Time for loss calculation for target: 0.011820554733276367
Time for Loss backward: 1.7912094593048096
Time needed for the batch 2.9048805236816406
Time needed for logging 0.0072994232177734375
Training epoch 0 | batch 487
Batch on Device 0 computed in 0.7398519515991211 seconds.
tensor([0.2978], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354356050491333
Time for loss calculation for target: 0.011819124221801758
Time for Loss backward: 1.7889461517333984
Time needed for the batch 2.9033546447753906
Time needed for logging 0.007035255432128906
Training epoch 0 | batch 488
Batch on Device 0 computed in 0.7398965358734131 seconds.
tensor([0.6097], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544025421142578
Time for loss calculation for target: 0.011742830276489258
Time for Loss backward: 1.8048973083496094
Time needed for the batch 2.9184350967407227
Time needed for logging 0.002058267593383789
Training epoch 0 | batch 489
Batch on Device 0 computed in 0.7399606704711914 seconds.
tensor([0.4530], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543543815612793
Time for loss calculation for target: 0.011783599853515625
Time for Loss backward: 1.7926464080810547
Time needed for the batch 2.9073033332824707
Time needed for logging 0.0070438385009765625
Training epoch 0 | batch 490
Batch on Device 0 computed in 0.7399260997772217 seconds.
tensor([0.5210], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544178009033203
Time for loss calculation for target: 0.011811256408691406
Time for Loss backward: 1.78916335105896
Time needed for the batch 2.9033548831939697
Time needed for logging 0.007258892059326172
Training epoch 0 | batch 491
Batch on Device 0 computed in 0.7398121356964111 seconds.
tensor([0.3027], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543527126312256
Time for loss calculation for target: 0.011884927749633789
Time for Loss backward: 1.7905356884002686
Time needed for the batch 2.9045965671539307
Time needed for logging 0.007280111312866211
Training epoch 0 | batch 492
Batch on Device 0 computed in 0.7399337291717529 seconds.
tensor([0.3026], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436129570007324
Time for loss calculation for target: 0.011888504028320312
Time for Loss backward: 1.7903251647949219
Time needed for the batch 2.9046716690063477
Time needed for logging 0.007068634033203125
Training epoch 0 | batch 493
Batch on Device 0 computed in 0.7398192882537842 seconds.
tensor([0.3770], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445523262023926
Time for loss calculation for target: 0.011834383010864258
Time for Loss backward: 1.7876842021942139
Time needed for the batch 2.9019131660461426
Time needed for logging 0.007135152816772461
Training epoch 0 | batch 494
Batch on Device 0 computed in 0.7421972751617432 seconds.
tensor([0.3993], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354388952255249
Time for loss calculation for target: 0.011811971664428711
Time for Loss backward: 1.7872273921966553
Time needed for the batch 2.9040980339050293
Time needed for logging 0.007250785827636719
Training epoch 0 | batch 495
Batch on Device 0 computed in 0.7423176765441895 seconds.
tensor([0.3724], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544034957885742
Time for loss calculation for target: 0.011816263198852539
Time for Loss backward: 1.7907295227050781
Time needed for the batch 2.9075357913970947
Time needed for logging 0.007243156433105469
Training epoch 0 | batch 496
Batch on Device 0 computed in 0.7399194240570068 seconds.
tensor([0.4379], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35492920875549316
Time for loss calculation for target: 0.01209259033203125
Time for Loss backward: 1.7941207885742188
Time needed for the batch 2.909470319747925
Time needed for logging 0.007142066955566406
Training epoch 0 | batch 497
Batch on Device 0 computed in 0.7399566173553467 seconds.
tensor([0.3136], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442233085632324
Time for loss calculation for target: 0.011899948120117188
Time for Loss backward: 1.7921311855316162
Time needed for the batch 2.9066708087921143
Time needed for logging 0.0071942806243896484
Training epoch 0 | batch 498
Batch on Device 0 computed in 0.7398052215576172 seconds.
tensor([0.4423], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543534278869629
Time for loss calculation for target: 0.011785507202148438
Time for Loss backward: 1.7909483909606934
Time needed for the batch 2.9050140380859375
Time needed for logging 0.00724482536315918
Training epoch 0 | batch 499
Batch on Device 0 computed in 0.7400033473968506 seconds.
tensor([0.3781], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543815612792969
Time for loss calculation for target: 0.011751890182495117
Time for Loss backward: 1.7902777194976807
Time needed for the batch 2.9043540954589844
Time needed for logging 0.007031440734863281
Training epoch 0 | batch 500
Batch on Device 0 computed in 0.7399454116821289 seconds.
tensor([0.4183], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543713092803955
Time for loss calculation for target: 0.012004852294921875
Time for Loss backward: 1.7889416217803955
Time needed for the batch 3.051222324371338
Time needed for logging 4.5299530029296875e-05
Training epoch 0 | batch 501
Batch on Device 0 computed in 0.7400126457214355 seconds.
tensor([0.5809], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543705940246582
Time for loss calculation for target: 0.011749982833862305
Time for Loss backward: 1.7925374507904053
Time needed for the batch 2.9130520820617676
Time needed for logging 0.04060101509094238
Training epoch 0 | batch 502
Batch on Device 0 computed in 0.7398748397827148 seconds.
tensor([0.4344], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443592071533203
Time for loss calculation for target: 0.011826753616333008
Time for Loss backward: 1.788139820098877
Time needed for the batch 2.9025797843933105
Time needed for logging 0.00722193717956543
Training epoch 0 | batch 503
Batch on Device 0 computed in 0.7398464679718018 seconds.
tensor([0.4499], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35432958602905273
Time for loss calculation for target: 0.011864900588989258
Time for Loss backward: 1.786703109741211
Time needed for the batch 2.9007022380828857
Time needed for logging 0.0073316097259521484
Training epoch 0 | batch 504
Batch on Device 0 computed in 0.741645336151123 seconds.
tensor([0.2882], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543429374694824
Time for loss calculation for target: 0.01179647445678711
Time for Loss backward: 1.7876167297363281
Time needed for the batch 2.9041857719421387
Time needed for logging 0.007236003875732422
Training epoch 0 | batch 505
Batch on Device 0 computed in 0.7398948669433594 seconds.
tensor([0.9489], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436010360717773
Time for loss calculation for target: 0.01176762580871582
Time for Loss backward: 1.79374361038208
Time needed for the batch 2.912022590637207
Time needed for logging 0.00725555419921875
Training epoch 0 | batch 506
Batch on Device 0 computed in 0.7399735450744629 seconds.
tensor([0.4147], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544340133666992
Time for loss calculation for target: 0.01180267333984375
Time for Loss backward: 1.7915856838226318
Time needed for the batch 2.9058163166046143
Time needed for logging 0.0071299076080322266
Training epoch 0 | batch 507
Batch on Device 0 computed in 0.7399961948394775 seconds.
tensor([0.6098], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354419469833374
Time for loss calculation for target: 0.011778116226196289
Time for Loss backward: 1.7902913093566895
Time needed for the batch 2.9078242778778076
Time needed for logging 0.007060050964355469
Training epoch 0 | batch 508
Batch on Device 0 computed in 0.7398858070373535 seconds.
tensor([0.5276], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436415672302246
Time for loss calculation for target: 0.011828184127807617
Time for Loss backward: 1.7875866889953613
Time needed for the batch 2.901604652404785
Time needed for logging 0.0071871280670166016
Training epoch 0 | batch 509
Batch on Device 0 computed in 0.7434799671173096 seconds.
tensor([0.1955], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543522357940674
Time for loss calculation for target: 0.011822938919067383
Time for Loss backward: 1.792351245880127
Time needed for the batch 2.910640001296997
Time needed for logging 0.007170915603637695
Training epoch 0 | batch 510
Batch on Device 0 computed in 0.7398512363433838 seconds.
tensor([0.2355], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543212413787842
Time for loss calculation for target: 0.011791706085205078
Time for Loss backward: 1.791060209274292
Time needed for the batch 2.904757261276245
Time needed for logging 0.0073206424713134766
Training epoch 0 | batch 511
Batch on Device 0 computed in 0.7398576736450195 seconds.
tensor([0.4269], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543574810028076
Time for loss calculation for target: 0.01182699203491211
Time for Loss backward: 1.7900903224945068
Time needed for the batch 2.90427565574646
Time needed for logging 0.007325887680053711
Training epoch 0 | batch 512
Batch on Device 0 computed in 0.7398874759674072 seconds.
tensor([0.4694], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543887138366699
Time for loss calculation for target: 0.011799335479736328
Time for Loss backward: 1.7904012203216553
Time needed for the batch 2.9046618938446045
Time needed for logging 0.0071680545806884766
Training epoch 0 | batch 513
Batch on Device 0 computed in 0.7399451732635498 seconds.
tensor([0.2151], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35431909561157227
Time for loss calculation for target: 0.011711359024047852
Time for Loss backward: 1.791010856628418
Time needed for the batch 2.9050421714782715
Time needed for logging 0.007122516632080078
Training epoch 0 | batch 514
Batch on Device 0 computed in 0.7413043975830078 seconds.
tensor([0.6427], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543727397918701
Time for loss calculation for target: 0.011847257614135742
Time for Loss backward: 1.7917368412017822
Time needed for the batch 2.9071757793426514
Time needed for logging 0.007101535797119141
Training epoch 0 | batch 515
Batch on Device 0 computed in 0.7400121688842773 seconds.
tensor([0.3224], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545496463775635
Time for loss calculation for target: 0.011909723281860352
Time for Loss backward: 1.7904255390167236
Time needed for the batch 2.904819965362549
Time needed for logging 0.007488250732421875
Training epoch 0 | batch 516
Batch on Device 0 computed in 0.7475643157958984 seconds.
tensor([0.6689], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543660640716553
Time for loss calculation for target: 0.011789321899414062
Time for Loss backward: 1.7895970344543457
Time needed for the batch 2.9117534160614014
Time needed for logging 0.0071680545806884766
Training epoch 0 | batch 517
Batch on Device 0 computed in 0.7399508953094482 seconds.
tensor([0.3789], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543529510498047
Time for loss calculation for target: 0.011817455291748047
Time for Loss backward: 1.7928869724273682
Time needed for the batch 2.907050609588623
Time needed for logging 0.007086038589477539
Training epoch 0 | batch 518
Batch on Device 0 computed in 0.7400202751159668 seconds.
tensor([0.1942], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544142246246338
Time for loss calculation for target: 0.011821746826171875
Time for Loss backward: 1.7871813774108887
Time needed for the batch 2.901479959487915
Time needed for logging 0.007485628128051758
Training epoch 0 | batch 519
Batch on Device 0 computed in 0.7424008846282959 seconds.
tensor([0.8945], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439586639404297
Time for loss calculation for target: 0.011984586715698242
Time for Loss backward: 1.790937900543213
Time needed for the batch 2.9081220626831055
Time needed for logging 0.007504463195800781
Training epoch 0 | batch 520
Batch on Device 0 computed in 0.748845100402832 seconds.
tensor([0.6838], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445237159729004
Time for loss calculation for target: 0.011757135391235352
Time for Loss backward: 1.7928555011749268
Time needed for the batch 2.916239023208618
Time needed for logging 0.0067598819732666016
Training epoch 0 | batch 521
Batch on Device 0 computed in 0.7399485111236572 seconds.
tensor([0.2568], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543727397918701
Time for loss calculation for target: 0.011678218841552734
Time for Loss backward: 1.7920951843261719
Time needed for the batch 2.9056577682495117
Time needed for logging 0.006690025329589844
Training epoch 0 | batch 522
Batch on Device 0 computed in 0.7406444549560547 seconds.
tensor([0.2881], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544628620147705
Time for loss calculation for target: 0.011786222457885742
Time for Loss backward: 1.7938220500946045
Time needed for the batch 2.9080283641815186
Time needed for logging 0.0071277618408203125
Training epoch 0 | batch 523
Batch on Device 0 computed in 0.7400798797607422 seconds.
tensor([0.3918], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436415672302246
Time for loss calculation for target: 0.011732101440429688
Time for Loss backward: 1.786668300628662
Time needed for the batch 2.9010889530181885
Time needed for logging 0.007080793380737305
Training epoch 0 | batch 524
Batch on Device 0 computed in 0.7441813945770264 seconds.
tensor([0.5065], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543431758880615
Time for loss calculation for target: 0.011775970458984375
Time for Loss backward: 1.7913103103637695
Time needed for the batch 2.910670518875122
Time needed for logging 0.0071294307708740234
Training epoch 0 | batch 525
Batch on Device 0 computed in 0.7401630878448486 seconds.
tensor([0.3548], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436487197875977
Time for loss calculation for target: 0.011768341064453125
Time for Loss backward: 1.7909550666809082
Time needed for the batch 2.9056615829467773
Time needed for logging 0.007105112075805664
Training epoch 0 | batch 526
Batch on Device 0 computed in 0.7400343418121338 seconds.
tensor([0.4715], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440683364868164
Time for loss calculation for target: 0.012038946151733398
Time for Loss backward: 1.7860887050628662
Time needed for the batch 2.9005849361419678
Time needed for logging 0.007132530212402344
Training epoch 0 | batch 527
Batch on Device 0 computed in 0.7430167198181152 seconds.
tensor([0.4396], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543574810028076
Time for loss calculation for target: 0.012051582336425781
Time for Loss backward: 1.7909822463989258
Time needed for the batch 2.908461570739746
Time needed for logging 0.007788419723510742
Training epoch 0 | batch 528
Batch on Device 0 computed in 0.7400188446044922 seconds.
tensor([0.6189], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436248779296875
Time for loss calculation for target: 0.011760950088500977
Time for Loss backward: 1.786062479019165
Time needed for the batch 2.9006264209747314
Time needed for logging 0.00704503059387207
Training epoch 0 | batch 529
Batch on Device 0 computed in 0.7410686016082764 seconds.
tensor([0.6959], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543860912322998
Time for loss calculation for target: 0.011894702911376953
Time for Loss backward: 1.7902333736419678
Time needed for the batch 2.906873941421509
Time needed for logging 0.0072100162506103516
Training epoch 0 | batch 530
Batch on Device 0 computed in 0.7398755550384521 seconds.
tensor([0.4129], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543992042541504
Time for loss calculation for target: 0.011836767196655273
Time for Loss backward: 1.7851386070251465
Time needed for the batch 2.899393081665039
Time needed for logging 0.007100820541381836
Training epoch 0 | batch 531
Batch on Device 0 computed in 0.744011640548706 seconds.
tensor([0.7187], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543570041656494
Time for loss calculation for target: 0.012058496475219727
Time for Loss backward: 1.783501148223877
Time needed for the batch 2.901984930038452
Time needed for logging 0.007155179977416992
Training epoch 0 | batch 532
Batch on Device 0 computed in 0.7424452304840088 seconds.
tensor([0.5823], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433340072631836
Time for loss calculation for target: 0.011766672134399414
Time for Loss backward: 1.790419101715088
Time needed for the batch 2.9070582389831543
Time needed for logging 0.0070111751556396484
Training epoch 0 | batch 533
Batch on Device 0 computed in 0.7398688793182373 seconds.
tensor([0.7650], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544497489929199
Time for loss calculation for target: 0.01188039779663086
Time for Loss backward: 1.7892637252807617
Time needed for the batch 2.9039180278778076
Time needed for logging 0.006964683532714844
Training epoch 0 | batch 534
Batch on Device 0 computed in 0.7398293018341064 seconds.
tensor([0.2915], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543424606323242
Time for loss calculation for target: 0.011868476867675781
Time for Loss backward: 1.78651762008667
Time needed for the batch 2.9004297256469727
Time needed for logging 0.007063627243041992
Training epoch 0 | batch 535
Batch on Device 0 computed in 0.743427038192749 seconds.
tensor([0.5279], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543548583984375
Time for loss calculation for target: 0.012238502502441406
Time for Loss backward: 1.788034200668335
Time needed for the batch 2.906836986541748
Time needed for logging 0.007036924362182617
Training epoch 0 | batch 536
Batch on Device 0 computed in 0.7398414611816406 seconds.
tensor([0.2774], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354323148727417
Time for loss calculation for target: 0.011871337890625
Time for Loss backward: 1.785477638244629
Time needed for the batch 2.8993098735809326
Time needed for logging 0.0070722103118896484
Training epoch 0 | batch 537
Batch on Device 0 computed in 0.7437310218811035 seconds.
tensor([0.3179], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543527126312256
Time for loss calculation for target: 0.011755228042602539
Time for Loss backward: 1.7918980121612549
Time needed for the batch 2.909848690032959
Time needed for logging 0.007093191146850586
Training epoch 0 | batch 538
Batch on Device 0 computed in 0.7402620315551758 seconds.
tensor([0.5124], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35431694984436035
Time for loss calculation for target: 0.011754751205444336
Time for Loss backward: 1.7859482765197754
Time needed for the batch 2.900888442993164
Time needed for logging 0.007042884826660156
Training epoch 0 | batch 539
Batch on Device 0 computed in 0.7432658672332764 seconds.
tensor([0.2041], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544328212738037
Time for loss calculation for target: 0.012099266052246094
Time for Loss backward: 1.7905991077423096
Time needed for the batch 2.9080724716186523
Time needed for logging 0.0071680545806884766
Training epoch 0 | batch 540
Batch on Device 0 computed in 0.7400281429290771 seconds.
tensor([0.7930], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543100357055664
Time for loss calculation for target: 0.011813879013061523
Time for Loss backward: 1.7898056507110596
Time needed for the batch 2.904177665710449
Time needed for logging 0.006956815719604492
Training epoch 0 | batch 541
Batch on Device 0 computed in 0.7398946285247803 seconds.
tensor([0.3755], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543236255645752
Time for loss calculation for target: 0.011857986450195312
Time for Loss backward: 1.790525197982788
Time needed for the batch 2.9053285121917725
Time needed for logging 0.0070552825927734375
Training epoch 0 | batch 542
Batch on Device 0 computed in 0.7398650646209717 seconds.
tensor([0.5156], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439324378967285
Time for loss calculation for target: 0.011777162551879883
Time for Loss backward: 1.7919096946716309
Time needed for the batch 2.906454086303711
Time needed for logging 0.007029056549072266
Training epoch 0 | batch 543
Batch on Device 0 computed in 0.7400712966918945 seconds.
tensor([0.4523], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437536239624023
Time for loss calculation for target: 0.011699438095092773
Time for Loss backward: 1.79007887840271
Time needed for the batch 2.905104637145996
Time needed for logging 0.007220745086669922
Training epoch 0 | batch 544
Batch on Device 0 computed in 0.7399606704711914 seconds.
tensor([0.3190], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543410301208496
Time for loss calculation for target: 0.011767864227294922
Time for Loss backward: 1.7916316986083984
Time needed for the batch 2.9056761264801025
Time needed for logging 0.0070345401763916016
Training epoch 0 | batch 545
Batch on Device 0 computed in 0.739870548248291 seconds.
tensor([0.5161], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439085960388184
Time for loss calculation for target: 0.011699438095092773
Time for Loss backward: 1.7904820442199707
Time needed for the batch 2.9040632247924805
Time needed for logging 0.007061481475830078
Training epoch 0 | batch 546
Batch on Device 0 computed in 0.7398364543914795 seconds.
tensor([0.3789], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543524742126465
Time for loss calculation for target: 0.011865615844726562
Time for Loss backward: 1.7901010513305664
Time needed for the batch 2.904249668121338
Time needed for logging 0.007089853286743164
Training epoch 0 | batch 547
Batch on Device 0 computed in 0.7398452758789062 seconds.
tensor([0.3375], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546028137207031
Time for loss calculation for target: 0.011998176574707031
Time for Loss backward: 1.7889292240142822
Time needed for the batch 2.903290033340454
Time needed for logging 0.0069615840911865234
Training epoch 0 | batch 548
Batch on Device 0 computed in 0.7399928569793701 seconds.
tensor([0.7153], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546454906463623
Time for loss calculation for target: 0.011946678161621094
Time for Loss backward: 1.7877209186553955
Time needed for the batch 2.9023597240448
Time needed for logging 0.007108926773071289
Training epoch 0 | batch 549
Batch on Device 0 computed in 0.739976167678833 seconds.
tensor([0.4570], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545684814453125
Time for loss calculation for target: 0.011904239654541016
Time for Loss backward: 1.7864291667938232
Time needed for the batch 2.9010329246520996
Time needed for logging 0.0069692134857177734
Training epoch 0 | batch 550
Batch on Device 0 computed in 0.7429995536804199 seconds.
tensor([0.5748], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436296463012695
Time for loss calculation for target: 0.011838197708129883
Time for Loss backward: 1.790130615234375
Time needed for the batch 2.9076576232910156
Time needed for logging 0.0070285797119140625
Training epoch 0 | batch 551
Batch on Device 0 computed in 0.7405555248260498 seconds.
tensor([0.7272], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544304370880127
Time for loss calculation for target: 0.011767387390136719
Time for Loss backward: 1.7898108959197998
Time needed for the batch 2.9046144485473633
Time needed for logging 0.00693058967590332
Training epoch 0 | batch 552
Batch on Device 0 computed in 0.7398829460144043 seconds.
tensor([0.3070], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433506965637207
Time for loss calculation for target: 0.011715888977050781
Time for Loss backward: 1.7859716415405273
Time needed for the batch 2.899782419204712
Time needed for logging 0.007136344909667969
Training epoch 0 | batch 553
Batch on Device 0 computed in 0.7439448833465576 seconds.
tensor([0.5201], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441160202026367
Time for loss calculation for target: 0.011822700500488281
Time for Loss backward: 1.7906761169433594
Time needed for the batch 2.909158706665039
Time needed for logging 0.006994009017944336
Training epoch 0 | batch 554
Batch on Device 0 computed in 0.7400155067443848 seconds.
tensor([0.3400], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544929027557373
Time for loss calculation for target: 0.011771678924560547
Time for Loss backward: 1.7996020317077637
Time needed for the batch 2.9135453701019287
Time needed for logging 0.00695347785949707
Training epoch 0 | batch 555
Batch on Device 0 computed in 0.7400364875793457 seconds.
tensor([0.5499], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544003963470459
Time for loss calculation for target: 0.011820793151855469
Time for Loss backward: 1.789423942565918
Time needed for the batch 2.9040615558624268
Time needed for logging 0.006684780120849609
Training epoch 0 | batch 556
Batch on Device 0 computed in 0.7398617267608643 seconds.
tensor([0.4072], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544273376464844
Time for loss calculation for target: 0.012238025665283203
Time for Loss backward: 1.7896182537078857
Time needed for the batch 2.9041495323181152
Time needed for logging 0.006812095642089844
Training epoch 0 | batch 557
Batch on Device 0 computed in 0.7399466037750244 seconds.
tensor([0.5031], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544325828552246
Time for loss calculation for target: 0.011773347854614258
Time for Loss backward: 1.788163185119629
Time needed for the batch 2.902233839035034
Time needed for logging 0.0070629119873046875
Training epoch 0 | batch 558
Batch on Device 0 computed in 0.7398419380187988 seconds.
tensor([0.4717], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442233085632324
Time for loss calculation for target: 0.011821985244750977
Time for Loss backward: 1.785078525543213
Time needed for the batch 2.8995561599731445
Time needed for logging 0.007055997848510742
Training epoch 0 | batch 559
Batch on Device 0 computed in 0.7467665672302246 seconds.
tensor([1.0368], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35431766510009766
Time for loss calculation for target: 0.011793375015258789
Time for Loss backward: 1.7844352722167969
Time needed for the batch 2.905303955078125
Time needed for logging 0.007008552551269531
Training epoch 0 | batch 560
Batch on Device 0 computed in 0.7442290782928467 seconds.
tensor([0.4752], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433125495910645
Time for loss calculation for target: 0.012029409408569336
Time for Loss backward: 1.7903368473052979
Time needed for the batch 2.908653974533081
Time needed for logging 0.0070552825927734375
Training epoch 0 | batch 561
Batch on Device 0 computed in 0.7398481369018555 seconds.
tensor([0.7135], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544001579284668
Time for loss calculation for target: 0.011807680130004883
Time for Loss backward: 1.7918922901153564
Time needed for the batch 2.905836820602417
Time needed for logging 0.007020235061645508
Training epoch 0 | batch 562
Batch on Device 0 computed in 0.7412734031677246 seconds.
tensor([0.4918], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543970584869385
Time for loss calculation for target: 0.011797189712524414
Time for Loss backward: 1.7877163887023926
Time needed for the batch 2.9031822681427
Time needed for logging 0.007023334503173828
Training epoch 0 | batch 563
Batch on Device 0 computed in 0.7434689998626709 seconds.
tensor([0.6757], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440564155578613
Time for loss calculation for target: 0.011683225631713867
Time for Loss backward: 1.7857837677001953
Time needed for the batch 2.903604507446289
Time needed for logging 0.0072329044342041016
Training epoch 0 | batch 564
Batch on Device 0 computed in 0.7439632415771484 seconds.
tensor([0.3150], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354414701461792
Time for loss calculation for target: 0.011600017547607422
Time for Loss backward: 1.7841691970825195
Time needed for the batch 2.901991844177246
Time needed for logging 0.0073163509368896484
Training epoch 0 | batch 565
Batch on Device 0 computed in 0.7448279857635498 seconds.
tensor([0.8218], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543703556060791
Time for loss calculation for target: 0.011658191680908203
Time for Loss backward: 1.7850620746612549
Time needed for the batch 2.903916597366333
Time needed for logging 0.007361888885498047
Training epoch 0 | batch 566
Batch on Device 0 computed in 0.7422997951507568 seconds.
tensor([0.3057], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544297218322754
Time for loss calculation for target: 0.01165628433227539
Time for Loss backward: 1.7855079174041748
Time needed for the batch 2.9018452167510986
Time needed for logging 0.007306337356567383
Training epoch 0 | batch 567
Batch on Device 0 computed in 0.7438602447509766 seconds.
tensor([0.3279], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543705940246582
Time for loss calculation for target: 0.011653661727905273
Time for Loss backward: 1.7842421531677246
Time needed for the batch 2.9021077156066895
Time needed for logging 0.007261037826538086
Training epoch 0 | batch 568
Batch on Device 0 computed in 0.7434110641479492 seconds.
tensor([0.5263], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544321060180664
Time for loss calculation for target: 0.011767148971557617
Time for Loss backward: 1.7853102684020996
Time needed for the batch 2.9028408527374268
Time needed for logging 0.0072956085205078125
Training epoch 0 | batch 569
Batch on Device 0 computed in 0.7438385486602783 seconds.
tensor([0.7398], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434746742248535
Time for loss calculation for target: 0.011693716049194336
Time for Loss backward: 1.783200740814209
Time needed for the batch 2.9005649089813232
Time needed for logging 0.007285356521606445
Training epoch 0 | batch 570
Batch on Device 0 computed in 0.7439069747924805 seconds.
tensor([0.7310], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544611930847168
Time for loss calculation for target: 0.011727571487426758
Time for Loss backward: 1.7844038009643555
Time needed for the batch 2.902498960494995
Time needed for logging 0.007346391677856445
Training epoch 0 | batch 571
Batch on Device 0 computed in 0.744112491607666 seconds.
tensor([0.4330], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543741703033447
Time for loss calculation for target: 0.011706352233886719
Time for Loss backward: 1.7914247512817383
Time needed for the batch 2.9094932079315186
Time needed for logging 0.007297039031982422
Training epoch 0 | batch 572
Batch on Device 0 computed in 0.7399706840515137 seconds.
tensor([0.1880], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543975353240967
Time for loss calculation for target: 0.011624574661254883
Time for Loss backward: 1.7911429405212402
Time needed for the batch 2.905080556869507
Time needed for logging 0.00720667839050293
Training epoch 0 | batch 573
Batch on Device 0 computed in 0.742377519607544 seconds.
tensor([0.7694], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440850257873535
Time for loss calculation for target: 0.011667728424072266
Time for Loss backward: 1.7850496768951416
Time needed for the batch 2.9013590812683105
Time needed for logging 0.007269859313964844
Training epoch 0 | batch 574
Batch on Device 0 computed in 0.7446300983428955 seconds.
tensor([0.2662], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437703132629395
Time for loss calculation for target: 0.011784553527832031
Time for Loss backward: 1.7889375686645508
Time needed for the batch 2.907837390899658
Time needed for logging 0.007283687591552734
Training epoch 0 | batch 575
Batch on Device 0 computed in 0.7399191856384277 seconds.
tensor([0.4064], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436224937438965
Time for loss calculation for target: 0.011705636978149414
Time for Loss backward: 1.78468918800354
Time needed for the batch 2.8986053466796875
Time needed for logging 0.007359027862548828
Training epoch 0 | batch 576
Batch on Device 0 computed in 0.7443034648895264 seconds.
tensor([0.5724], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439467430114746
Time for loss calculation for target: 0.0117950439453125
Time for Loss backward: 1.7882392406463623
Time needed for the batch 2.9067323207855225
Time needed for logging 0.007209062576293945
Training epoch 0 | batch 577
Batch on Device 0 computed in 0.7407515048980713 seconds.
tensor([0.3256], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543715476989746
Time for loss calculation for target: 0.011713981628417969
Time for Loss backward: 1.7888109683990479
Time needed for the batch 2.9050936698913574
Time needed for logging 0.007261514663696289
Training epoch 0 | batch 578
Batch on Device 0 computed in 0.7447679042816162 seconds.
tensor([0.4638], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544449806213379
Time for loss calculation for target: 0.011840581893920898
Time for Loss backward: 1.7848169803619385
Time needed for the batch 2.903822422027588
Time needed for logging 0.007205486297607422
Training epoch 0 | batch 579
Batch on Device 0 computed in 0.7447423934936523 seconds.
tensor([0.3011], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543860912322998
Time for loss calculation for target: 0.011669158935546875
Time for Loss backward: 1.7879912853240967
Time needed for the batch 2.906852960586548
Time needed for logging 0.007249355316162109
Training epoch 0 | batch 580
Batch on Device 0 computed in 0.740455150604248 seconds.
tensor([0.2803], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439372062683105
Time for loss calculation for target: 0.011823892593383789
Time for Loss backward: 1.7885706424713135
Time needed for the batch 2.903341293334961
Time needed for logging 0.0073316097259521484
Training epoch 0 | batch 581
Batch on Device 0 computed in 0.7400877475738525 seconds.
tensor([0.1916], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440659523010254
Time for loss calculation for target: 0.01172018051147461
Time for Loss backward: 1.7911732196807861
Time needed for the batch 2.905322790145874
Time needed for logging 0.007222890853881836
Training epoch 0 | batch 582
Batch on Device 0 computed in 0.7476677894592285 seconds.
tensor([0.4280], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443758964538574
Time for loss calculation for target: 0.011780500411987305
Time for Loss backward: 1.7900352478027344
Time needed for the batch 2.911970853805542
Time needed for logging 0.007241487503051758
Training epoch 0 | batch 583
Batch on Device 0 computed in 0.740067720413208 seconds.
tensor([0.4369], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35451722145080566
Time for loss calculation for target: 0.011580944061279297
Time for Loss backward: 1.7907886505126953
Time needed for the batch 2.904839277267456
Time needed for logging 0.007261753082275391
Training epoch 0 | batch 584
Batch on Device 0 computed in 0.7400803565979004 seconds.
tensor([0.1485], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543741703033447
Time for loss calculation for target: 0.011595010757446289
Time for Loss backward: 1.7896950244903564
Time needed for the batch 2.9036521911621094
Time needed for logging 0.007287740707397461
Training epoch 0 | batch 585
Batch on Device 0 computed in 0.7397959232330322 seconds.
tensor([0.3152], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543870449066162
Time for loss calculation for target: 0.011966466903686523
Time for Loss backward: 1.7915551662445068
Time needed for the batch 2.9057037830352783
Time needed for logging 0.007311344146728516
Training epoch 0 | batch 586
Batch on Device 0 computed in 0.7400245666503906 seconds.
tensor([0.4349], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543515205383301
Time for loss calculation for target: 0.011813879013061523
Time for Loss backward: 1.7892343997955322
Time needed for the batch 2.9034619331359863
Time needed for logging 0.007203102111816406
Training epoch 0 | batch 587
Batch on Device 0 computed in 0.7398769855499268 seconds.
tensor([0.3998], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543870449066162
Time for loss calculation for target: 0.011828184127807617
Time for Loss backward: 1.789747953414917
Time needed for the batch 2.9038751125335693
Time needed for logging 0.0072062015533447266
Training epoch 0 | batch 588
Batch on Device 0 computed in 0.7397916316986084 seconds.
tensor([0.4237], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543529510498047
Time for loss calculation for target: 0.011847972869873047
Time for Loss backward: 1.7843904495239258
Time needed for the batch 2.8986399173736572
Time needed for logging 0.006764888763427734
Training epoch 0 | batch 589
Batch on Device 0 computed in 0.744697093963623 seconds.
tensor([0.3558], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544042110443115
Time for loss calculation for target: 0.012095212936401367
Time for Loss backward: 1.7869689464569092
Time needed for the batch 2.9070420265197754
Time needed for logging 0.006778240203857422
Training epoch 0 | batch 590
Batch on Device 0 computed in 0.7405211925506592 seconds.
tensor([0.5188], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543679714202881
Time for loss calculation for target: 0.011869192123413086
Time for Loss backward: 1.7911288738250732
Time needed for the batch 2.905487537384033
Time needed for logging 0.007353782653808594
Training epoch 0 | batch 591
Batch on Device 0 computed in 0.7397429943084717 seconds.
tensor([0.5270], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440707206726074
Time for loss calculation for target: 0.011831998825073242
Time for Loss backward: 1.7893977165222168
Time needed for the batch 2.903719186782837
Time needed for logging 0.007102251052856445
Training epoch 0 | batch 592
Batch on Device 0 computed in 0.7398796081542969 seconds.
tensor([0.1150], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35435986518859863
Time for loss calculation for target: 0.01175832748413086
Time for Loss backward: 1.790790319442749
Time needed for the batch 2.904926061630249
Time needed for logging 0.007210493087768555
Training epoch 0 | batch 593
Batch on Device 0 computed in 0.7399265766143799 seconds.
tensor([0.3213], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354938268661499
Time for loss calculation for target: 0.01210165023803711
Time for Loss backward: 1.7916622161865234
Time needed for the batch 2.9122836589813232
Time needed for logging 0.007174015045166016
Training epoch 0 | batch 594
Batch on Device 0 computed in 0.7494640350341797 seconds.
tensor([0.3859], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436248779296875
Time for loss calculation for target: 0.01182246208190918
Time for Loss backward: 1.7892093658447266
Time needed for the batch 2.9127464294433594
Time needed for logging 0.00711369514465332
Training epoch 0 | batch 595
Batch on Device 0 computed in 0.7398679256439209 seconds.
tensor([0.4108], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543679714202881
Time for loss calculation for target: 0.011921167373657227
Time for Loss backward: 1.7887868881225586
Time needed for the batch 2.9031684398651123
Time needed for logging 0.0072040557861328125
Training epoch 0 | batch 596
Batch on Device 0 computed in 0.7400074005126953 seconds.
tensor([0.4579], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544456958770752
Time for loss calculation for target: 0.011873006820678711
Time for Loss backward: 1.8577406406402588
Time needed for the batch 2.972146511077881
Time needed for logging 0.007047891616821289
Training epoch 0 | batch 597
Batch on Device 0 computed in 0.7398827075958252 seconds.
tensor([0.4490], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354358434677124
Time for loss calculation for target: 0.011777877807617188
Time for Loss backward: 1.7907836437225342
Time needed for the batch 2.9049859046936035
Time needed for logging 0.007280111312866211
Training epoch 0 | batch 598
Batch on Device 0 computed in 0.7401316165924072 seconds.
tensor([0.6253], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354341983795166
Time for loss calculation for target: 0.011768579483032227
Time for Loss backward: 1.7902193069458008
Time needed for the batch 2.9043102264404297
Time needed for logging 0.006680011749267578
Training epoch 0 | batch 599
Batch on Device 0 computed in 0.7400963306427002 seconds.
tensor([0.3293], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441064834594727
Time for loss calculation for target: 0.011811971664428711
Time for Loss backward: 1.7904727458953857
Time needed for the batch 2.904930353164673
Time needed for logging 0.007265806198120117
Training epoch 0 | batch 600
Batch on Device 0 computed in 0.740027904510498 seconds.
tensor([0.5104], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439157485961914
Time for loss calculation for target: 0.011807680130004883
Time for Loss backward: 1.78955078125
Time needed for the batch 2.90399169921875
Time needed for logging 0.007174491882324219
Training epoch 0 | batch 601
Batch on Device 0 computed in 0.7400329113006592 seconds.
tensor([0.3164], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354400634765625
Time for loss calculation for target: 0.011752843856811523
Time for Loss backward: 1.7902097702026367
Time needed for the batch 2.904723882675171
Time needed for logging 0.0072519779205322266
Training epoch 0 | batch 602
Batch on Device 0 computed in 0.7400016784667969 seconds.
tensor([0.3317], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543887138366699
Time for loss calculation for target: 0.011831045150756836
Time for Loss backward: 1.7888400554656982
Time needed for the batch 2.9035069942474365
Time needed for logging 0.0072324275970458984
Training epoch 0 | batch 603
Batch on Device 0 computed in 0.7399909496307373 seconds.
tensor([0.4081], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437488555908203
Time for loss calculation for target: 0.011798620223999023
Time for Loss backward: 1.789851188659668
Time needed for the batch 2.904177188873291
Time needed for logging 0.007357597351074219
Training epoch 0 | batch 604
Batch on Device 0 computed in 0.7399322986602783 seconds.
tensor([0.7084], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544163703918457
Time for loss calculation for target: 0.011818885803222656
Time for Loss backward: 1.7898609638214111
Time needed for the batch 2.904083013534546
Time needed for logging 0.007106304168701172
Training epoch 0 | batch 605
Batch on Device 0 computed in 0.7398879528045654 seconds.
tensor([0.4949], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543553352355957
Time for loss calculation for target: 0.011816263198852539
Time for Loss backward: 1.7909801006317139
Time needed for the batch 2.905043601989746
Time needed for logging 0.007082223892211914
Training epoch 0 | batch 606
Batch on Device 0 computed in 0.7400121688842773 seconds.
tensor([0.3480], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544008731842041
Time for loss calculation for target: 0.011821269989013672
Time for Loss backward: 1.7928111553192139
Time needed for the batch 2.9076621532440186
Time needed for logging 0.008443355560302734
Training epoch 0 | batch 607
Batch on Device 0 computed in 0.740077018737793 seconds.
tensor([0.2871], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544487953186035
Time for loss calculation for target: 0.011738300323486328
Time for Loss backward: 1.789566993713379
Time needed for the batch 2.906752824783325
Time needed for logging 0.0070400238037109375
Training epoch 0 | batch 608
Batch on Device 0 computed in 0.7400543689727783 seconds.
tensor([0.4728], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544156551361084
Time for loss calculation for target: 0.011725425720214844
Time for Loss backward: 1.7914206981658936
Time needed for the batch 2.905667304992676
Time needed for logging 0.007154226303100586
Training epoch 0 | batch 609
Batch on Device 0 computed in 0.7400093078613281 seconds.
tensor([0.3532], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35438990592956543
Time for loss calculation for target: 0.01175832748413086
Time for Loss backward: 1.7901384830474854
Time needed for the batch 2.904353618621826
Time needed for logging 0.007176876068115234
Training epoch 0 | batch 610
Batch on Device 0 computed in 0.74019455909729 seconds.
tensor([0.5705], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354367733001709
Time for loss calculation for target: 0.011746883392333984
Time for Loss backward: 1.7862372398376465
Time needed for the batch 2.9004273414611816
Time needed for logging 0.00732874870300293
Training epoch 0 | batch 611
Batch on Device 0 computed in 0.7415966987609863 seconds.
tensor([0.3127], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543870449066162
Time for loss calculation for target: 0.011723756790161133
Time for Loss backward: 1.7861828804016113
Time needed for the batch 2.902229070663452
Time needed for logging 0.007249593734741211
Training epoch 0 | batch 612
Batch on Device 0 computed in 0.7429978847503662 seconds.
tensor([0.4024], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545420169830322
Time for loss calculation for target: 0.01178741455078125
Time for Loss backward: 1.7853643894195557
Time needed for the batch 2.9031882286071777
Time needed for logging 0.007405519485473633
Training epoch 0 | batch 613
Batch on Device 0 computed in 0.7421736717224121 seconds.
tensor([0.5214], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35468053817749023
Time for loss calculation for target: 0.011868000030517578
Time for Loss backward: 1.790759801864624
Time needed for the batch 2.9076993465423584
Time needed for logging 0.0071985721588134766
Training epoch 0 | batch 614
Batch on Device 0 computed in 0.7402989864349365 seconds.
tensor([0.3419], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35480260848999023
Time for loss calculation for target: 0.012262344360351562
Time for Loss backward: 1.7840921878814697
Time needed for the batch 2.8995347023010254
Time needed for logging 0.0072650909423828125
Training epoch 0 | batch 615
Batch on Device 0 computed in 0.7417466640472412 seconds.
tensor([0.5777], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437679290771484
Time for loss calculation for target: 0.011772394180297852
Time for Loss backward: 1.7854499816894531
Time needed for the batch 2.901279926300049
Time needed for logging 0.007355928421020508
Training epoch 0 | batch 616
Batch on Device 0 computed in 0.7425248622894287 seconds.
tensor([0.1831], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544425964355469
Time for loss calculation for target: 0.011766195297241211
Time for Loss backward: 1.7912273406982422
Time needed for the batch 2.9079320430755615
Time needed for logging 0.00735783576965332
Training epoch 0 | batch 617
Batch on Device 0 computed in 0.7399413585662842 seconds.
tensor([0.1288], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35490918159484863
Time for loss calculation for target: 0.01202249526977539
Time for Loss backward: 1.7882440090179443
Time needed for the batch 2.9034359455108643
Time needed for logging 0.0068511962890625
Training epoch 0 | batch 618
Batch on Device 0 computed in 0.7400169372558594 seconds.
tensor([0.5046], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544156551361084
Time for loss calculation for target: 0.012106895446777344
Time for Loss backward: 1.7900123596191406
Time needed for the batch 2.9046967029571533
Time needed for logging 0.007074594497680664
Training epoch 0 | batch 619
Batch on Device 0 computed in 0.7400431632995605 seconds.
tensor([0.5348], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544161319732666
Time for loss calculation for target: 0.01182246208190918
Time for Loss backward: 1.7891623973846436
Time needed for the batch 2.903188467025757
Time needed for logging 0.007093191146850586
Training epoch 0 | batch 620
Batch on Device 0 computed in 0.7447018623352051 seconds.
tensor([0.4025], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35438036918640137
Time for loss calculation for target: 0.01179361343383789
Time for Loss backward: 1.7909910678863525
Time needed for the batch 2.9098825454711914
Time needed for logging 0.0071103572845458984
Training epoch 0 | batch 621
Batch on Device 0 computed in 0.7401630878448486 seconds.
tensor([0.4156], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354428768157959
Time for loss calculation for target: 0.011806964874267578
Time for Loss backward: 1.790163516998291
Time needed for the batch 2.904359817504883
Time needed for logging 0.0072765350341796875
Training epoch 0 | batch 622
Batch on Device 0 computed in 0.7400755882263184 seconds.
tensor([0.4615], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440731048583984
Time for loss calculation for target: 0.012128591537475586
Time for Loss backward: 1.7888493537902832
Time needed for the batch 2.903432846069336
Time needed for logging 0.007135629653930664
Training epoch 0 | batch 623
Batch on Device 0 computed in 0.740018367767334 seconds.
tensor([0.3711], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3549473285675049
Time for loss calculation for target: 0.012006282806396484
Time for Loss backward: 1.7868196964263916
Time needed for the batch 2.901721954345703
Time needed for logging 0.0071790218353271484
Training epoch 0 | batch 624
Batch on Device 0 computed in 0.7399280071258545 seconds.
tensor([0.3558], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543362617492676
Time for loss calculation for target: 0.011816978454589844
Time for Loss backward: 1.7913322448730469
Time needed for the batch 2.904813051223755
Time needed for logging 0.007016658782958984
Training epoch 0 | batch 625
Batch on Device 0 computed in 0.7401156425476074 seconds.
tensor([0.2898], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543825149536133
Time for loss calculation for target: 0.011716842651367188
Time for Loss backward: 1.784266471862793
Time needed for the batch 2.8985342979431152
Time needed for logging 0.007185220718383789
Training epoch 0 | batch 626
Batch on Device 0 computed in 0.7430493831634521 seconds.
tensor([0.3926], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543980121612549
Time for loss calculation for target: 0.011877059936523438
Time for Loss backward: 1.784686803817749
Time needed for the batch 2.901716947555542
Time needed for logging 0.0071680545806884766
Training epoch 0 | batch 627
Batch on Device 0 computed in 0.7428388595581055 seconds.
tensor([0.3597], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35428476333618164
Time for loss calculation for target: 0.011768341064453125
Time for Loss backward: 1.7901744842529297
Time needed for the batch 2.9070661067962646
Time needed for logging 0.007115602493286133
Training epoch 0 | batch 628
Batch on Device 0 computed in 0.7398667335510254 seconds.
tensor([0.3999], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35449743270874023
Time for loss calculation for target: 0.011830568313598633
Time for Loss backward: 1.794386386871338
Time needed for the batch 2.9086384773254395
Time needed for logging 0.00696110725402832
Training epoch 0 | batch 629
Batch on Device 0 computed in 0.7399880886077881 seconds.
tensor([0.4645], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544905185699463
Time for loss calculation for target: 0.011688709259033203
Time for Loss backward: 1.79052734375
Time needed for the batch 2.904614210128784
Time needed for logging 0.007302999496459961
Training epoch 0 | batch 630
Batch on Device 0 computed in 0.7398345470428467 seconds.
tensor([0.5746], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354414701461792
Time for loss calculation for target: 0.011668682098388672
Time for Loss backward: 1.793389081954956
Time needed for the batch 2.907142400741577
Time needed for logging 0.0072901248931884766
Training epoch 0 | batch 631
Batch on Device 0 computed in 0.7399511337280273 seconds.
tensor([0.1851], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543992042541504
Time for loss calculation for target: 0.011725425720214844
Time for Loss backward: 1.790822982788086
Time needed for the batch 2.9049477577209473
Time needed for logging 0.00724029541015625
Training epoch 0 | batch 632
Batch on Device 0 computed in 0.7400379180908203 seconds.
tensor([0.2934], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35430026054382324
Time for loss calculation for target: 0.011708498001098633
Time for Loss backward: 1.7910878658294678
Time needed for the batch 2.9051759243011475
Time needed for logging 0.007324934005737305
Training epoch 0 | batch 633
Batch on Device 0 computed in 0.7403604984283447 seconds.
tensor([0.4814], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433387756347656
Time for loss calculation for target: 0.011686563491821289
Time for Loss backward: 1.7943027019500732
Time needed for the batch 2.9086105823516846
Time needed for logging 0.007162332534790039
Training epoch 0 | batch 634
Batch on Device 0 computed in 0.7400598526000977 seconds.
tensor([0.4033], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544352054595947
Time for loss calculation for target: 0.011794328689575195
Time for Loss backward: 1.7967700958251953
Time needed for the batch 2.911323070526123
Time needed for logging 0.007518291473388672
Training epoch 0 | batch 635
Batch on Device 0 computed in 0.7399625778198242 seconds.
tensor([0.4900], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547036647796631
Time for loss calculation for target: 0.011938333511352539
Time for Loss backward: 1.7898025512695312
Time needed for the batch 2.9047746658325195
Time needed for logging 0.0069427490234375
Training epoch 0 | batch 636
Batch on Device 0 computed in 0.739962100982666 seconds.
tensor([0.4403], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35474634170532227
Time for loss calculation for target: 0.011922359466552734
Time for Loss backward: 1.7861738204956055
Time needed for the batch 2.9009203910827637
Time needed for logging 0.007260799407958984
Training epoch 0 | batch 637
Batch on Device 0 computed in 0.7410097122192383 seconds.
tensor([0.4526], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543243408203125
Time for loss calculation for target: 0.011742115020751953
Time for Loss backward: 1.79180908203125
Time needed for the batch 2.907294273376465
Time needed for logging 0.006836652755737305
Training epoch 0 | batch 638
Batch on Device 0 computed in 0.7400438785552979 seconds.
tensor([0.6966], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35432887077331543
Time for loss calculation for target: 0.011751413345336914
Time for Loss backward: 1.790172815322876
Time needed for the batch 2.9038469791412354
Time needed for logging 0.0070514678955078125
Training epoch 0 | batch 639
Batch on Device 0 computed in 0.7401816844940186 seconds.
tensor([0.1415], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543522357940674
Time for loss calculation for target: 0.011767148971557617
Time for Loss backward: 1.7913928031921387
Time needed for the batch 2.905640125274658
Time needed for logging 0.007106781005859375
Training epoch 0 | batch 640
Batch on Device 0 computed in 0.7399234771728516 seconds.
tensor([0.5848], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543210029602051
Time for loss calculation for target: 0.011850833892822266
Time for Loss backward: 1.790402889251709
Time needed for the batch 2.904917001724243
Time needed for logging 0.006741523742675781
Training epoch 0 | batch 641
Batch on Device 0 computed in 0.7399568557739258 seconds.
tensor([0.4039], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440587997436523
Time for loss calculation for target: 0.011888742446899414
Time for Loss backward: 1.7917108535766602
Time needed for the batch 2.9057462215423584
Time needed for logging 0.0069980621337890625
Training epoch 0 | batch 642
Batch on Device 0 computed in 0.7398397922515869 seconds.
tensor([0.5547], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354428768157959
Time for loss calculation for target: 0.01179361343383789
Time for Loss backward: 1.7893245220184326
Time needed for the batch 2.903535842895508
Time needed for logging 0.006530284881591797
Training epoch 0 | batch 643
Batch on Device 0 computed in 0.7406115531921387 seconds.
tensor([0.5147], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543667793273926
Time for loss calculation for target: 0.011799335479736328
Time for Loss backward: 1.791245937347412
Time needed for the batch 2.9059503078460693
Time needed for logging 0.006585836410522461
Training epoch 0 | batch 644
Batch on Device 0 computed in 0.7398967742919922 seconds.
tensor([0.5721], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545265197753906
Time for loss calculation for target: 0.011908531188964844
Time for Loss backward: 1.7883639335632324
Time needed for the batch 2.902160167694092
Time needed for logging 0.0065288543701171875
Training epoch 0 | batch 645
Batch on Device 0 computed in 0.7419428825378418 seconds.
tensor([0.2897], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35465526580810547
Time for loss calculation for target: 0.012063741683959961
Time for Loss backward: 1.7905588150024414
Time needed for the batch 2.9069983959198
Time needed for logging 0.0071337223052978516
Training epoch 0 | batch 646
Batch on Device 0 computed in 0.740300178527832 seconds.
tensor([0.4797], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445284843444824
Time for loss calculation for target: 0.011701345443725586
Time for Loss backward: 1.7910332679748535
Time needed for the batch 2.905276298522949
Time needed for logging 0.007155656814575195
Training epoch 0 | batch 647
Batch on Device 0 computed in 0.7398416996002197 seconds.
tensor([0.3588], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543410301208496
Time for loss calculation for target: 0.011818170547485352
Time for Loss backward: 1.7894723415374756
Time needed for the batch 2.903327465057373
Time needed for logging 0.0070188045501708984
Training epoch 0 | batch 648
Batch on Device 0 computed in 0.7401986122131348 seconds.
tensor([0.5029], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545656204223633
Time for loss calculation for target: 0.011865615844726562
Time for Loss backward: 1.7905921936035156
Time needed for the batch 2.9049580097198486
Time needed for logging 0.006905078887939453
Training epoch 0 | batch 649
Batch on Device 0 computed in 0.7399132251739502 seconds.
tensor([0.7800], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544459342956543
Time for loss calculation for target: 0.01184535026550293
Time for Loss backward: 1.7866559028625488
Time needed for the batch 2.9007110595703125
Time needed for logging 0.007317781448364258
Training epoch 0 | batch 650
Batch on Device 0 computed in 0.74237060546875 seconds.
tensor([0.2998], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544890880584717
Time for loss calculation for target: 0.01183462142944336
Time for Loss backward: 1.790663242340088
Time needed for the batch 2.907687187194824
Time needed for logging 0.007186412811279297
Training epoch 0 | batch 651
Batch on Device 0 computed in 0.7399163246154785 seconds.
tensor([0.2348], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354398250579834
Time for loss calculation for target: 0.011680364608764648
Time for Loss backward: 1.7912075519561768
Time needed for the batch 2.905256509780884
Time needed for logging 0.007064342498779297
Training epoch 0 | batch 652
Batch on Device 0 computed in 0.7397940158843994 seconds.
tensor([0.2892], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543229103088379
Time for loss calculation for target: 0.011827230453491211
Time for Loss backward: 1.7968952655792236
Time needed for the batch 2.9109127521514893
Time needed for logging 0.007086277008056641
Training epoch 0 | batch 653
Batch on Device 0 computed in 0.739863395690918 seconds.
tensor([0.5787], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445261001586914
Time for loss calculation for target: 0.011817455291748047
Time for Loss backward: 1.7923088073730469
Time needed for the batch 2.906633138656616
Time needed for logging 0.007300615310668945
Training epoch 0 | batch 654
Batch on Device 0 computed in 0.7398922443389893 seconds.
tensor([0.2035], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544180393218994
Time for loss calculation for target: 0.011796712875366211
Time for Loss backward: 1.7925951480865479
Time needed for the batch 2.906594753265381
Time needed for logging 0.007049083709716797
Training epoch 0 | batch 655
Batch on Device 0 computed in 0.7400476932525635 seconds.
tensor([0.3562], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354475736618042
Time for loss calculation for target: 0.012129545211791992
Time for Loss backward: 1.7867975234985352
Time needed for the batch 2.901644706726074
Time needed for logging 0.0072019100189208984
Training epoch 0 | batch 656
Batch on Device 0 computed in 0.7428097724914551 seconds.
tensor([0.4971], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543884754180908
Time for loss calculation for target: 0.011823415756225586
Time for Loss backward: 1.784611701965332
Time needed for the batch 2.9017128944396973
Time needed for logging 0.007216215133666992
Training epoch 0 | batch 657
Batch on Device 0 computed in 0.743980884552002 seconds.
tensor([0.3947], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543365001678467
Time for loss calculation for target: 0.011775493621826172
Time for Loss backward: 1.7889735698699951
Time needed for the batch 2.9074409008026123
Time needed for logging 0.007199525833129883
Training epoch 0 | batch 658
Batch on Device 0 computed in 0.7399849891662598 seconds.
tensor([0.2637], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543527126312256
Time for loss calculation for target: 0.01184535026550293
Time for Loss backward: 1.7930901050567627
Time needed for the batch 2.9071319103240967
Time needed for logging 0.007132768630981445
Training epoch 0 | batch 659
Batch on Device 0 computed in 0.739924430847168 seconds.
tensor([0.5596], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544445037841797
Time for loss calculation for target: 0.01206207275390625
Time for Loss backward: 1.7908270359039307
Time needed for the batch 2.905189037322998
Time needed for logging 0.00724482536315918
Training epoch 0 | batch 660
Batch on Device 0 computed in 0.7399551868438721 seconds.
tensor([0.3765], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547680377960205
Time for loss calculation for target: 0.011902093887329102
Time for Loss backward: 1.789609670639038
Time needed for the batch 2.9040050506591797
Time needed for logging 0.007160663604736328
Training epoch 0 | batch 661
Batch on Device 0 computed in 0.7398736476898193 seconds.
tensor([0.5207], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35435914993286133
Time for loss calculation for target: 0.01178121566772461
Time for Loss backward: 1.79097580909729
Time needed for the batch 2.9047834873199463
Time needed for logging 0.007285594940185547
Training epoch 0 | batch 662
Batch on Device 0 computed in 0.7398190498352051 seconds.
tensor([0.3164], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35444116592407227
Time for loss calculation for target: 0.011835575103759766
Time for Loss backward: 1.7892613410949707
Time needed for the batch 2.903435707092285
Time needed for logging 0.007205963134765625
Training epoch 0 | batch 663
Batch on Device 0 computed in 0.7398803234100342 seconds.
tensor([0.5120], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35483431816101074
Time for loss calculation for target: 0.012209892272949219
Time for Loss backward: 1.7892320156097412
Time needed for the batch 2.9042463302612305
Time needed for logging 0.00707554817199707
Training epoch 0 | batch 664
Batch on Device 0 computed in 0.7399682998657227 seconds.
tensor([0.2380], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544340133666992
Time for loss calculation for target: 0.011812448501586914
Time for Loss backward: 1.7875258922576904
Time needed for the batch 2.901554584503174
Time needed for logging 0.007348060607910156
Training epoch 0 | batch 665
Batch on Device 0 computed in 0.7399992942810059 seconds.
tensor([0.3331], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544790744781494
Time for loss calculation for target: 0.01185750961303711
Time for Loss backward: 1.789910078048706
Time needed for the batch 2.9048612117767334
Time needed for logging 0.007311820983886719
Training epoch 0 | batch 666
Batch on Device 0 computed in 0.7399218082427979 seconds.
tensor([0.5165], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445284843444824
Time for loss calculation for target: 0.011769771575927734
Time for Loss backward: 1.787755012512207
Time needed for the batch 2.9032413959503174
Time needed for logging 0.006622314453125
Training epoch 0 | batch 667
Batch on Device 0 computed in 0.7411794662475586 seconds.
tensor([0.3749], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544600009918213
Time for loss calculation for target: 0.011792659759521484
Time for Loss backward: 1.7908813953399658
Time needed for the batch 2.9062297344207764
Time needed for logging 0.0065653324127197266
Training epoch 0 | batch 668
Batch on Device 0 computed in 0.7400131225585938 seconds.
tensor([0.4968], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544142246246338
Time for loss calculation for target: 0.011896610260009766
Time for Loss backward: 1.7913382053375244
Time needed for the batch 2.905362367630005
Time needed for logging 0.006579160690307617
Training epoch 0 | batch 669
Batch on Device 0 computed in 0.7399561405181885 seconds.
tensor([0.4577], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443568229675293
Time for loss calculation for target: 0.011731147766113281
Time for Loss backward: 1.7913331985473633
Time needed for the batch 2.905045747756958
Time needed for logging 0.00670170783996582
Training epoch 0 | batch 670
Batch on Device 0 computed in 0.7399611473083496 seconds.
tensor([0.3370], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544039726257324
Time for loss calculation for target: 0.011832475662231445
Time for Loss backward: 1.8143877983093262
Time needed for the batch 2.9283506870269775
Time needed for logging 0.006668567657470703
Training epoch 0 | batch 671
Batch on Device 0 computed in 0.7399628162384033 seconds.
tensor([0.3589], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544132709503174
Time for loss calculation for target: 0.01181793212890625
Time for Loss backward: 1.788379430770874
Time needed for the batch 2.902207612991333
Time needed for logging 0.006546497344970703
Training epoch 0 | batch 672
Batch on Device 0 computed in 0.7413756847381592 seconds.
tensor([0.8055], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439562797546387
Time for loss calculation for target: 0.011744022369384766
Time for Loss backward: 1.792649269104004
Time needed for the batch 2.908670663833618
Time needed for logging 0.006406545639038086
Training epoch 0 | batch 673
Batch on Device 0 computed in 0.7399876117706299 seconds.
tensor([0.7387], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545055389404297
Time for loss calculation for target: 0.011730194091796875
Time for Loss backward: 1.7916183471679688
Time needed for the batch 2.9054367542266846
Time needed for logging 0.0064160823822021484
Training epoch 0 | batch 674
Batch on Device 0 computed in 0.7399215698242188 seconds.
tensor([0.7715], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440754890441895
Time for loss calculation for target: 0.011880159378051758
Time for Loss backward: 1.7847754955291748
Time needed for the batch 2.8984761238098145
Time needed for logging 0.006731748580932617
Training epoch 0 | batch 675
Batch on Device 0 computed in 0.7447478771209717 seconds.
tensor([0.3811], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440731048583984
Time for loss calculation for target: 0.0118255615234375
Time for Loss backward: 1.7878012657165527
Time needed for the batch 2.9065747261047363
Time needed for logging 0.0066187381744384766
Training epoch 0 | batch 676
Batch on Device 0 computed in 0.7416369915008545 seconds.
tensor([0.4288], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544297218322754
Time for loss calculation for target: 0.011818170547485352
Time for Loss backward: 1.7875196933746338
Time needed for the batch 2.9041693210601807
Time needed for logging 0.006510257720947266
Training epoch 0 | batch 677
Batch on Device 0 computed in 0.7436797618865967 seconds.
tensor([0.4734], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547818660736084
Time for loss calculation for target: 0.011984586715698242
Time for Loss backward: 1.7891325950622559
Time needed for the batch 2.9068551063537598
Time needed for logging 0.006536960601806641
Training epoch 0 | batch 678
Batch on Device 0 computed in 0.7410910129547119 seconds.
tensor([0.3634], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35466766357421875
Time for loss calculation for target: 0.011898040771484375
Time for Loss backward: 1.7842626571655273
Time needed for the batch 2.8997795581817627
Time needed for logging 0.006540060043334961
Training epoch 0 | batch 679
Batch on Device 0 computed in 0.7461597919464111 seconds.
tensor([0.5746], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546457290649414
Time for loss calculation for target: 0.011893987655639648
Time for Loss backward: 1.7899436950683594
Time needed for the batch 2.910456657409668
Time needed for logging 0.006597042083740234
Training epoch 0 | batch 680
Batch on Device 0 computed in 0.7408876419067383 seconds.
tensor([0.5435], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437774658203125
Time for loss calculation for target: 0.08041095733642578
Time for Loss backward: 1.7912535667419434
Time needed for the batch 2.9755215644836426
Time needed for logging 0.006577014923095703
Training epoch 0 | batch 681
Batch on Device 0 computed in 0.7398903369903564 seconds.
tensor([0.4033], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544449806213379
Time for loss calculation for target: 0.011670589447021484
Time for Loss backward: 1.7919890880584717
Time needed for the batch 2.9055891036987305
Time needed for logging 0.0065419673919677734
Training epoch 0 | batch 682
Batch on Device 0 computed in 0.7435970306396484 seconds.
tensor([0.9154], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35449862480163574
Time for loss calculation for target: 0.011778116226196289
Time for Loss backward: 1.7910809516906738
Time needed for the batch 2.9085822105407715
Time needed for logging 0.006420612335205078
Training epoch 0 | batch 683
Batch on Device 0 computed in 0.7400298118591309 seconds.
tensor([0.4826], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544647693634033
Time for loss calculation for target: 0.011750221252441406
Time for Loss backward: 1.7879819869995117
Time needed for the batch 2.9018783569335938
Time needed for logging 0.0064737796783447266
Training epoch 0 | batch 684
Batch on Device 0 computed in 0.7414579391479492 seconds.
tensor([0.3395], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354461669921875
Time for loss calculation for target: 0.01208806037902832
Time for Loss backward: 1.7825181484222412
Time needed for the batch 2.8981685638427734
Time needed for logging 0.006552219390869141
Training epoch 0 | batch 685
Batch on Device 0 computed in 0.746783971786499 seconds.
tensor([0.3165], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544154167175293
Time for loss calculation for target: 0.011731624603271484
Time for Loss backward: 1.78515625
Time needed for the batch 2.905597448348999
Time needed for logging 0.006535530090332031
Training epoch 0 | batch 686
Batch on Device 0 computed in 0.7458124160766602 seconds.
tensor([0.5351], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442090034484863
Time for loss calculation for target: 0.011744260787963867
Time for Loss backward: 1.7878592014312744
Time needed for the batch 2.9077558517456055
Time needed for logging 0.006824493408203125
Training epoch 0 | batch 687
Batch on Device 0 computed in 0.7425861358642578 seconds.
tensor([0.8799], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544435501098633
Time for loss calculation for target: 0.011759519577026367
Time for Loss backward: 1.7917237281799316
Time needed for the batch 2.908574104309082
Time needed for logging 0.0064733028411865234
Training epoch 0 | batch 688
Batch on Device 0 computed in 0.7400319576263428 seconds.
tensor([0.3517], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439062118530273
Time for loss calculation for target: 0.011734724044799805
Time for Loss backward: 1.7839314937591553
Time needed for the batch 2.897928237915039
Time needed for logging 0.006570100784301758
Training epoch 0 | batch 689
Batch on Device 0 computed in 0.7452292442321777 seconds.
tensor([0.5366], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35444116592407227
Time for loss calculation for target: 0.011911392211914062
Time for Loss backward: 1.7851219177246094
Time needed for the batch 2.904186487197876
Time needed for logging 0.006589651107788086
Training epoch 0 | batch 690
Batch on Device 0 computed in 0.7454421520233154 seconds.
tensor([0.8108], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433340072631836
Time for loss calculation for target: 0.011820316314697266
Time for Loss backward: 1.7840135097503662
Time needed for the batch 2.9028847217559814
Time needed for logging 0.0065915584564208984
Training epoch 0 | batch 691
Batch on Device 0 computed in 0.7461497783660889 seconds.
tensor([0.4900], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434699058532715
Time for loss calculation for target: 0.011853218078613281
Time for Loss backward: 1.784264326095581
Time needed for the batch 2.90425705909729
Time needed for logging 0.00664830207824707
Training epoch 0 | batch 692
Batch on Device 0 computed in 0.7446639537811279 seconds.
tensor([0.4284], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436344146728516
Time for loss calculation for target: 0.011920928955078125
Time for Loss backward: 1.7860169410705566
Time needed for the batch 2.904423236846924
Time needed for logging 0.0066149234771728516
Training epoch 0 | batch 693
Batch on Device 0 computed in 0.7432587146759033 seconds.
tensor([0.2987], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543703556060791
Time for loss calculation for target: 0.011848926544189453
Time for Loss backward: 1.7903928756713867
Time needed for the batch 2.9087917804718018
Time needed for logging 0.006471872329711914
Training epoch 0 | batch 694
Batch on Device 0 computed in 0.7404818534851074 seconds.
tensor([0.3816], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442638397216797
Time for loss calculation for target: 0.011755228042602539
Time for Loss backward: 1.7908735275268555
Time needed for the batch 2.9061079025268555
Time needed for logging 0.006672859191894531
Training epoch 0 | batch 695
Batch on Device 0 computed in 0.7399947643280029 seconds.
tensor([0.4651], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436534881591797
Time for loss calculation for target: 0.011767387390136719
Time for Loss backward: 1.7917027473449707
Time needed for the batch 2.9053494930267334
Time needed for logging 0.006560802459716797
Training epoch 0 | batch 696
Batch on Device 0 computed in 0.7399308681488037 seconds.
tensor([0.3394], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442543029785156
Time for loss calculation for target: 0.011819601058959961
Time for Loss backward: 1.7919964790344238
Time needed for the batch 2.9056756496429443
Time needed for logging 0.006455183029174805
Training epoch 0 | batch 697
Batch on Device 0 computed in 0.7400383949279785 seconds.
tensor([0.4463], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543741703033447
Time for loss calculation for target: 0.011737585067749023
Time for Loss backward: 1.7895455360412598
Time needed for the batch 2.903348922729492
Time needed for logging 0.0064849853515625
Training epoch 0 | batch 698
Batch on Device 0 computed in 0.7401940822601318 seconds.
tensor([0.3506], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544001579284668
Time for loss calculation for target: 0.011743307113647461
Time for Loss backward: 1.7886757850646973
Time needed for the batch 2.9027609825134277
Time needed for logging 0.006421804428100586
Training epoch 0 | batch 699
Batch on Device 0 computed in 0.7427167892456055 seconds.
tensor([0.5155], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35477375984191895
Time for loss calculation for target: 0.011868715286254883
Time for Loss backward: 1.7894854545593262
Time needed for the batch 2.9063265323638916
Time needed for logging 0.006142616271972656
Training epoch 0 | batch 700
Batch on Device 0 computed in 0.741344690322876 seconds.
tensor([0.6161], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35474252700805664
Time for loss calculation for target: 0.011969804763793945
Time for Loss backward: 1.791759967803955
Time needed for the batch 2.907806873321533
Time needed for logging 0.006384849548339844
Training epoch 0 | batch 701
Batch on Device 0 computed in 0.7398183345794678 seconds.
tensor([0.3628], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546178340911865
Time for loss calculation for target: 0.011878728866577148
Time for Loss backward: 1.793546438217163
Time needed for the batch 2.9074230194091797
Time needed for logging 0.006607532501220703
Training epoch 0 | batch 702
Batch on Device 0 computed in 0.7399449348449707 seconds.
tensor([0.5688], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543121814727783
Time for loss calculation for target: 0.011732101440429688
Time for Loss backward: 1.7889399528503418
Time needed for the batch 2.9022982120513916
Time needed for logging 0.006579160690307617
Training epoch 0 | batch 703
Batch on Device 0 computed in 0.740065336227417 seconds.
tensor([0.4852], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433006286621094
Time for loss calculation for target: 0.011888504028320312
Time for Loss backward: 1.7897846698760986
Time needed for the batch 2.9038732051849365
Time needed for logging 0.007280826568603516
Training epoch 0 | batch 704
Batch on Device 0 computed in 0.7400867938995361 seconds.
tensor([0.7725], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433506965637207
Time for loss calculation for target: 0.011760711669921875
Time for Loss backward: 1.7911057472229004
Time needed for the batch 2.9053897857666016
Time needed for logging 0.007339000701904297
Training epoch 0 | batch 705
Batch on Device 0 computed in 0.7399191856384277 seconds.
tensor([0.5081], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543844223022461
Time for loss calculation for target: 0.011786460876464844
Time for Loss backward: 1.7909009456634521
Time needed for the batch 2.904994249343872
Time needed for logging 0.006575107574462891
Training epoch 0 | batch 706
Batch on Device 0 computed in 0.740027904510498 seconds.
tensor([0.2932], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434770584106445
Time for loss calculation for target: 0.011848688125610352
Time for Loss backward: 1.79024338722229
Time needed for the batch 2.9040775299072266
Time needed for logging 0.0064618587493896484
Training epoch 0 | batch 707
Batch on Device 0 computed in 0.7400240898132324 seconds.
tensor([0.2940], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543558120727539
Time for loss calculation for target: 0.011649370193481445
Time for Loss backward: 1.7910583019256592
Time needed for the batch 2.9046902656555176
Time needed for logging 0.006602764129638672
Training epoch 0 | batch 708
Batch on Device 0 computed in 0.7398672103881836 seconds.
tensor([0.1918], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543426990509033
Time for loss calculation for target: 0.011792898178100586
Time for Loss backward: 1.7887108325958252
Time needed for the batch 2.9024362564086914
Time needed for logging 0.006539583206176758
Training epoch 0 | batch 709
Batch on Device 0 computed in 0.7413737773895264 seconds.
tensor([0.4230], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35431742668151855
Time for loss calculation for target: 0.011847257614135742
Time for Loss backward: 1.7850046157836914
Time needed for the batch 2.9001991748809814
Time needed for logging 0.0065441131591796875
Training epoch 0 | batch 710
Batch on Device 0 computed in 0.7467222213745117 seconds.
tensor([0.5463], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436177253723145
Time for loss calculation for target: 0.01180720329284668
Time for Loss backward: 1.7840800285339355
Time needed for the batch 2.9047772884368896
Time needed for logging 0.0068089962005615234
Training epoch 0 | batch 711
Batch on Device 0 computed in 0.7461888790130615 seconds.
tensor([0.6728], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442662239074707
Time for loss calculation for target: 0.011828184127807617
Time for Loss backward: 1.784564733505249
Time needed for the batch 2.9044365882873535
Time needed for logging 0.0065958499908447266
Training epoch 0 | batch 712
Batch on Device 0 computed in 0.746009111404419 seconds.
tensor([0.3995], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543410301208496
Time for loss calculation for target: 0.011813163757324219
Time for Loss backward: 1.7889463901519775
Time needed for the batch 2.9088118076324463
Time needed for logging 0.007092714309692383
Training epoch 0 | batch 713
Batch on Device 0 computed in 0.7399299144744873 seconds.
tensor([0.5933], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434913635253906
Time for loss calculation for target: 0.011779069900512695
Time for Loss backward: 1.7897584438323975
Time needed for the batch 2.9042563438415527
Time needed for logging 0.0071451663970947266
Training epoch 0 | batch 714
Batch on Device 0 computed in 0.7400453090667725 seconds.
tensor([0.9757], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439181327819824
Time for loss calculation for target: 0.011780023574829102
Time for Loss backward: 1.7974457740783691
Time needed for the batch 2.911536693572998
Time needed for logging 0.0072193145751953125
Training epoch 0 | batch 715
Batch on Device 0 computed in 0.7399435043334961 seconds.
tensor([0.5793], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440611839294434
Time for loss calculation for target: 0.011732101440429688
Time for Loss backward: 1.7901217937469482
Time needed for the batch 2.9041976928710938
Time needed for logging 0.0072672367095947266
Training epoch 0 | batch 716
Batch on Device 0 computed in 0.7399327754974365 seconds.
tensor([0.4162], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543517589569092
Time for loss calculation for target: 0.011725187301635742
Time for Loss backward: 1.7903385162353516
Time needed for the batch 2.9044299125671387
Time needed for logging 0.0073833465576171875
Training epoch 0 | batch 717
Batch on Device 0 computed in 0.7400097846984863 seconds.
tensor([0.5490], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543736934661865
Time for loss calculation for target: 0.011857271194458008
Time for Loss backward: 1.7922742366790771
Time needed for the batch 2.9066460132598877
Time needed for logging 0.007123231887817383
Training epoch 0 | batch 718
Batch on Device 0 computed in 0.7399032115936279 seconds.
tensor([0.5059], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544294834136963
Time for loss calculation for target: 0.011843681335449219
Time for Loss backward: 1.7906222343444824
Time needed for the batch 2.904862403869629
Time needed for logging 0.006983757019042969
Training epoch 0 | batch 719
Batch on Device 0 computed in 0.7400341033935547 seconds.
tensor([0.8466], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448217391967773
Time for loss calculation for target: 0.011868715286254883
Time for Loss backward: 1.7883007526397705
Time needed for the batch 2.9026687145233154
Time needed for logging 0.0076372623443603516
Training epoch 0 | batch 720
Batch on Device 0 computed in 0.7399494647979736 seconds.
tensor([0.3174], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439276695251465
Time for loss calculation for target: 0.011924982070922852
Time for Loss backward: 1.7899096012115479
Time needed for the batch 2.9046473503112793
Time needed for logging 0.006633758544921875
Training epoch 0 | batch 721
Batch on Device 0 computed in 0.7415511608123779 seconds.
tensor([0.5743], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35468530654907227
Time for loss calculation for target: 0.011975765228271484
Time for Loss backward: 1.7917609214782715
Time needed for the batch 2.9079954624176025
Time needed for logging 0.00655364990234375
Training epoch 0 | batch 722
Batch on Device 0 computed in 0.7398953437805176 seconds.
tensor([0.6227], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547804355621338
Time for loss calculation for target: 0.011912107467651367
Time for Loss backward: 1.7902820110321045
Time needed for the batch 2.904820442199707
Time needed for logging 0.00651240348815918
Training epoch 0 | batch 723
Batch on Device 0 computed in 0.740276575088501 seconds.
tensor([0.7423], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543992042541504
Time for loss calculation for target: 0.011790752410888672
Time for Loss backward: 1.7915019989013672
Time needed for the batch 2.905827760696411
Time needed for logging 0.006512165069580078
Training epoch 0 | batch 724
Batch on Device 0 computed in 0.7399754524230957 seconds.
tensor([0.2199], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544490337371826
Time for loss calculation for target: 0.011748075485229492
Time for Loss backward: 1.7900276184082031
Time needed for the batch 2.9037837982177734
Time needed for logging 0.0065233707427978516
Training epoch 0 | batch 725
Batch on Device 0 computed in 0.7413780689239502 seconds.
tensor([0.4138], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543987274169922
Time for loss calculation for target: 0.011747598648071289
Time for Loss backward: 1.7900333404541016
Time needed for the batch 2.905280113220215
Time needed for logging 0.006685733795166016
Training epoch 0 | batch 726
Batch on Device 0 computed in 0.7403044700622559 seconds.
tensor([0.4782], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354447603225708
Time for loss calculation for target: 0.011815309524536133
Time for Loss backward: 1.7890543937683105
Time needed for the batch 2.903721332550049
Time needed for logging 0.006543874740600586
Training epoch 0 | batch 727
Batch on Device 0 computed in 0.7411999702453613 seconds.
tensor([0.4509], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543717861175537
Time for loss calculation for target: 0.011832714080810547
Time for Loss backward: 1.7917819023132324
Time needed for the batch 2.9079949855804443
Time needed for logging 0.00651097297668457
Training epoch 0 | batch 728
Batch on Device 0 computed in 0.7398502826690674 seconds.
tensor([0.1220], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440826416015625
Time for loss calculation for target: 0.011698007583618164
Time for Loss backward: 1.7909536361694336
Time needed for the batch 2.904440402984619
Time needed for logging 0.006486415863037109
Training epoch 0 | batch 729
Batch on Device 0 computed in 0.7398936748504639 seconds.
tensor([0.5250], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543708324432373
Time for loss calculation for target: 0.012133598327636719
Time for Loss backward: 1.7909679412841797
Time needed for the batch 2.9050345420837402
Time needed for logging 0.006608009338378906
Training epoch 0 | batch 730
Batch on Device 0 computed in 0.7397968769073486 seconds.
tensor([0.3786], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433268547058105
Time for loss calculation for target: 0.011746644973754883
Time for Loss backward: 1.7902891635894775
Time needed for the batch 2.9037764072418213
Time needed for logging 0.007256984710693359
Training epoch 0 | batch 731
Batch on Device 0 computed in 0.7397198677062988 seconds.
tensor([0.1729], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3548920154571533
Time for loss calculation for target: 0.011866331100463867
Time for Loss backward: 1.792381763458252
Time needed for the batch 2.9069528579711914
Time needed for logging 0.007073402404785156
Training epoch 0 | batch 732
Batch on Device 0 computed in 0.7399618625640869 seconds.
tensor([0.3630], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544301986694336
Time for loss calculation for target: 0.011678457260131836
Time for Loss backward: 1.7910182476043701
Time needed for the batch 2.905254602432251
Time needed for logging 0.00738215446472168
Training epoch 0 | batch 733
Batch on Device 0 computed in 0.7399699687957764 seconds.
tensor([0.4548], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433220863342285
Time for loss calculation for target: 0.011793375015258789
Time for Loss backward: 1.789992094039917
Time needed for the batch 2.9041240215301514
Time needed for logging 0.007222890853881836
Training epoch 0 | batch 734
Batch on Device 0 computed in 0.7399177551269531 seconds.
tensor([0.3103], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440921783447266
Time for loss calculation for target: 0.011899709701538086
Time for Loss backward: 1.8554573059082031
Time needed for the batch 2.9697604179382324
Time needed for logging 0.00738215446472168
Training epoch 0 | batch 735
Batch on Device 0 computed in 0.7399795055389404 seconds.
tensor([0.5429], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544337749481201
Time for loss calculation for target: 0.011774539947509766
Time for Loss backward: 1.7842075824737549
Time needed for the batch 2.898554801940918
Time needed for logging 0.00719451904296875
Training epoch 0 | batch 736
Batch on Device 0 computed in 0.7432811260223389 seconds.
tensor([0.3965], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544790744781494
Time for loss calculation for target: 0.011788606643676758
Time for Loss backward: 1.7878670692443848
Time needed for the batch 2.9053258895874023
Time needed for logging 0.007116079330444336
Training epoch 0 | batch 737
Batch on Device 0 computed in 0.740009069442749 seconds.
tensor([0.3041], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442662239074707
Time for loss calculation for target: 0.011692523956298828
Time for Loss backward: 1.7885768413543701
Time needed for the batch 2.9025728702545166
Time needed for logging 0.0067903995513916016
Training epoch 0 | batch 738
Batch on Device 0 computed in 0.741278886795044 seconds.
tensor([0.9207], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445713996887207
Time for loss calculation for target: 0.011694908142089844
Time for Loss backward: 1.7908036708831787
Time needed for the batch 2.9060909748077393
Time needed for logging 0.007118940353393555
Training epoch 0 | batch 739
Batch on Device 0 computed in 0.7404141426086426 seconds.
tensor([0.4258], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35446739196777344
Time for loss calculation for target: 0.011752605438232422
Time for Loss backward: 1.8531358242034912
Time needed for the batch 2.9677343368530273
Time needed for logging 0.007252216339111328
Training epoch 0 | batch 740
Batch on Device 0 computed in 0.7448949813842773 seconds.
tensor([0.4911], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448336601257324
Time for loss calculation for target: 0.011710882186889648
Time for Loss backward: 1.7855467796325684
Time needed for the batch 2.9046475887298584
Time needed for logging 0.0073146820068359375
Training epoch 0 | batch 741
Batch on Device 0 computed in 0.7458291053771973 seconds.
tensor([0.6488], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354449987411499
Time for loss calculation for target: 0.012077569961547852
Time for Loss backward: 1.792374610900879
Time needed for the batch 2.9126272201538086
Time needed for logging 0.00723576545715332
Training epoch 0 | batch 742
Batch on Device 0 computed in 0.7400822639465332 seconds.
tensor([0.7070], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547630310058594
Time for loss calculation for target: 0.011940240859985352
Time for Loss backward: 1.8550641536712646
Time needed for the batch 2.9697747230529785
Time needed for logging 0.007233858108520508
Training epoch 0 | batch 743
Batch on Device 0 computed in 0.7410192489624023 seconds.
tensor([0.3599], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445332527160645
Time for loss calculation for target: 0.011677265167236328
Time for Loss backward: 1.7887728214263916
Time needed for the batch 2.903834104537964
Time needed for logging 0.007237434387207031
Training epoch 0 | batch 744
Batch on Device 0 computed in 0.7400014400482178 seconds.
tensor([0.4688], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544597625732422
Time for loss calculation for target: 0.011699438095092773
Time for Loss backward: 1.7901124954223633
Time needed for the batch 2.9042882919311523
Time needed for logging 0.007257699966430664
Training epoch 0 | batch 745
Batch on Device 0 computed in 0.740077018737793 seconds.
tensor([0.2194], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35481786727905273
Time for loss calculation for target: 0.011846303939819336
Time for Loss backward: 1.7900326251983643
Time needed for the batch 2.9047131538391113
Time needed for logging 0.007431507110595703
Training epoch 0 | batch 746
Batch on Device 0 computed in 0.7400562763214111 seconds.
tensor([0.4337], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35458970069885254
Time for loss calculation for target: 0.011852741241455078
Time for Loss backward: 1.7902495861053467
Time needed for the batch 2.904970407485962
Time needed for logging 0.007143735885620117
Training epoch 0 | batch 747
Batch on Device 0 computed in 0.7408344745635986 seconds.
tensor([0.5494], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544487953186035
Time for loss calculation for target: 0.011758089065551758
Time for Loss backward: 1.7885630130767822
Time needed for the batch 2.9035515785217285
Time needed for logging 0.007338285446166992
Training epoch 0 | batch 748
Batch on Device 0 computed in 0.7400100231170654 seconds.
tensor([0.4410], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544332981109619
Time for loss calculation for target: 0.011628866195678711
Time for Loss backward: 1.7897849082946777
Time needed for the batch 2.903766393661499
Time needed for logging 0.00722193717956543
Training epoch 0 | batch 749
Batch on Device 0 computed in 0.7400529384613037 seconds.
tensor([0.6588], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544609546661377
Time for loss calculation for target: 0.011777400970458984
Time for Loss backward: 1.7866923809051514
Time needed for the batch 2.90053129196167
Time needed for logging 0.007348537445068359
Training epoch 0 | batch 750
Batch on Device 0 computed in 0.7436861991882324 seconds.
tensor([0.4839], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442519187927246
Time for loss calculation for target: 0.08120059967041016
Time for Loss backward: 1.7867207527160645
Time needed for the batch 2.974118947982788
Time needed for logging 0.007185220718383789
Training epoch 0 | batch 751
Batch on Device 0 computed in 0.7403216361999512 seconds.
tensor([0.6088], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544306755065918
Time for loss calculation for target: 0.011615514755249023
Time for Loss backward: 1.7887699604034424
Time needed for the batch 2.9030709266662598
Time needed for logging 0.007049560546875
Training epoch 0 | batch 752
Batch on Device 0 computed in 0.7400765419006348 seconds.
tensor([0.4063], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441040992736816
Time for loss calculation for target: 0.011728525161743164
Time for Loss backward: 1.7883365154266357
Time needed for the batch 2.907259464263916
Time needed for logging 0.007291316986083984
Training epoch 0 | batch 753
Batch on Device 0 computed in 0.7401754856109619 seconds.
tensor([0.3108], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437655448913574
Time for loss calculation for target: 0.011723995208740234
Time for Loss backward: 1.7936787605285645
Time needed for the batch 2.9080734252929688
Time needed for logging 0.007248878479003906
Training epoch 0 | batch 754
Batch on Device 0 computed in 0.7400016784667969 seconds.
tensor([0.4385], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35444021224975586
Time for loss calculation for target: 0.011950969696044922
Time for Loss backward: 1.7907071113586426
Time needed for the batch 2.9051012992858887
Time needed for logging 0.007326364517211914
Training epoch 0 | batch 755
Batch on Device 0 computed in 0.7401611804962158 seconds.
tensor([0.3787], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448718070983887
Time for loss calculation for target: 0.011829376220703125
Time for Loss backward: 1.7897942066192627
Time needed for the batch 2.9042751789093018
Time needed for logging 0.007036447525024414
Training epoch 0 | batch 756
Batch on Device 0 computed in 0.740154504776001 seconds.
tensor([0.3826], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544299602508545
Time for loss calculation for target: 0.011753082275390625
Time for Loss backward: 1.790032148361206
Time needed for the batch 2.9044241905212402
Time needed for logging 0.007276058197021484
Training epoch 0 | batch 757
Batch on Device 0 computed in 0.7402157783508301 seconds.
tensor([0.3831], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544325828552246
Time for loss calculation for target: 0.011789321899414062
Time for Loss backward: 1.7904267311096191
Time needed for the batch 2.9044859409332275
Time needed for logging 0.007147312164306641
Training epoch 0 | batch 758
Batch on Device 0 computed in 0.7401955127716064 seconds.
tensor([0.4221], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440516471862793
Time for loss calculation for target: 0.01198434829711914
Time for Loss backward: 1.7869372367858887
Time needed for the batch 2.9014666080474854
Time needed for logging 0.007231473922729492
Training epoch 0 | batch 759
Batch on Device 0 computed in 0.7443382740020752 seconds.
tensor([0.2456], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440731048583984
Time for loss calculation for target: 0.011761188507080078
Time for Loss backward: 1.7882664203643799
Time needed for the batch 2.9067468643188477
Time needed for logging 0.007385730743408203
Training epoch 0 | batch 760
Batch on Device 0 computed in 0.7401068210601807 seconds.
tensor([0.5290], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437822341918945
Time for loss calculation for target: 0.01169276237487793
Time for Loss backward: 1.790191411972046
Time needed for the batch 2.9038920402526855
Time needed for logging 0.007401943206787109
Training epoch 0 | batch 761
Batch on Device 0 computed in 0.7401485443115234 seconds.
tensor([0.4747], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436153411865234
Time for loss calculation for target: 0.011850118637084961
Time for Loss backward: 1.7916181087493896
Time needed for the batch 2.9060893058776855
Time needed for logging 0.007220029830932617
Training epoch 0 | batch 762
Batch on Device 0 computed in 0.7399992942810059 seconds.
tensor([0.3563], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544478416442871
Time for loss calculation for target: 0.01199650764465332
Time for Loss backward: 1.7844939231872559
Time needed for the batch 2.899568557739258
Time needed for logging 0.00722193717956543
Training epoch 0 | batch 763
Batch on Device 0 computed in 0.742851972579956 seconds.
tensor([0.6297], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544774055480957
Time for loss calculation for target: 0.011713981628417969
Time for Loss backward: 1.791074275970459
Time needed for the batch 2.9082159996032715
Time needed for logging 0.007283210754394531
Training epoch 0 | batch 764
Batch on Device 0 computed in 0.7400908470153809 seconds.
tensor([0.7087], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448169708251953
Time for loss calculation for target: 0.011677742004394531
Time for Loss backward: 1.7839162349700928
Time needed for the batch 2.8982646465301514
Time needed for logging 0.006585597991943359
Training epoch 0 | batch 765
Batch on Device 0 computed in 0.7461912631988525 seconds.
tensor([0.5475], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445499420166016
Time for loss calculation for target: 0.011776924133300781
Time for Loss backward: 1.7857258319854736
Time needed for the batch 2.9057741165161133
Time needed for logging 0.00661778450012207
Training epoch 0 | batch 766
Batch on Device 0 computed in 0.7446634769439697 seconds.
tensor([0.2520], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544032573699951
Time for loss calculation for target: 0.012073755264282227
Time for Loss backward: 1.7828383445739746
Time needed for the batch 2.9026806354522705
Time needed for logging 0.006604433059692383
Training epoch 0 | batch 767
Batch on Device 0 computed in 0.7467136383056641 seconds.
tensor([0.4209], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443925857543945
Time for loss calculation for target: 0.011654853820800781
Time for Loss backward: 1.783402681350708
Time needed for the batch 2.9039933681488037
Time needed for logging 0.006824970245361328
Training epoch 0 | batch 768
Batch on Device 0 computed in 0.747023344039917 seconds.
tensor([0.4341], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543868064880371
Time for loss calculation for target: 0.011895895004272461
Time for Loss backward: 1.7903006076812744
Time needed for the batch 2.912635564804077
Time needed for logging 0.007127046585083008
Training epoch 0 | batch 769
Batch on Device 0 computed in 0.7399091720581055 seconds.
tensor([0.3176], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547861576080322
Time for loss calculation for target: 0.011783361434936523
Time for Loss backward: 1.790177583694458
Time needed for the batch 2.9047577381134033
Time needed for logging 0.007188558578491211
Training epoch 0 | batch 770
Batch on Device 0 computed in 0.7400996685028076 seconds.
tensor([0.4325], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440802574157715
Time for loss calculation for target: 0.011932134628295898
Time for Loss backward: 1.7898802757263184
Time needed for the batch 2.9043729305267334
Time needed for logging 0.007147789001464844
Training epoch 0 | batch 771
Batch on Device 0 computed in 0.7400856018066406 seconds.
tensor([0.1670], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443997383117676
Time for loss calculation for target: 0.01174020767211914
Time for Loss backward: 1.7895755767822266
Time needed for the batch 2.9041292667388916
Time needed for logging 0.0072956085205078125
Training epoch 0 | batch 772
Batch on Device 0 computed in 0.7400979995727539 seconds.
tensor([0.6058], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35450172424316406
Time for loss calculation for target: 0.011876106262207031
Time for Loss backward: 1.789851427078247
Time needed for the batch 2.9043004512786865
Time needed for logging 0.0071468353271484375
Training epoch 0 | batch 773
Batch on Device 0 computed in 0.7400047779083252 seconds.
tensor([0.4676], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434865951538086
Time for loss calculation for target: 0.011779546737670898
Time for Loss backward: 1.7925832271575928
Time needed for the batch 2.906710147857666
Time needed for logging 0.007141590118408203
Training epoch 0 | batch 774
Batch on Device 0 computed in 0.7400534152984619 seconds.
tensor([0.4205], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544454574584961
Time for loss calculation for target: 0.011813640594482422
Time for Loss backward: 1.7855966091156006
Time needed for the batch 2.899942398071289
Time needed for logging 0.0073091983795166016
Training epoch 0 | batch 775
Batch on Device 0 computed in 0.7444562911987305 seconds.
tensor([0.4075], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354442834854126
Time for loss calculation for target: 0.01192784309387207
Time for Loss backward: 1.7918484210968018
Time needed for the batch 2.910848617553711
Time needed for logging 0.007096767425537109
Training epoch 0 | batch 776
Batch on Device 0 computed in 0.7400963306427002 seconds.
tensor([0.4354], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545103073120117
Time for loss calculation for target: 0.011851310729980469
Time for Loss backward: 1.7906181812286377
Time needed for the batch 2.905036449432373
Time needed for logging 0.007034778594970703
Training epoch 0 | batch 777
Batch on Device 0 computed in 0.7401008605957031 seconds.
tensor([0.3692], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543884754180908
Time for loss calculation for target: 0.011756658554077148
Time for Loss backward: 1.793067216873169
Time needed for the batch 2.907196521759033
Time needed for logging 0.007105350494384766
Training epoch 0 | batch 778
Batch on Device 0 computed in 0.7400820255279541 seconds.
tensor([0.4789], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545093536376953
Time for loss calculation for target: 0.01177835464477539
Time for Loss backward: 1.7925646305084229
Time needed for the batch 2.906327724456787
Time needed for logging 0.006968021392822266
Training epoch 0 | batch 779
Batch on Device 0 computed in 0.7402482032775879 seconds.
tensor([0.4173], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437989234924316
Time for loss calculation for target: 0.01189732551574707
Time for Loss backward: 1.7890758514404297
Time needed for the batch 2.904029607772827
Time needed for logging 0.006967306137084961
Training epoch 0 | batch 780
Batch on Device 0 computed in 0.7426140308380127 seconds.
tensor([0.3958], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443592071533203
Time for loss calculation for target: 0.011792182922363281
Time for Loss backward: 1.78668212890625
Time needed for the batch 2.903536081314087
Time needed for logging 0.007261753082275391
Training epoch 0 | batch 781
Batch on Device 0 computed in 0.743006706237793 seconds.
tensor([0.5037], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448336601257324
Time for loss calculation for target: 0.011800289154052734
Time for Loss backward: 1.7911357879638672
Time needed for the batch 2.908611297607422
Time needed for logging 0.006992340087890625
Training epoch 0 | batch 782
Batch on Device 0 computed in 0.7400343418121338 seconds.
tensor([0.5879], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544609546661377
Time for loss calculation for target: 0.011760950088500977
Time for Loss backward: 1.7900185585021973
Time needed for the batch 2.90433669090271
Time needed for logging 0.0070590972900390625
Training epoch 0 | batch 783
Batch on Device 0 computed in 0.7399070262908936 seconds.
tensor([0.6772], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442280769348145
Time for loss calculation for target: 0.011769533157348633
Time for Loss backward: 1.7867097854614258
Time needed for the batch 2.900735855102539
Time needed for logging 0.007366180419921875
Training epoch 0 | batch 784
Batch on Device 0 computed in 0.7400336265563965 seconds.
tensor([0.4231], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440826416015625
Time for loss calculation for target: 0.011798858642578125
Time for Loss backward: 1.786309003829956
Time needed for the batch 2.900214195251465
Time needed for logging 0.007404804229736328
Training epoch 0 | batch 785
Batch on Device 0 computed in 0.7424142360687256 seconds.
tensor([0.4125], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448741912841797
Time for loss calculation for target: 0.011843442916870117
Time for Loss backward: 1.7907593250274658
Time needed for the batch 2.907977342605591
Time needed for logging 0.007230997085571289
Training epoch 0 | batch 786
Batch on Device 0 computed in 0.7401983737945557 seconds.
tensor([0.4266], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545064926147461
Time for loss calculation for target: 0.011821985244750977
Time for Loss backward: 1.7897639274597168
Time needed for the batch 2.9041941165924072
Time needed for logging 0.007264375686645508
Training epoch 0 | batch 787
Batch on Device 0 computed in 0.7400977611541748 seconds.
tensor([0.4137], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544886112213135
Time for loss calculation for target: 0.011873245239257812
Time for Loss backward: 1.79063081741333
Time needed for the batch 2.905318260192871
Time needed for logging 0.00736689567565918
Training epoch 0 | batch 788
Batch on Device 0 computed in 0.7401628494262695 seconds.
tensor([0.4916], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544936180114746
Time for loss calculation for target: 0.011800289154052734
Time for Loss backward: 1.7918219566345215
Time needed for the batch 2.9064691066741943
Time needed for logging 0.007221698760986328
Training epoch 0 | batch 789
Batch on Device 0 computed in 0.7400569915771484 seconds.
tensor([0.2145], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448265075683594
Time for loss calculation for target: 0.011646747589111328
Time for Loss backward: 1.7912790775299072
Time needed for the batch 2.905505657196045
Time needed for logging 0.00703740119934082
Training epoch 0 | batch 790
Batch on Device 0 computed in 0.740023136138916 seconds.
tensor([0.4935], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544645309448242
Time for loss calculation for target: 0.011798381805419922
Time for Loss backward: 1.791527509689331
Time needed for the batch 2.9056718349456787
Time needed for logging 0.0072116851806640625
Training epoch 0 | batch 791
Batch on Device 0 computed in 0.7400667667388916 seconds.
tensor([0.3706], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544654846191406
Time for loss calculation for target: 0.012418270111083984
Time for Loss backward: 1.7881412506103516
Time needed for the batch 2.907676935195923
Time needed for logging 0.007277250289916992
Training epoch 0 | batch 792
Batch on Device 0 computed in 0.7400851249694824 seconds.
tensor([0.3460], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35494279861450195
Time for loss calculation for target: 0.012018680572509766
Time for Loss backward: 1.7863047122955322
Time needed for the batch 2.9014880657196045
Time needed for logging 0.007287263870239258
Training epoch 0 | batch 793
Batch on Device 0 computed in 0.7425642013549805 seconds.
tensor([0.3988], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35499000549316406
Time for loss calculation for target: 0.012050628662109375
Time for Loss backward: 1.7900209426879883
Time needed for the batch 2.908031940460205
Time needed for logging 0.007207155227661133
Training epoch 0 | batch 794
Batch on Device 0 computed in 0.7401084899902344 seconds.
tensor([0.5152], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545093536376953
Time for loss calculation for target: 0.011837244033813477
Time for Loss backward: 1.7916531562805176
Time needed for the batch 2.9063329696655273
Time needed for logging 0.007643461227416992
Training epoch 0 | batch 795
Batch on Device 0 computed in 0.7400891780853271 seconds.
tensor([0.5307], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3549618721008301
Time for loss calculation for target: 0.01235508918762207
Time for Loss backward: 1.782278299331665
Time needed for the batch 2.898162603378296
Time needed for logging 0.007352590560913086
Training epoch 0 | batch 796
Batch on Device 0 computed in 0.7443852424621582 seconds.
tensor([0.1731], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545076847076416
Time for loss calculation for target: 0.011705398559570312
Time for Loss backward: 1.7882297039031982
Time needed for the batch 2.9070160388946533
Time needed for logging 0.007219552993774414
Training epoch 0 | batch 797
Batch on Device 0 computed in 0.7400312423706055 seconds.
tensor([0.3917], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544957637786865
Time for loss calculation for target: 0.011711835861206055
Time for Loss backward: 1.7860691547393799
Time needed for the batch 2.900045394897461
Time needed for logging 0.0071887969970703125
Training epoch 0 | batch 798
Batch on Device 0 computed in 0.746349573135376 seconds.
tensor([0.4712], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354461669921875
Time for loss calculation for target: 0.011769294738769531
Time for Loss backward: 1.7885565757751465
Time needed for the batch 2.909325361251831
Time needed for logging 0.0071027278900146484
Training epoch 0 | batch 799
Batch on Device 0 computed in 0.7401943206787109 seconds.
tensor([0.4523], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442686080932617
Time for loss calculation for target: 0.012028932571411133
Time for Loss backward: 1.7894675731658936
Time needed for the batch 2.9040353298187256
Time needed for logging 0.007094144821166992
Training epoch 0 | batch 800
Batch on Device 0 computed in 0.7401728630065918 seconds.
tensor([0.3606], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3550095558166504
Time for loss calculation for target: 0.011908292770385742
Time for Loss backward: 1.7894721031188965
Time needed for the batch 2.90451979637146
Time needed for logging 0.007354259490966797
Training epoch 0 | batch 801
Batch on Device 0 computed in 0.7402448654174805 seconds.
tensor([0.3821], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544278144836426
Time for loss calculation for target: 0.011651277542114258
Time for Loss backward: 1.7860231399536133
Time needed for the batch 2.9005062580108643
Time needed for logging 0.007123470306396484
Training epoch 0 | batch 802
Batch on Device 0 computed in 0.7439563274383545 seconds.
tensor([0.3688], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35460710525512695
Time for loss calculation for target: 0.011869430541992188
Time for Loss backward: 1.789637565612793
Time needed for the batch 2.9081692695617676
Time needed for logging 0.007155656814575195
Training epoch 0 | batch 803
Batch on Device 0 computed in 0.7402064800262451 seconds.
tensor([0.5119], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445427894592285
Time for loss calculation for target: 0.01193547248840332
Time for Loss backward: 1.788637638092041
Time needed for the batch 2.907167673110962
Time needed for logging 0.0071620941162109375
Training epoch 0 | batch 804
Batch on Device 0 computed in 0.7409591674804688 seconds.
tensor([0.2664], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35455870628356934
Time for loss calculation for target: 0.011690378189086914
Time for Loss backward: 1.7857630252838135
Time needed for the batch 2.9007956981658936
Time needed for logging 0.007132530212402344
Training epoch 0 | batch 805
Batch on Device 0 computed in 0.7446539402008057 seconds.
tensor([0.5337], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544352054595947
Time for loss calculation for target: 0.011731386184692383
Time for Loss backward: 1.7864611148834229
Time needed for the batch 2.905141830444336
Time needed for logging 0.0071773529052734375
Training epoch 0 | batch 806
Batch on Device 0 computed in 0.7437608242034912 seconds.
tensor([0.4049], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35447001457214355
Time for loss calculation for target: 0.011732339859008789
Time for Loss backward: 1.7868006229400635
Time needed for the batch 2.9047341346740723
Time needed for logging 0.0072231292724609375
Training epoch 0 | batch 807
Batch on Device 0 computed in 0.7433769702911377 seconds.
tensor([0.3258], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442447662353516
Time for loss calculation for target: 0.011943578720092773
Time for Loss backward: 1.7890112400054932
Time needed for the batch 2.9067511558532715
Time needed for logging 0.007166862487792969
Training epoch 0 | batch 808
Batch on Device 0 computed in 0.7404654026031494 seconds.
tensor([0.3135], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440659523010254
Time for loss calculation for target: 0.011690139770507812
Time for Loss backward: 1.7854077816009521
Time needed for the batch 2.9000167846679688
Time needed for logging 0.00716090202331543
Training epoch 0 | batch 809
Batch on Device 0 computed in 0.7458441257476807 seconds.
tensor([0.1425], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35464000701904297
Time for loss calculation for target: 0.01185297966003418
Time for Loss backward: 1.789032220840454
Time needed for the batch 2.909677028656006
Time needed for logging 0.007265567779541016
Training epoch 0 | batch 810
Batch on Device 0 computed in 0.7400631904602051 seconds.
tensor([0.3093], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544299602508545
Time for loss calculation for target: 0.011631250381469727
Time for Loss backward: 1.7843303680419922
Time needed for the batch 2.898571252822876
Time needed for logging 0.007160186767578125
Training epoch 0 | batch 811
Batch on Device 0 computed in 0.7449004650115967 seconds.
tensor([1.1441], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448360443115234
Time for loss calculation for target: 0.011816024780273438
Time for Loss backward: 1.7914280891418457
Time needed for the batch 2.910922050476074
Time needed for logging 0.007497549057006836
Training epoch 0 | batch 812
Batch on Device 0 computed in 0.7400493621826172 seconds.
tensor([0.4521], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544950485229492
Time for loss calculation for target: 0.08218550682067871
Time for Loss backward: 1.7850823402404785
Time needed for the batch 2.970167636871338
Time needed for logging 0.007173776626586914
Training epoch 0 | batch 813
Batch on Device 0 computed in 0.7401611804962158 seconds.
tensor([0.7458], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448479652404785
Time for loss calculation for target: 0.011752605438232422
Time for Loss backward: 1.788017988204956
Time needed for the batch 2.9023501873016357
Time needed for logging 0.007213592529296875
Training epoch 0 | batch 814
Batch on Device 0 computed in 0.7400870323181152 seconds.
tensor([0.5021], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354475736618042
Time for loss calculation for target: 0.011899232864379883
Time for Loss backward: 1.7903170585632324
Time needed for the batch 2.904766798019409
Time needed for logging 0.007374763488769531
Training epoch 0 | batch 815
Batch on Device 0 computed in 0.740074634552002 seconds.
tensor([0.3306], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543696403503418
Time for loss calculation for target: 0.011780977249145508
Time for Loss backward: 1.7853055000305176
Time needed for the batch 2.8997318744659424
Time needed for logging 0.007205963134765625
Training epoch 0 | batch 816
Batch on Device 0 computed in 0.746382474899292 seconds.
tensor([0.4753], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448718070983887
Time for loss calculation for target: 0.012098073959350586
Time for Loss backward: 1.7852146625518799
Time needed for the batch 2.906254291534424
Time needed for logging 0.0072498321533203125
Training epoch 0 | batch 817
Batch on Device 0 computed in 0.7436120510101318 seconds.
tensor([0.4424], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442519187927246
Time for loss calculation for target: 0.011725425720214844
Time for Loss backward: 1.789323329925537
Time needed for the batch 2.9071202278137207
Time needed for logging 0.007069826126098633
Training epoch 0 | batch 818
Batch on Device 0 computed in 0.7400972843170166 seconds.
tensor([0.3241], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543577194213867
Time for loss calculation for target: 0.011895418167114258
Time for Loss backward: 1.7897593975067139
Time needed for the batch 2.9039793014526367
Time needed for logging 0.007216691970825195
Training epoch 0 | batch 819
Batch on Device 0 computed in 0.7399706840515137 seconds.
tensor([0.3227], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354459285736084
Time for loss calculation for target: 0.011823415756225586
Time for Loss backward: 1.7845308780670166
Time needed for the batch 2.8982033729553223
Time needed for logging 0.007283926010131836
Training epoch 0 | batch 820
Batch on Device 0 computed in 0.7438123226165771 seconds.
tensor([0.4519], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439205169677734
Time for loss calculation for target: 0.012096881866455078
Time for Loss backward: 1.7869675159454346
Time needed for the batch 2.905735731124878
Time needed for logging 0.007298707962036133
Training epoch 0 | batch 821
Batch on Device 0 computed in 0.7399132251739502 seconds.
tensor([0.7295], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443615913391113
Time for loss calculation for target: 0.011804819107055664
Time for Loss backward: 1.7894198894500732
Time needed for the batch 2.903496742248535
Time needed for logging 0.007040977478027344
Training epoch 0 | batch 822
Batch on Device 0 computed in 0.7398955821990967 seconds.
tensor([0.7430], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543574810028076
Time for loss calculation for target: 0.011778831481933594
Time for Loss backward: 1.7825889587402344
Time needed for the batch 2.896719455718994
Time needed for logging 0.0072367191314697266
Training epoch 0 | batch 823
Batch on Device 0 computed in 0.7441146373748779 seconds.
tensor([0.3185], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35435986518859863
Time for loss calculation for target: 0.011785745620727539
Time for Loss backward: 1.7899975776672363
Time needed for the batch 2.9085681438446045
Time needed for logging 0.00745701789855957
Training epoch 0 | batch 824
Batch on Device 0 computed in 0.7399008274078369 seconds.
tensor([0.4155], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544020652770996
Time for loss calculation for target: 0.01202535629272461
Time for Loss backward: 1.7850589752197266
Time needed for the batch 2.8996849060058594
Time needed for logging 0.007261753082275391
Training epoch 0 | batch 825
Batch on Device 0 computed in 0.7434418201446533 seconds.
tensor([0.3528], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434865951538086
Time for loss calculation for target: 0.011706829071044922
Time for Loss backward: 1.790611743927002
Time needed for the batch 2.9080309867858887
Time needed for logging 0.007177591323852539
Training epoch 0 | batch 826
Batch on Device 0 computed in 0.7400162220001221 seconds.
tensor([0.3487], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543665409088135
Time for loss calculation for target: 0.011836528778076172
Time for Loss backward: 1.790560245513916
Time needed for the batch 2.9047975540161133
Time needed for logging 0.007136344909667969
Training epoch 0 | batch 827
Batch on Device 0 computed in 0.7398900985717773 seconds.
tensor([0.3177], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445070266723633
Time for loss calculation for target: 0.011777400970458984
Time for Loss backward: 1.7910759449005127
Time needed for the batch 2.9050655364990234
Time needed for logging 0.007160186767578125
Training epoch 0 | batch 828
Batch on Device 0 computed in 0.7400870323181152 seconds.
tensor([0.3514], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35446715354919434
Time for loss calculation for target: 0.012506246566772461
Time for Loss backward: 1.7892835140228271
Time needed for the batch 2.9042539596557617
Time needed for logging 0.007198810577392578
Training epoch 0 | batch 829
Batch on Device 0 computed in 0.7402825355529785 seconds.
tensor([0.3261], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354480504989624
Time for loss calculation for target: 0.011760234832763672
Time for Loss backward: 1.7905988693237305
Time needed for the batch 2.905179023742676
Time needed for logging 0.007250785827636719
Training epoch 0 | batch 830
Batch on Device 0 computed in 0.7400498390197754 seconds.
tensor([0.2683], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35450100898742676
Time for loss calculation for target: 0.012370824813842773
Time for Loss backward: 1.7889118194580078
Time needed for the batch 2.903999090194702
Time needed for logging 0.007295846939086914
Training epoch 0 | batch 831
Batch on Device 0 computed in 0.7400357723236084 seconds.
tensor([0.3946], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543879985809326
Time for loss calculation for target: 0.01177835464477539
Time for Loss backward: 1.7900829315185547
Time needed for the batch 2.904383420944214
Time needed for logging 0.007182121276855469
Training epoch 0 | batch 832
Batch on Device 0 computed in 0.7400846481323242 seconds.
tensor([0.3934], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544154167175293
Time for loss calculation for target: 0.01177072525024414
Time for Loss backward: 1.7904975414276123
Time needed for the batch 2.904550552368164
Time needed for logging 0.006997108459472656
Training epoch 0 | batch 833
Batch on Device 0 computed in 0.7402474880218506 seconds.
tensor([0.2508], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437703132629395
Time for loss calculation for target: 0.011765718460083008
Time for Loss backward: 1.7905642986297607
Time needed for the batch 2.9048798084259033
Time needed for logging 0.00708317756652832
Training epoch 0 | batch 834
Batch on Device 0 computed in 0.7401187419891357 seconds.
tensor([0.5059], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442280769348145
Time for loss calculation for target: 0.011879205703735352
Time for Loss backward: 1.7884480953216553
Time needed for the batch 2.9030983448028564
Time needed for logging 0.007094860076904297
Training epoch 0 | batch 835
Batch on Device 0 computed in 0.7403755187988281 seconds.
tensor([0.4086], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544175624847412
Time for loss calculation for target: 0.01185154914855957
Time for Loss backward: 1.7907028198242188
Time needed for the batch 2.9055867195129395
Time needed for logging 0.0071909427642822266
Training epoch 0 | batch 836
Batch on Device 0 computed in 0.7402360439300537 seconds.
tensor([0.4336], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354769229888916
Time for loss calculation for target: 0.011916637420654297
Time for Loss backward: 1.788447618484497
Time needed for the batch 2.9082112312316895
Time needed for logging 0.0071032047271728516
Training epoch 0 | batch 837
Batch on Device 0 computed in 0.7401902675628662 seconds.
tensor([0.3079], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433268547058105
Time for loss calculation for target: 0.011850118637084961
Time for Loss backward: 1.7906243801116943
Time needed for the batch 2.904623031616211
Time needed for logging 0.00725245475769043
Training epoch 0 | batch 838
Batch on Device 0 computed in 0.7400891780853271 seconds.
tensor([0.3305], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544008731842041
Time for loss calculation for target: 0.011897802352905273
Time for Loss backward: 1.7889904975891113
Time needed for the batch 2.903486490249634
Time needed for logging 0.007295131683349609
Training epoch 0 | batch 839
Batch on Device 0 computed in 0.7415206432342529 seconds.
tensor([0.1830], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544440269470215
Time for loss calculation for target: 0.01176309585571289
Time for Loss backward: 1.7864711284637451
Time needed for the batch 2.9023232460021973
Time needed for logging 0.007714271545410156
Training epoch 0 | batch 840
Batch on Device 0 computed in 0.7404236793518066 seconds.
tensor([0.1267], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445594787597656
Time for loss calculation for target: 0.011856794357299805
Time for Loss backward: 1.7901551723480225
Time needed for the batch 2.905787229537964
Time needed for logging 0.0073108673095703125
Training epoch 0 | batch 841
Batch on Device 0 computed in 0.7400476932525635 seconds.
tensor([0.2088], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544483184814453
Time for loss calculation for target: 0.011839866638183594
Time for Loss backward: 1.7913081645965576
Time needed for the batch 2.9057915210723877
Time needed for logging 0.0073239803314208984
Training epoch 0 | batch 842
Batch on Device 0 computed in 0.7399628162384033 seconds.
tensor([0.6024], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440611839294434
Time for loss calculation for target: 0.011747598648071289
Time for Loss backward: 1.7898929119110107
Time needed for the batch 2.9040892124176025
Time needed for logging 0.007107257843017578
Training epoch 0 | batch 843
Batch on Device 0 computed in 0.7399947643280029 seconds.
tensor([0.5108], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544478416442871
Time for loss calculation for target: 0.011746406555175781
Time for Loss backward: 1.7878859043121338
Time needed for the batch 2.901902198791504
Time needed for logging 0.007334470748901367
Training epoch 0 | batch 844
Batch on Device 0 computed in 0.744347095489502 seconds.
tensor([0.3822], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437488555908203
Time for loss calculation for target: 0.011799812316894531
Time for Loss backward: 1.7986564636230469
Time needed for the batch 2.9174845218658447
Time needed for logging 0.007284402847290039
Training epoch 0 | batch 845
Batch on Device 0 computed in 0.7400829792022705 seconds.
tensor([0.4766], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544943332672119
Time for loss calculation for target: 0.011741399765014648
Time for Loss backward: 1.791517734527588
Time needed for the batch 2.905733108520508
Time needed for logging 0.007224082946777344
Training epoch 0 | batch 846
Batch on Device 0 computed in 0.7399818897247314 seconds.
tensor([0.4812], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442161560058594
Time for loss calculation for target: 0.011891365051269531
Time for Loss backward: 1.78574538230896
Time needed for the batch 2.9003264904022217
Time needed for logging 0.007279157638549805
Training epoch 0 | batch 847
Batch on Device 0 computed in 0.7428491115570068 seconds.
tensor([0.5208], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440564155578613
Time for loss calculation for target: 0.011753320693969727
Time for Loss backward: 1.809359073638916
Time needed for the batch 2.9265329837799072
Time needed for logging 0.007139921188354492
Training epoch 0 | batch 848
Batch on Device 0 computed in 0.7404406070709229 seconds.
tensor([0.4159], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354358434677124
Time for loss calculation for target: 0.011727094650268555
Time for Loss backward: 1.7909362316131592
Time needed for the batch 2.905637264251709
Time needed for logging 0.007157564163208008
Training epoch 0 | batch 849
Batch on Device 0 computed in 0.740210771560669 seconds.
tensor([0.2267], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434389114379883
Time for loss calculation for target: 0.012639760971069336
Time for Loss backward: 1.7898621559143066
Time needed for the batch 2.905151128768921
Time needed for logging 0.007045269012451172
Training epoch 0 | batch 850
Batch on Device 0 computed in 0.7400739192962646 seconds.
tensor([0.6280], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543393611907959
Time for loss calculation for target: 0.011785030364990234
Time for Loss backward: 1.7894446849822998
Time needed for the batch 2.9041733741760254
Time needed for logging 0.0072629451751708984
Training epoch 0 | batch 851
Batch on Device 0 computed in 0.7400000095367432 seconds.
tensor([0.3741], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543124198913574
Time for loss calculation for target: 0.011670589447021484
Time for Loss backward: 1.7932913303375244
Time needed for the batch 2.9073150157928467
Time needed for logging 0.0070247650146484375
Training epoch 0 | batch 852
Batch on Device 0 computed in 0.7402215003967285 seconds.
tensor([0.3292], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543686866760254
Time for loss calculation for target: 0.011832714080810547
Time for Loss backward: 1.791020393371582
Time needed for the batch 2.9052813053131104
Time needed for logging 0.007077693939208984
Training epoch 0 | batch 853
Batch on Device 0 computed in 0.7403106689453125 seconds.
tensor([0.2423], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543894290924072
Time for loss calculation for target: 0.012004613876342773
Time for Loss backward: 1.7881534099578857
Time needed for the batch 2.902831792831421
Time needed for logging 0.007433176040649414
Training epoch 0 | batch 854
Batch on Device 0 computed in 0.7443501949310303 seconds.
tensor([0.4774], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545832633972168
Time for loss calculation for target: 0.011989831924438477
Time for Loss backward: 1.7833917140960693
Time needed for the batch 2.9020774364471436
Time needed for logging 0.007490873336791992
Training epoch 0 | batch 855
Batch on Device 0 computed in 0.7414429187774658 seconds.
tensor([0.4656], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445237159729004
Time for loss calculation for target: 0.011744022369384766
Time for Loss backward: 1.7907612323760986
Time needed for the batch 2.9069581031799316
Time needed for logging 0.007120847702026367
Training epoch 0 | batch 856
Batch on Device 0 computed in 0.7399284839630127 seconds.
tensor([0.4566], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442090034484863
Time for loss calculation for target: 0.011856794357299805
Time for Loss backward: 1.791039228439331
Time needed for the batch 2.905493974685669
Time needed for logging 0.007176399230957031
Training epoch 0 | batch 857
Batch on Device 0 computed in 0.7401037216186523 seconds.
tensor([0.6185], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545870780944824
Time for loss calculation for target: 0.012288331985473633
Time for Loss backward: 1.7856853008270264
Time needed for the batch 2.900712490081787
Time needed for logging 0.007356405258178711
Training epoch 0 | batch 858
Batch on Device 0 computed in 0.740800142288208 seconds.
tensor([0.3735], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439205169677734
Time for loss calculation for target: 0.01172947883605957
Time for Loss backward: 1.7915022373199463
Time needed for the batch 2.9081945419311523
Time needed for logging 0.007079362869262695
Training epoch 0 | batch 859
Batch on Device 0 computed in 0.7411608695983887 seconds.
tensor([0.4205], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543667793273926
Time for loss calculation for target: 0.01177215576171875
Time for Loss backward: 1.7941086292266846
Time needed for the batch 2.90938401222229
Time needed for logging 0.0069234371185302734
Training epoch 0 | batch 860
Batch on Device 0 computed in 0.739987850189209 seconds.
tensor([0.5546], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35450315475463867
Time for loss calculation for target: 0.011966705322265625
Time for Loss backward: 1.797236680984497
Time needed for the batch 2.911992311477661
Time needed for logging 0.007372379302978516
Training epoch 0 | batch 861
Batch on Device 0 computed in 0.740189790725708 seconds.
tensor([0.5103], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543887138366699
Time for loss calculation for target: 0.01212930679321289
Time for Loss backward: 1.7845749855041504
Time needed for the batch 2.899710178375244
Time needed for logging 0.007212638854980469
Training epoch 0 | batch 862
Batch on Device 0 computed in 0.7422244548797607 seconds.
tensor([0.4657], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441040992736816
Time for loss calculation for target: 0.011814355850219727
Time for Loss backward: 1.7879703044891357
Time needed for the batch 2.9048614501953125
Time needed for logging 0.007120847702026367
Training epoch 0 | batch 863
Batch on Device 0 computed in 0.7400765419006348 seconds.
tensor([0.4401], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543682098388672
Time for loss calculation for target: 0.011812210083007812
Time for Loss backward: 1.7897965908050537
Time needed for the batch 2.9040653705596924
Time needed for logging 0.007171154022216797
Training epoch 0 | batch 864
Batch on Device 0 computed in 0.7400610446929932 seconds.
tensor([0.3136], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35433101654052734
Time for loss calculation for target: 0.011891841888427734
Time for Loss backward: 1.7896239757537842
Time needed for the batch 2.9038596153259277
Time needed for logging 0.007214546203613281
Training epoch 0 | batch 865
Batch on Device 0 computed in 0.7400727272033691 seconds.
tensor([0.3802], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442209243774414
Time for loss calculation for target: 0.012101411819458008
Time for Loss backward: 1.790557861328125
Time needed for the batch 2.9054160118103027
Time needed for logging 0.007152557373046875
Training epoch 0 | batch 866
Batch on Device 0 computed in 0.7401320934295654 seconds.
tensor([0.1002], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439586639404297
Time for loss calculation for target: 0.011796712875366211
Time for Loss backward: 1.789722204208374
Time needed for the batch 2.904021739959717
Time needed for logging 0.007250070571899414
Training epoch 0 | batch 867
Batch on Device 0 computed in 0.7420713901519775 seconds.
tensor([0.5177], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441112518310547
Time for loss calculation for target: 0.011778831481933594
Time for Loss backward: 1.7883837223052979
Time needed for the batch 2.904157876968384
Time needed for logging 0.007261991500854492
Training epoch 0 | batch 868
Batch on Device 0 computed in 0.7399783134460449 seconds.
tensor([0.2018], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543851375579834
Time for loss calculation for target: 0.011767387390136719
Time for Loss backward: 1.8625359535217285
Time needed for the batch 2.9799323081970215
Time needed for logging 0.007222414016723633
Training epoch 0 | batch 869
Batch on Device 0 computed in 0.7400758266448975 seconds.
tensor([0.3868], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442304611206055
Time for loss calculation for target: 0.01236104965209961
Time for Loss backward: 1.790010929107666
Time needed for the batch 2.9048361778259277
Time needed for logging 0.007311820983886719
Training epoch 0 | batch 870
Batch on Device 0 computed in 0.7402350902557373 seconds.
tensor([0.4802], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544900417327881
Time for loss calculation for target: 0.011813163757324219
Time for Loss backward: 1.7896466255187988
Time needed for the batch 2.9043631553649902
Time needed for logging 0.007302999496459961
Training epoch 0 | batch 871
Batch on Device 0 computed in 0.7401447296142578 seconds.
tensor([0.2525], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544187545776367
Time for loss calculation for target: 0.011783599853515625
Time for Loss backward: 1.7894980907440186
Time needed for the batch 2.903804302215576
Time needed for logging 0.0071675777435302734
Training epoch 0 | batch 872
Batch on Device 0 computed in 0.7419993877410889 seconds.
tensor([0.5185], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35463857650756836
Time for loss calculation for target: 0.011943817138671875
Time for Loss backward: 1.7913615703582764
Time needed for the batch 2.9080851078033447
Time needed for logging 0.0070705413818359375
Training epoch 0 | batch 873
Batch on Device 0 computed in 0.7400391101837158 seconds.
tensor([0.2498], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437989234924316
Time for loss calculation for target: 0.011763572692871094
Time for Loss backward: 1.789440393447876
Time needed for the batch 2.9036989212036133
Time needed for logging 0.007201433181762695
Training epoch 0 | batch 874
Batch on Device 0 computed in 0.7428340911865234 seconds.
tensor([0.3469], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544437885284424
Time for loss calculation for target: 0.011772871017456055
Time for Loss backward: 1.790637493133545
Time needed for the batch 2.9079785346984863
Time needed for logging 0.007298707962036133
Training epoch 0 | batch 875
Batch on Device 0 computed in 0.7413876056671143 seconds.
tensor([0.2528], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544445037841797
Time for loss calculation for target: 0.01174473762512207
Time for Loss backward: 1.789140224456787
Time needed for the batch 2.9043283462524414
Time needed for logging 0.007206439971923828
Training epoch 0 | batch 876
Batch on Device 0 computed in 0.7402169704437256 seconds.
tensor([0.3535], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543267250061035
Time for loss calculation for target: 0.011787891387939453
Time for Loss backward: 1.7905917167663574
Time needed for the batch 2.905010461807251
Time needed for logging 0.00716710090637207
Training epoch 0 | batch 877
Batch on Device 0 computed in 0.7401573657989502 seconds.
tensor([0.3112], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544180393218994
Time for loss calculation for target: 0.011795997619628906
Time for Loss backward: 1.790722370147705
Time needed for the batch 2.9050114154815674
Time needed for logging 0.007186174392700195
Training epoch 0 | batch 878
Batch on Device 0 computed in 0.7403531074523926 seconds.
tensor([0.4570], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445618629455566
Time for loss calculation for target: 0.011861801147460938
Time for Loss backward: 1.7900638580322266
Time needed for the batch 2.9042422771453857
Time needed for logging 0.006920337677001953
Training epoch 0 | batch 879
Batch on Device 0 computed in 0.7400615215301514 seconds.
tensor([0.5930], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544135093688965
Time for loss calculation for target: 0.011790752410888672
Time for Loss backward: 1.788825511932373
Time needed for the batch 2.9040284156799316
Time needed for logging 0.007223606109619141
Training epoch 0 | batch 880
Batch on Device 0 computed in 0.7401158809661865 seconds.
tensor([0.4263], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544728755950928
Time for loss calculation for target: 0.011748313903808594
Time for Loss backward: 1.7902483940124512
Time needed for the batch 2.9044878482818604
Time needed for logging 0.007109880447387695
Training epoch 0 | batch 881
Batch on Device 0 computed in 0.7400467395782471 seconds.
tensor([0.3608], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544609546661377
Time for loss calculation for target: 0.011873960494995117
Time for Loss backward: 1.7857115268707275
Time needed for the batch 2.900064468383789
Time needed for logging 0.00717616081237793
Training epoch 0 | batch 882
Batch on Device 0 computed in 0.7436251640319824 seconds.
tensor([0.4150], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35454297065734863
Time for loss calculation for target: 0.011814594268798828
Time for Loss backward: 1.7917380332946777
Time needed for the batch 2.909297466278076
Time needed for logging 0.006989479064941406
Training epoch 0 | batch 883
Batch on Device 0 computed in 0.7401137351989746 seconds.
tensor([0.3412], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543558120727539
Time for loss calculation for target: 0.01175379753112793
Time for Loss backward: 1.7902522087097168
Time needed for the batch 2.9045512676239014
Time needed for logging 0.0071258544921875
Training epoch 0 | batch 884
Batch on Device 0 computed in 0.7402377128601074 seconds.
tensor([0.5087], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544957637786865
Time for loss calculation for target: 0.011875391006469727
Time for Loss backward: 1.792395830154419
Time needed for the batch 2.9071121215820312
Time needed for logging 0.006907463073730469
Training epoch 0 | batch 885
Batch on Device 0 computed in 0.7400388717651367 seconds.
tensor([0.3699], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441136360168457
Time for loss calculation for target: 0.011831045150756836
Time for Loss backward: 1.7914936542510986
Time needed for the batch 2.9060091972351074
Time needed for logging 0.007212162017822266
Training epoch 0 | batch 886
Batch on Device 0 computed in 0.7400503158569336 seconds.
tensor([0.3201], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440945625305176
Time for loss calculation for target: 0.011803865432739258
Time for Loss backward: 1.7902672290802002
Time needed for the batch 2.904423236846924
Time needed for logging 0.007047414779663086
Training epoch 0 | batch 887
Batch on Device 0 computed in 0.7400729656219482 seconds.
tensor([0.5414], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35444092750549316
Time for loss calculation for target: 0.011806249618530273
Time for Loss backward: 1.7903673648834229
Time needed for the batch 2.904554843902588
Time needed for logging 0.007201433181762695
Training epoch 0 | batch 888
Batch on Device 0 computed in 0.7401254177093506 seconds.
tensor([0.4532], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445618629455566
Time for loss calculation for target: 0.011846542358398438
Time for Loss backward: 1.7920680046081543
Time needed for the batch 2.906592845916748
Time needed for logging 0.0071222782135009766
Training epoch 0 | batch 889
Batch on Device 0 computed in 0.7402193546295166 seconds.
tensor([0.6606], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544037342071533
Time for loss calculation for target: 0.011762857437133789
Time for Loss backward: 1.7914869785308838
Time needed for the batch 2.905933380126953
Time needed for logging 0.0072443485260009766
Training epoch 0 | batch 890
Batch on Device 0 computed in 0.740100622177124 seconds.
tensor([0.4613], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544015884399414
Time for loss calculation for target: 0.011755228042602539
Time for Loss backward: 1.7893500328063965
Time needed for the batch 2.9038138389587402
Time needed for logging 0.007493019104003906
Training epoch 0 | batch 891
Batch on Device 0 computed in 0.7399735450744629 seconds.
tensor([0.4409], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544189929962158
Time for loss calculation for target: 0.011768579483032227
Time for Loss backward: 1.789093255996704
Time needed for the batch 2.90354323387146
Time needed for logging 0.007321596145629883
Training epoch 0 | batch 892
Batch on Device 0 computed in 0.7400009632110596 seconds.
tensor([0.5136], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442233085632324
Time for loss calculation for target: 0.011716604232788086
Time for Loss backward: 1.7913107872009277
Time needed for the batch 2.905571460723877
Time needed for logging 0.007036447525024414
Training epoch 0 | batch 893
Batch on Device 0 computed in 0.7400398254394531 seconds.
tensor([0.5509], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543684482574463
Time for loss calculation for target: 0.011895418167114258
Time for Loss backward: 1.7929465770721436
Time needed for the batch 2.907195806503296
Time needed for logging 0.007057905197143555
Training epoch 0 | batch 894
Batch on Device 0 computed in 0.7401688098907471 seconds.
tensor([0.4279], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443997383117676
Time for loss calculation for target: 0.011857986450195312
Time for Loss backward: 1.7904813289642334
Time needed for the batch 2.9097979068756104
Time needed for logging 0.007326602935791016
Training epoch 0 | batch 895
Batch on Device 0 computed in 0.7401187419891357 seconds.
tensor([0.7099], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35447025299072266
Time for loss calculation for target: 0.011825323104858398
Time for Loss backward: 1.7894301414489746
Time needed for the batch 2.904114007949829
Time needed for logging 0.007429599761962891
Training epoch 0 | batch 896
Batch on Device 0 computed in 0.7401852607727051 seconds.
tensor([0.2669], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545398712158203
Time for loss calculation for target: 0.011943578720092773
Time for Loss backward: 1.789712905883789
Time needed for the batch 2.9048094749450684
Time needed for logging 0.007334232330322266
Training epoch 0 | batch 897
Batch on Device 0 computed in 0.7401456832885742 seconds.
tensor([0.2959], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544020652770996
Time for loss calculation for target: 0.011812686920166016
Time for Loss backward: 1.783907413482666
Time needed for the batch 2.9029312133789062
Time needed for logging 0.007219552993774414
Training epoch 0 | batch 898
Batch on Device 0 computed in 0.7452988624572754 seconds.
tensor([0.6405], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442185401916504
Time for loss calculation for target: 0.01181340217590332
Time for Loss backward: 1.7915818691253662
Time needed for the batch 2.911526918411255
Time needed for logging 0.006888866424560547
Training epoch 0 | batch 899
Batch on Device 0 computed in 0.7399835586547852 seconds.
tensor([0.2273], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544466495513916
Time for loss calculation for target: 0.011863470077514648
Time for Loss backward: 1.794645071029663
Time needed for the batch 2.9093382358551025
Time needed for logging 0.006989479064941406
Training epoch 0 | batch 900
Batch on Device 0 computed in 0.740053653717041 seconds.
tensor([0.4779], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544495105743408
Time for loss calculation for target: 0.011833906173706055
Time for Loss backward: 1.7904248237609863
Time needed for the batch 2.9049618244171143
Time needed for logging 0.00729060173034668
Training epoch 0 | batch 901
Batch on Device 0 computed in 0.7401225566864014 seconds.
tensor([0.4230], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546295166015625
Time for loss calculation for target: 0.011964797973632812
Time for Loss backward: 1.7854838371276855
Time needed for the batch 2.9004929065704346
Time needed for logging 0.007305622100830078
Training epoch 0 | batch 902
Batch on Device 0 computed in 0.7424161434173584 seconds.
tensor([0.4864], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543968200683594
Time for loss calculation for target: 0.011881828308105469
Time for Loss backward: 1.7830426692962646
Time needed for the batch 2.9004311561584473
Time needed for logging 0.007177591323852539
Training epoch 0 | batch 903
Batch on Device 0 computed in 0.7423906326293945 seconds.
tensor([0.6071], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543686866760254
Time for loss calculation for target: 0.011861562728881836
Time for Loss backward: 1.7837374210357666
Time needed for the batch 2.9004709720611572
Time needed for logging 0.0073511600494384766
Training epoch 0 | batch 904
Batch on Device 0 computed in 0.7428042888641357 seconds.
tensor([0.4429], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35446810722351074
Time for loss calculation for target: 0.011806726455688477
Time for Loss backward: 1.79079008102417
Time needed for the batch 2.908125400543213
Time needed for logging 0.007285594940185547
Training epoch 0 | batch 905
Batch on Device 0 computed in 0.7401854991912842 seconds.
tensor([0.3940], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3540961742401123
Time for loss calculation for target: 0.011963844299316406
Time for Loss backward: 1.789421796798706
Time needed for the batch 2.90427827835083
Time needed for logging 0.007338762283325195
Training epoch 0 | batch 906
Batch on Device 0 computed in 0.7428126335144043 seconds.
tensor([0.3892], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354356050491333
Time for loss calculation for target: 0.011797189712524414
Time for Loss backward: 1.790891170501709
Time needed for the batch 2.908313035964966
Time needed for logging 0.0070569515228271484
Training epoch 0 | batch 907
Batch on Device 0 computed in 0.7403547763824463 seconds.
tensor([0.2677], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35447239875793457
Time for loss calculation for target: 0.011690378189086914
Time for Loss backward: 1.7917695045471191
Time needed for the batch 2.9061532020568848
Time needed for logging 0.007155179977416992
Training epoch 0 | batch 908
Batch on Device 0 computed in 0.7413015365600586 seconds.
tensor([0.1950], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543534278869629
Time for loss calculation for target: 0.011826753616333008
Time for Loss backward: 1.7884912490844727
Time needed for the batch 2.9041707515716553
Time needed for logging 0.007142305374145508
Training epoch 0 | batch 909
Batch on Device 0 computed in 0.7400403022766113 seconds.
tensor([0.4727], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543965816497803
Time for loss calculation for target: 0.01174783706665039
Time for Loss backward: 1.7926034927368164
Time needed for the batch 2.9067347049713135
Time needed for logging 0.0070612430572509766
Training epoch 0 | batch 910
Batch on Device 0 computed in 0.7400317192077637 seconds.
tensor([0.3172], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544306755065918
Time for loss calculation for target: 0.011773824691772461
Time for Loss backward: 1.7878034114837646
Time needed for the batch 2.9019885063171387
Time needed for logging 0.0072209835052490234
Training epoch 0 | batch 911
Batch on Device 0 computed in 0.7438015937805176 seconds.
tensor([0.3322], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544275760650635
Time for loss calculation for target: 0.011743545532226562
Time for Loss backward: 1.7880101203918457
Time needed for the batch 2.906106472015381
Time needed for logging 0.007227659225463867
Training epoch 0 | batch 912
Batch on Device 0 computed in 0.7450802326202393 seconds.
tensor([0.3258], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445570945739746
Time for loss calculation for target: 0.011733770370483398
Time for Loss backward: 1.7932443618774414
Time needed for the batch 2.9125258922576904
Time needed for logging 0.007100343704223633
Training epoch 0 | batch 913
Batch on Device 0 computed in 0.7402989864349365 seconds.
tensor([0.6356], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544144630432129
Time for loss calculation for target: 0.011739492416381836
Time for Loss backward: 1.7943215370178223
Time needed for the batch 2.908743381500244
Time needed for logging 0.007172346115112305
Training epoch 0 | batch 914
Batch on Device 0 computed in 0.7400875091552734 seconds.
tensor([0.5320], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544280529022217
Time for loss calculation for target: 0.011844396591186523
Time for Loss backward: 1.7913684844970703
Time needed for the batch 2.9059817790985107
Time needed for logging 0.007228374481201172
Training epoch 0 | batch 915
Batch on Device 0 computed in 0.7403409481048584 seconds.
tensor([0.2813], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544585704803467
Time for loss calculation for target: 0.0117645263671875
Time for Loss backward: 1.789534330368042
Time needed for the batch 2.9041242599487305
Time needed for logging 0.007206439971923828
Training epoch 0 | batch 916
Batch on Device 0 computed in 0.7401638031005859 seconds.
tensor([0.6173], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35449957847595215
Time for loss calculation for target: 0.011898517608642578
Time for Loss backward: 1.7900710105895996
Time needed for the batch 2.904872417449951
Time needed for logging 0.0070645809173583984
Training epoch 0 | batch 917
Batch on Device 0 computed in 0.7402017116546631 seconds.
tensor([0.4369], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439467430114746
Time for loss calculation for target: 0.011867523193359375
Time for Loss backward: 1.7901298999786377
Time needed for the batch 2.904705047607422
Time needed for logging 0.007386445999145508
Training epoch 0 | batch 918
Batch on Device 0 computed in 0.7401158809661865 seconds.
tensor([0.6158], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354475736618042
Time for loss calculation for target: 0.011875391006469727
Time for Loss backward: 1.7901251316070557
Time needed for the batch 2.904585838317871
Time needed for logging 0.007191896438598633
Training epoch 0 | batch 919
Batch on Device 0 computed in 0.7402610778808594 seconds.
tensor([0.3949], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35450053215026855
Time for loss calculation for target: 0.011815786361694336
Time for Loss backward: 1.78946852684021
Time needed for the batch 2.9042179584503174
Time needed for logging 0.007242918014526367
Training epoch 0 | batch 920
Batch on Device 0 computed in 0.7402262687683105 seconds.
tensor([0.2994], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544273376464844
Time for loss calculation for target: 0.011770486831665039
Time for Loss backward: 1.7883942127227783
Time needed for the batch 2.9031548500061035
Time needed for logging 0.007114887237548828
Training epoch 0 | batch 921
Batch on Device 0 computed in 0.7401766777038574 seconds.
tensor([0.2133], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35446929931640625
Time for loss calculation for target: 0.011672735214233398
Time for Loss backward: 1.7913169860839844
Time needed for the batch 2.905595064163208
Time needed for logging 0.00722193717956543
Training epoch 0 | batch 922
Batch on Device 0 computed in 0.7399692535400391 seconds.
tensor([0.4641], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543875217437744
Time for loss calculation for target: 0.011761665344238281
Time for Loss backward: 1.790487289428711
Time needed for the batch 2.9044277667999268
Time needed for logging 0.007056474685668945
Training epoch 0 | batch 923
Batch on Device 0 computed in 0.7410109043121338 seconds.
tensor([0.6390], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544800281524658
Time for loss calculation for target: 0.011720418930053711
Time for Loss backward: 1.7888383865356445
Time needed for the batch 2.90403151512146
Time needed for logging 0.007264375686645508
Training epoch 0 | batch 924
Batch on Device 0 computed in 0.7401306629180908 seconds.
tensor([0.4535], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354447603225708
Time for loss calculation for target: 0.01167607307434082
Time for Loss backward: 1.7926750183105469
Time needed for the batch 2.906766176223755
Time needed for logging 0.006655216217041016
Training epoch 0 | batch 925
Batch on Device 0 computed in 0.7399499416351318 seconds.
tensor([0.1818], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440659523010254
Time for loss calculation for target: 0.011709213256835938
Time for Loss backward: 1.7893450260162354
Time needed for the batch 2.9030895233154297
Time needed for logging 0.006761789321899414
Training epoch 0 | batch 926
Batch on Device 0 computed in 0.740058422088623 seconds.
tensor([0.6324], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443544387817383
Time for loss calculation for target: 0.011704444885253906
Time for Loss backward: 1.7878525257110596
Time needed for the batch 2.901334762573242
Time needed for logging 0.006698131561279297
Training epoch 0 | batch 927
Batch on Device 0 computed in 0.7414402961730957 seconds.
tensor([0.3853], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35438108444213867
Time for loss calculation for target: 0.012412309646606445
Time for Loss backward: 1.7823872566223145
Time needed for the batch 2.899211883544922
Time needed for logging 0.006638526916503906
Training epoch 0 | batch 928
Batch on Device 0 computed in 0.7467703819274902 seconds.
tensor([0.4528], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544886112213135
Time for loss calculation for target: 0.011741399765014648
Time for Loss backward: 1.7924127578735352
Time needed for the batch 2.9135031700134277
Time needed for logging 0.006512641906738281
Training epoch 0 | batch 929
Batch on Device 0 computed in 0.7400593757629395 seconds.
tensor([0.3138], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543989658355713
Time for loss calculation for target: 0.011705636978149414
Time for Loss backward: 1.7910234928131104
Time needed for the batch 2.9059062004089355
Time needed for logging 0.006651401519775391
Training epoch 0 | batch 930
Batch on Device 0 computed in 0.7400739192962646 seconds.
tensor([0.4375], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544609546661377
Time for loss calculation for target: 0.01168513298034668
Time for Loss backward: 1.7839891910552979
Time needed for the batch 2.897697687149048
Time needed for logging 0.006785154342651367
Training epoch 0 | batch 931
Batch on Device 0 computed in 0.7428731918334961 seconds.
tensor([0.5919], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544042110443115
Time for loss calculation for target: 0.01195979118347168
Time for Loss backward: 1.7843053340911865
Time needed for the batch 2.90162992477417
Time needed for logging 0.006574392318725586
Training epoch 0 | batch 932
Batch on Device 0 computed in 0.746739387512207 seconds.
tensor([0.5657], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35472965240478516
Time for loss calculation for target: 0.011912107467651367
Time for Loss backward: 1.7914769649505615
Time needed for the batch 2.912627696990967
Time needed for logging 0.006514549255371094
Training epoch 0 | batch 933
Batch on Device 0 computed in 0.7401325702667236 seconds.
tensor([0.3899], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547043800354004
Time for loss calculation for target: 0.011713504791259766
Time for Loss backward: 1.7920103073120117
Time needed for the batch 2.9065864086151123
Time needed for logging 0.006684064865112305
Training epoch 0 | batch 934
Batch on Device 0 computed in 0.7410233020782471 seconds.
tensor([0.4633], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354766845703125
Time for loss calculation for target: 0.011852741241455078
Time for Loss backward: 1.7917017936706543
Time needed for the batch 2.9067180156707764
Time needed for logging 0.006630659103393555
Training epoch 0 | batch 935
Batch on Device 0 computed in 0.7399899959564209 seconds.
tensor([0.6493], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544125556945801
Time for loss calculation for target: 0.011684656143188477
Time for Loss backward: 1.7910826206207275
Time needed for the batch 2.9051339626312256
Time needed for logging 0.006880044937133789
Training epoch 0 | batch 936
Batch on Device 0 computed in 0.740020751953125 seconds.
tensor([0.4003], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436391830444336
Time for loss calculation for target: 0.011677742004394531
Time for Loss backward: 1.790527582168579
Time needed for the batch 2.9044477939605713
Time needed for logging 0.006802558898925781
Training epoch 0 | batch 937
Batch on Device 0 computed in 0.7402265071868896 seconds.
tensor([0.3030], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544175624847412
Time for loss calculation for target: 0.011694192886352539
Time for Loss backward: 1.7944674491882324
Time needed for the batch 2.9080848693847656
Time needed for logging 0.006608009338378906
Training epoch 0 | batch 938
Batch on Device 0 computed in 0.7401244640350342 seconds.
tensor([0.4529], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354508638381958
Time for loss calculation for target: 0.011809825897216797
Time for Loss backward: 1.7836253643035889
Time needed for the batch 2.898132085800171
Time needed for logging 0.006627559661865234
Training epoch 0 | batch 939
Batch on Device 0 computed in 0.7457191944122314 seconds.
tensor([0.5115], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354372501373291
Time for loss calculation for target: 0.011684894561767578
Time for Loss backward: 1.7921817302703857
Time needed for the batch 2.9120664596557617
Time needed for logging 0.00659489631652832
Training epoch 0 | batch 940
Batch on Device 0 computed in 0.7401747703552246 seconds.
tensor([0.2434], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544120788574219
Time for loss calculation for target: 0.011689186096191406
Time for Loss backward: 1.7898824214935303
Time needed for the batch 2.903632164001465
Time needed for logging 0.0067157745361328125
Training epoch 0 | batch 941
Batch on Device 0 computed in 0.7400693893432617 seconds.
tensor([0.3537], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445094108581543
Time for loss calculation for target: 0.011817455291748047
Time for Loss backward: 1.7916004657745361
Time needed for the batch 2.905702829360962
Time needed for logging 0.006749391555786133
Training epoch 0 | batch 942
Batch on Device 0 computed in 0.739891529083252 seconds.
tensor([0.4573], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544020652770996
Time for loss calculation for target: 0.011682748794555664
Time for Loss backward: 1.7914791107177734
Time needed for the batch 2.905132532119751
Time needed for logging 0.0067255496978759766
Training epoch 0 | batch 943
Batch on Device 0 computed in 0.7402327060699463 seconds.
tensor([0.4057], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35447263717651367
Time for loss calculation for target: 0.011868476867675781
Time for Loss backward: 1.7947757244110107
Time needed for the batch 2.9090735912323
Time needed for logging 0.006630659103393555
Training epoch 0 | batch 944
Batch on Device 0 computed in 0.7399256229400635 seconds.
tensor([0.3585], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443568229675293
Time for loss calculation for target: 0.01179194450378418
Time for Loss backward: 1.7890064716339111
Time needed for the batch 2.902733087539673
Time needed for logging 0.006733894348144531
Training epoch 0 | batch 945
Batch on Device 0 computed in 0.7400705814361572 seconds.
tensor([0.2956], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543970584869385
Time for loss calculation for target: 0.011589288711547852
Time for Loss backward: 1.7913451194763184
Time needed for the batch 2.904865026473999
Time needed for logging 0.006748676300048828
Training epoch 0 | batch 946
Batch on Device 0 computed in 0.7399563789367676 seconds.
tensor([0.6007], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440826416015625
Time for loss calculation for target: 0.011642694473266602
Time for Loss backward: 1.7849409580230713
Time needed for the batch 2.8984742164611816
Time needed for logging 0.006819725036621094
Training epoch 0 | batch 947
Batch on Device 0 computed in 0.7459590435028076 seconds.
tensor([0.2648], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543877601623535
Time for loss calculation for target: 0.011681318283081055
Time for Loss backward: 1.7909724712371826
Time needed for the batch 2.9107582569122314
Time needed for logging 0.007169008255004883
Training epoch 0 | batch 948
Batch on Device 0 computed in 0.7401139736175537 seconds.
tensor([0.3544], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445427894592285
Time for loss calculation for target: 0.01233530044555664
Time for Loss backward: 1.7900683879852295
Time needed for the batch 2.9047622680664062
Time needed for logging 0.006765604019165039
Training epoch 0 | batch 949
Batch on Device 0 computed in 0.7400553226470947 seconds.
tensor([0.2620], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543431758880615
Time for loss calculation for target: 0.011722564697265625
Time for Loss backward: 1.7915081977844238
Time needed for the batch 2.908714771270752
Time needed for logging 0.006642818450927734
Training epoch 0 | batch 950
Batch on Device 0 computed in 0.7399864196777344 seconds.
tensor([0.4331], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437726974487305
Time for loss calculation for target: 0.011677265167236328
Time for Loss backward: 1.791593074798584
Time needed for the batch 2.9050753116607666
Time needed for logging 0.006758451461791992
Training epoch 0 | batch 951
Batch on Device 0 computed in 0.740006685256958 seconds.
tensor([0.3777], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544294834136963
Time for loss calculation for target: 0.011705160140991211
Time for Loss backward: 1.7912561893463135
Time needed for the batch 2.904898166656494
Time needed for logging 0.006802558898925781
Training epoch 0 | batch 952
Batch on Device 0 computed in 0.7400310039520264 seconds.
tensor([0.1713], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543863296508789
Time for loss calculation for target: 0.01203465461730957
Time for Loss backward: 1.7896666526794434
Time needed for the batch 2.903665542602539
Time needed for logging 0.006697177886962891
Training epoch 0 | batch 953
Batch on Device 0 computed in 0.7400252819061279 seconds.
tensor([0.5132], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543720245361328
Time for loss calculation for target: 0.011717081069946289
Time for Loss backward: 1.7927651405334473
Time needed for the batch 2.906604766845703
Time needed for logging 0.005938529968261719
Training epoch 0 | batch 954
Batch on Device 0 computed in 0.7402441501617432 seconds.
tensor([0.4984], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546793460845947
Time for loss calculation for target: 0.011867284774780273
Time for Loss backward: 1.7905704975128174
Time needed for the batch 2.905060291290283
Time needed for logging 0.0067195892333984375
Training epoch 0 | batch 955
Batch on Device 0 computed in 0.7399642467498779 seconds.
tensor([0.3400], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547976016998291
Time for loss calculation for target: 0.011806488037109375
Time for Loss backward: 1.7882778644561768
Time needed for the batch 2.901977300643921
Time needed for logging 0.0067026615142822266
Training epoch 0 | batch 956
Batch on Device 0 computed in 0.7405483722686768 seconds.
tensor([0.5856], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442352294921875
Time for loss calculation for target: 0.011719942092895508
Time for Loss backward: 1.7910332679748535
Time needed for the batch 2.906435012817383
Time needed for logging 0.006708860397338867
Training epoch 0 | batch 957
Batch on Device 0 computed in 0.739987850189209 seconds.
tensor([0.4871], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35444188117980957
Time for loss calculation for target: 0.01178884506225586
Time for Loss backward: 1.7922272682189941
Time needed for the batch 2.9060261249542236
Time needed for logging 0.00674891471862793
Training epoch 0 | batch 958
Batch on Device 0 computed in 0.7401268482208252 seconds.
tensor([0.6343], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545255661010742
Time for loss calculation for target: 0.0117340087890625
Time for Loss backward: 1.788437843322754
Time needed for the batch 2.902484893798828
Time needed for logging 0.006711721420288086
Training epoch 0 | batch 959
Batch on Device 0 computed in 0.7409062385559082 seconds.
tensor([0.4722], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544785976409912
Time for loss calculation for target: 0.01173853874206543
Time for Loss backward: 1.791379451751709
Time needed for the batch 2.9068174362182617
Time needed for logging 0.006719827651977539
Training epoch 0 | batch 960
Batch on Device 0 computed in 0.7401762008666992 seconds.
tensor([0.2327], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545811176300049
Time for loss calculation for target: 0.01171731948852539
Time for Loss backward: 1.7912802696228027
Time needed for the batch 2.9055287837982178
Time needed for logging 0.006670713424682617
Training epoch 0 | batch 961
Batch on Device 0 computed in 0.7419090270996094 seconds.
tensor([0.3580], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441136360168457
Time for loss calculation for target: 0.011688470840454102
Time for Loss backward: 1.7926409244537354
Time needed for the batch 2.9082090854644775
Time needed for logging 0.006753206253051758
Training epoch 0 | batch 962
Batch on Device 0 computed in 0.7403686046600342 seconds.
tensor([0.3545], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354459285736084
Time for loss calculation for target: 0.011695623397827148
Time for Loss backward: 1.7914769649505615
Time needed for the batch 2.9055464267730713
Time needed for logging 0.006665468215942383
Training epoch 0 | batch 963
Batch on Device 0 computed in 0.7400684356689453 seconds.
tensor([0.4225], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544619083404541
Time for loss calculation for target: 0.011858224868774414
Time for Loss backward: 1.7908880710601807
Time needed for the batch 2.904910087585449
Time needed for logging 0.0071849822998046875
Training epoch 0 | batch 964
Batch on Device 0 computed in 0.7399389743804932 seconds.
tensor([0.3889], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442447662353516
Time for loss calculation for target: 0.011807680130004883
Time for Loss backward: 1.7897346019744873
Time needed for the batch 2.903751850128174
Time needed for logging 0.00675654411315918
Training epoch 0 | batch 965
Batch on Device 0 computed in 0.739985466003418 seconds.
tensor([0.4075], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545091152191162
Time for loss calculation for target: 0.011807918548583984
Time for Loss backward: 1.791921615600586
Time needed for the batch 2.9058868885040283
Time needed for logging 0.006902456283569336
Training epoch 0 | batch 966
Batch on Device 0 computed in 0.7401821613311768 seconds.
tensor([0.6993], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443639755249023
Time for loss calculation for target: 0.011643409729003906
Time for Loss backward: 1.7835619449615479
Time needed for the batch 2.897597074508667
Time needed for logging 0.006555795669555664
Training epoch 0 | batch 967
Batch on Device 0 computed in 0.7458920478820801 seconds.
tensor([0.5136], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544940948486328
Time for loss calculation for target: 0.011776924133300781
Time for Loss backward: 1.792097806930542
Time needed for the batch 2.911890983581543
Time needed for logging 0.0066814422607421875
Training epoch 0 | batch 968
Batch on Device 0 computed in 0.7404696941375732 seconds.
tensor([0.5144], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544299602508545
Time for loss calculation for target: 0.01169133186340332
Time for Loss backward: 1.792571783065796
Time needed for the batch 2.9079577922821045
Time needed for logging 0.006626605987548828
Training epoch 0 | batch 969
Batch on Device 0 computed in 0.7399110794067383 seconds.
tensor([0.2798], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440659523010254
Time for loss calculation for target: 0.012086868286132812
Time for Loss backward: 1.7924134731292725
Time needed for the batch 2.906334638595581
Time needed for logging 0.006724357604980469
Training epoch 0 | batch 970
Batch on Device 0 computed in 0.7400126457214355 seconds.
tensor([0.5040], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545088768005371
Time for loss calculation for target: 0.011703014373779297
Time for Loss backward: 1.788447618484497
Time needed for the batch 2.90230131149292
Time needed for logging 0.006782054901123047
Training epoch 0 | batch 971
Batch on Device 0 computed in 0.7420411109924316 seconds.
tensor([0.7128], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35477781295776367
Time for loss calculation for target: 0.011777639389038086
Time for Loss backward: 1.7898974418640137
Time needed for the batch 2.9062323570251465
Time needed for logging 0.006673574447631836
Training epoch 0 | batch 972
Batch on Device 0 computed in 0.7399940490722656 seconds.
tensor([0.2065], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544890880584717
Time for loss calculation for target: 0.011727333068847656
Time for Loss backward: 1.7894024848937988
Time needed for the batch 2.9027254581451416
Time needed for logging 0.006654262542724609
Training epoch 0 | batch 973
Batch on Device 0 computed in 0.7405166625976562 seconds.
tensor([0.3592], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544037342071533
Time for loss calculation for target: 0.012069940567016602
Time for Loss backward: 1.793442726135254
Time needed for the batch 2.9093167781829834
Time needed for logging 0.0070362091064453125
Training epoch 0 | batch 974
Batch on Device 0 computed in 0.7400624752044678 seconds.
tensor([0.4171], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545083999633789
Time for loss calculation for target: 0.011661529541015625
Time for Loss backward: 1.7942144870758057
Time needed for the batch 2.908332586288452
Time needed for logging 0.00669097900390625
Training epoch 0 | batch 975
Batch on Device 0 computed in 0.7402660846710205 seconds.
tensor([0.2404], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547365665435791
Time for loss calculation for target: 0.011983394622802734
Time for Loss backward: 1.7904906272888184
Time needed for the batch 2.9055099487304688
Time needed for logging 0.0072290897369384766
Training epoch 0 | batch 976
Batch on Device 0 computed in 0.7401947975158691 seconds.
tensor([0.4025], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545222282409668
Time for loss calculation for target: 0.011809110641479492
Time for Loss backward: 1.7902443408966064
Time needed for the batch 2.9055018424987793
Time needed for logging 0.007295846939086914
Training epoch 0 | batch 977
Batch on Device 0 computed in 0.7401492595672607 seconds.
tensor([0.3871], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35444116592407227
Time for loss calculation for target: 0.01178598403930664
Time for Loss backward: 1.7886343002319336
Time needed for the batch 2.903353214263916
Time needed for logging 0.007244586944580078
Training epoch 0 | batch 978
Batch on Device 0 computed in 0.7441325187683105 seconds.
tensor([0.1439], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35447216033935547
Time for loss calculation for target: 0.012595653533935547
Time for Loss backward: 1.784008264541626
Time needed for the batch 2.9031155109405518
Time needed for logging 0.007117509841918945
Training epoch 0 | batch 979
Batch on Device 0 computed in 0.7427504062652588 seconds.
tensor([0.4340], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434484481811523
Time for loss calculation for target: 0.011846065521240234
Time for Loss backward: 1.785465955734253
Time needed for the batch 2.9025533199310303
Time needed for logging 0.007110118865966797
Training epoch 0 | batch 980
Batch on Device 0 computed in 0.7430047988891602 seconds.
tensor([0.4101], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35446953773498535
Time for loss calculation for target: 0.01173257827758789
Time for Loss backward: 1.7904324531555176
Time needed for the batch 2.9075238704681396
Time needed for logging 0.007102251052856445
Training epoch 0 | batch 981
Batch on Device 0 computed in 0.7400705814361572 seconds.
tensor([0.3215], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544788360595703
Time for loss calculation for target: 0.011748075485229492
Time for Loss backward: 1.790468692779541
Time needed for the batch 2.9045450687408447
Time needed for logging 0.007156848907470703
Training epoch 0 | batch 982
Batch on Device 0 computed in 0.7401421070098877 seconds.
tensor([0.5229], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545384407043457
Time for loss calculation for target: 0.011798620223999023
Time for Loss backward: 1.785417079925537
Time needed for the batch 2.900623083114624
Time needed for logging 0.0071141719818115234
Training epoch 0 | batch 983
Batch on Device 0 computed in 0.742285966873169 seconds.
tensor([0.5792], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544952869415283
Time for loss calculation for target: 0.011734962463378906
Time for Loss backward: 1.7921910285949707
Time needed for the batch 2.9088823795318604
Time needed for logging 0.00722813606262207
Training epoch 0 | batch 984
Batch on Device 0 computed in 0.7401759624481201 seconds.
tensor([0.5238], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545241355895996
Time for loss calculation for target: 0.011844396591186523
Time for Loss backward: 1.789222240447998
Time needed for the batch 2.9039063453674316
Time needed for logging 0.007102251052856445
Training epoch 0 | batch 985
Batch on Device 0 computed in 0.7411563396453857 seconds.
tensor([0.2290], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544929027557373
Time for loss calculation for target: 0.011709213256835938
Time for Loss backward: 1.7864315509796143
Time needed for the batch 2.90147066116333
Time needed for logging 0.007112741470336914
Training epoch 0 | batch 986
Batch on Device 0 computed in 0.7426984310150146 seconds.
tensor([0.7125], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544278144836426
Time for loss calculation for target: 0.011839866638183594
Time for Loss backward: 1.7848331928253174
Time needed for the batch 2.9017698764801025
Time needed for logging 0.0071964263916015625
Training epoch 0 | batch 987
Batch on Device 0 computed in 0.7492763996124268 seconds.
tensor([0.4215], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35450005531311035
Time for loss calculation for target: 0.011809825897216797
Time for Loss backward: 1.792926549911499
Time needed for the batch 2.9166831970214844
Time needed for logging 0.007105112075805664
Training epoch 0 | batch 988
Batch on Device 0 computed in 0.7402491569519043 seconds.
tensor([0.3652], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544740676879883
Time for loss calculation for target: 0.01181650161743164
Time for Loss backward: 1.7894892692565918
Time needed for the batch 2.904435157775879
Time needed for logging 0.0073146820068359375
Training epoch 0 | batch 989
Batch on Device 0 computed in 0.7402255535125732 seconds.
tensor([0.2768], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443592071533203
Time for loss calculation for target: 0.011716842651367188
Time for Loss backward: 1.791076898574829
Time needed for the batch 2.9053399562835693
Time needed for logging 0.007086038589477539
Training epoch 0 | batch 990
Batch on Device 0 computed in 0.740821123123169 seconds.
tensor([0.1671], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35451388359069824
Time for loss calculation for target: 0.011774063110351562
Time for Loss backward: 1.7891170978546143
Time needed for the batch 2.904109477996826
Time needed for logging 0.007147789001464844
Training epoch 0 | batch 991
Batch on Device 0 computed in 0.7401504516601562 seconds.
tensor([0.7937], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354428768157959
Time for loss calculation for target: 0.011891365051269531
Time for Loss backward: 1.7845616340637207
Time needed for the batch 2.8991308212280273
Time needed for logging 0.007151365280151367
Training epoch 0 | batch 992
Batch on Device 0 computed in 0.7449886798858643 seconds.
tensor([0.4306], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445499420166016
Time for loss calculation for target: 0.011865854263305664
Time for Loss backward: 1.7845468521118164
Time needed for the batch 2.903773784637451
Time needed for logging 0.0071566104888916016
Training epoch 0 | batch 993
Batch on Device 0 computed in 0.7450375556945801 seconds.
tensor([0.4152], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544433116912842
Time for loss calculation for target: 0.011803865432739258
Time for Loss backward: 1.7848896980285645
Time needed for the batch 2.9039528369903564
Time needed for logging 0.007058620452880859
Training epoch 0 | batch 994
Batch on Device 0 computed in 0.7457790374755859 seconds.
tensor([0.4537], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544774055480957
Time for loss calculation for target: 0.01171731948852539
Time for Loss backward: 1.7906522750854492
Time needed for the batch 2.910452365875244
Time needed for logging 0.007111549377441406
Training epoch 0 | batch 995
Batch on Device 0 computed in 0.7403178215026855 seconds.
tensor([0.5247], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35450243949890137
Time for loss calculation for target: 0.011803627014160156
Time for Loss backward: 1.7895240783691406
Time needed for the batch 2.9041311740875244
Time needed for logging 0.007185935974121094
Training epoch 0 | batch 996
Batch on Device 0 computed in 0.7404611110687256 seconds.
tensor([0.3493], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35401153564453125
Time for loss calculation for target: 0.011837005615234375
Time for Loss backward: 1.79286789894104
Time needed for the batch 2.9081180095672607
Time needed for logging 0.007089376449584961
Training epoch 0 | batch 997
Batch on Device 0 computed in 0.7401294708251953 seconds.
tensor([0.4680], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35452699661254883
Time for loss calculation for target: 0.01187276840209961
Time for Loss backward: 1.78468656539917
Time needed for the batch 2.8996284008026123
Time needed for logging 0.0071868896484375
Training epoch 0 | batch 998
Batch on Device 0 computed in 0.7438535690307617 seconds.
tensor([0.2653], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544888496398926
Time for loss calculation for target: 0.011720657348632812
Time for Loss backward: 1.7891414165496826
Time needed for the batch 2.9081485271453857
Time needed for logging 0.006748676300048828
Training epoch 0 | batch 999
Batch on Device 0 computed in 0.7406320571899414 seconds.
tensor([0.6089], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35449790954589844
Time for loss calculation for target: 0.011685609817504883
Time for Loss backward: 1.9209558963775635
Time needed for the batch 3.0362861156463623
Time needed for logging 0.028939485549926758
Training epoch 0 | batch 1000
Batch on Device 0 computed in 0.7401268482208252 seconds.
tensor([0.4243], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440993309020996
Time for loss calculation for target: 0.011940717697143555
Time for Loss backward: 1.7897634506225586
Time needed for the batch 3.070120334625244
Time needed for logging 4.839897155761719e-05
Training epoch 0 | batch 1001
Batch on Device 0 computed in 0.7411181926727295 seconds.
tensor([0.5524], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545405864715576
Time for loss calculation for target: 0.011656522750854492
Time for Loss backward: 1.786451816558838
Time needed for the batch 2.907381772994995
Time needed for logging 0.04289674758911133
Training epoch 0 | batch 1002
Batch on Device 0 computed in 0.7400286197662354 seconds.
tensor([0.4869], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35450053215026855
Time for loss calculation for target: 0.011959552764892578
Time for Loss backward: 1.7902746200561523
Time needed for the batch 2.9053730964660645
Time needed for logging 0.006632804870605469
Training epoch 0 | batch 1003
Batch on Device 0 computed in 0.7414076328277588 seconds.
tensor([0.3607], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35455942153930664
Time for loss calculation for target: 0.011662960052490234
Time for Loss backward: 1.7842419147491455
Time needed for the batch 2.899751901626587
Time needed for logging 0.006665706634521484
Training epoch 0 | batch 1004
Batch on Device 0 computed in 0.7468302249908447 seconds.
tensor([0.3727], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544042110443115
Time for loss calculation for target: 0.011799812316894531
Time for Loss backward: 1.7894237041473389
Time needed for the batch 2.910015106201172
Time needed for logging 0.006618499755859375
Training epoch 0 | batch 1005
Batch on Device 0 computed in 0.741403341293335 seconds.
tensor([0.5435], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35446929931640625
Time for loss calculation for target: 0.011682510375976562
Time for Loss backward: 1.7857859134674072
Time needed for the batch 2.9009079933166504
Time needed for logging 0.006546735763549805
Training epoch 0 | batch 1006
Batch on Device 0 computed in 0.7458479404449463 seconds.
tensor([0.5617], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441160202026367
Time for loss calculation for target: 0.01164102554321289
Time for Loss backward: 1.7922356128692627
Time needed for the batch 2.911959648132324
Time needed for logging 0.006651401519775391
Training epoch 0 | batch 1007
Batch on Device 0 computed in 0.7400302886962891 seconds.
tensor([0.3519], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443711280822754
Time for loss calculation for target: 0.01169443130493164
Time for Loss backward: 1.8562335968017578
Time needed for the batch 2.9700398445129395
Time needed for logging 0.006742954254150391
Training epoch 0 | batch 1008
Batch on Device 0 computed in 0.7402174472808838 seconds.
tensor([0.3723], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544905185699463
Time for loss calculation for target: 0.011685609817504883
Time for Loss backward: 1.7949562072753906
Time needed for the batch 2.91148042678833
Time needed for logging 0.0066111087799072266
Training epoch 0 | batch 1009
Batch on Device 0 computed in 0.7401015758514404 seconds.
tensor([0.4328], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3548715114593506
Time for loss calculation for target: 0.011964559555053711
Time for Loss backward: 1.7859563827514648
Time needed for the batch 2.9007344245910645
Time needed for logging 0.00663304328918457
Training epoch 0 | batch 1010
Batch on Device 0 computed in 0.7448680400848389 seconds.
tensor([0.3832], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448336601257324
Time for loss calculation for target: 0.01185917854309082
Time for Loss backward: 1.7917945384979248
Time needed for the batch 2.911583185195923
Time needed for logging 0.0072269439697265625
Training epoch 0 | batch 1011
Batch on Device 0 computed in 0.7402679920196533 seconds.
tensor([0.3589], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439538955688477
Time for loss calculation for target: 0.011836528778076172
Time for Loss backward: 1.7906873226165771
Time needed for the batch 2.9055867195129395
Time needed for logging 0.007249116897583008
Training epoch 0 | batch 1012
Batch on Device 0 computed in 0.7401947975158691 seconds.
tensor([0.4989], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545064926147461
Time for loss calculation for target: 0.011793136596679688
Time for Loss backward: 1.7909343242645264
Time needed for the batch 2.905616521835327
Time needed for logging 0.00731658935546875
Training epoch 0 | batch 1013
Batch on Device 0 computed in 0.7401800155639648 seconds.
tensor([0.4035], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35449767112731934
Time for loss calculation for target: 0.011820077896118164
Time for Loss backward: 1.7920660972595215
Time needed for the batch 2.9065723419189453
Time needed for logging 0.007117033004760742
Training epoch 0 | batch 1014
Batch on Device 0 computed in 0.7404685020446777 seconds.
tensor([0.5175], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35434913635253906
Time for loss calculation for target: 0.011900901794433594
Time for Loss backward: 1.7869999408721924
Time needed for the batch 2.9013381004333496
Time needed for logging 0.007239103317260742
Training epoch 0 | batch 1015
Batch on Device 0 computed in 0.7451198101043701 seconds.
tensor([0.3757], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441040992736816
Time for loss calculation for target: 0.011723041534423828
Time for Loss backward: 1.7890563011169434
Time needed for the batch 2.9082114696502686
Time needed for logging 0.007117033004760742
Training epoch 0 | batch 1016
Batch on Device 0 computed in 0.7401993274688721 seconds.
tensor([0.4663], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3548564910888672
Time for loss calculation for target: 0.011976480484008789
Time for Loss backward: 1.7869443893432617
Time needed for the batch 2.9020867347717285
Time needed for logging 0.007268190383911133
Training epoch 0 | batch 1017
Batch on Device 0 computed in 0.7435369491577148 seconds.
tensor([0.6935], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544924259185791
Time for loss calculation for target: 0.011795997619628906
Time for Loss backward: 1.7918665409088135
Time needed for the batch 2.909919500350952
Time needed for logging 0.007243633270263672
Training epoch 0 | batch 1018
Batch on Device 0 computed in 0.7403364181518555 seconds.
tensor([0.3740], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544645309448242
Time for loss calculation for target: 0.01180720329284668
Time for Loss backward: 1.7901935577392578
Time needed for the batch 2.9047365188598633
Time needed for logging 0.007257223129272461
Training epoch 0 | batch 1019
Batch on Device 0 computed in 0.7401127815246582 seconds.
tensor([0.3514], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544504642486572
Time for loss calculation for target: 0.012087583541870117
Time for Loss backward: 1.7903401851654053
Time needed for the batch 2.9048984050750732
Time needed for logging 0.007205486297607422
Training epoch 0 | batch 1020
Batch on Device 0 computed in 0.7401478290557861 seconds.
tensor([0.6837], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443568229675293
Time for loss calculation for target: 0.011891603469848633
Time for Loss backward: 1.8531122207641602
Time needed for the batch 2.9675135612487793
Time needed for logging 0.007256507873535156
Training epoch 0 | batch 1021
Batch on Device 0 computed in 0.7429308891296387 seconds.
tensor([0.2083], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35393333435058594
Time for loss calculation for target: 0.011898517608642578
Time for Loss backward: 1.7912108898162842
Time needed for the batch 2.908752918243408
Time needed for logging 0.007566928863525391
Training epoch 0 | batch 1022
Batch on Device 0 computed in 0.740053653717041 seconds.
tensor([0.3588], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35446643829345703
Time for loss calculation for target: 0.011785507202148438
Time for Loss backward: 1.7928869724273682
Time needed for the batch 2.9076695442199707
Time needed for logging 0.007069587707519531
Training epoch 0 | batch 1023
Batch on Device 0 computed in 0.7402551174163818 seconds.
tensor([0.3778], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354442834854126
Time for loss calculation for target: 0.01199197769165039
Time for Loss backward: 1.7884583473205566
Time needed for the batch 2.903123378753662
Time needed for logging 0.006582021713256836
Training epoch 0 | batch 1024
Batch on Device 0 computed in 0.7415776252746582 seconds.
tensor([0.2908], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35447144508361816
Time for loss calculation for target: 0.011690616607666016
Time for Loss backward: 1.795736312866211
Time needed for the batch 2.911273241043091
Time needed for logging 0.006711006164550781
Training epoch 0 | batch 1025
Batch on Device 0 computed in 0.7406373023986816 seconds.
tensor([0.3550], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544433116912842
Time for loss calculation for target: 0.011758565902709961
Time for Loss backward: 1.7871100902557373
Time needed for the batch 2.902695655822754
Time needed for logging 0.0071680545806884766
Training epoch 0 | batch 1026
Batch on Device 0 computed in 0.7445812225341797 seconds.
tensor([0.4436], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544492721557617
Time for loss calculation for target: 0.011712789535522461
Time for Loss backward: 1.7874419689178467
Time needed for the batch 2.90598201751709
Time needed for logging 0.007103919982910156
Training epoch 0 | batch 1027
Batch on Device 0 computed in 0.7471408843994141 seconds.
tensor([0.4599], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544178009033203
Time for loss calculation for target: 0.011676788330078125
Time for Loss backward: 1.7863433361053467
Time needed for the batch 2.9074244499206543
Time needed for logging 0.007203102111816406
Training epoch 0 | batch 1028
Batch on Device 0 computed in 0.7442123889923096 seconds.
tensor([0.4915], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354428768157959
Time for loss calculation for target: 0.011779308319091797
Time for Loss backward: 1.7901086807250977
Time needed for the batch 2.908322811126709
Time needed for logging 0.007211446762084961
Training epoch 0 | batch 1029
Batch on Device 0 computed in 0.7401728630065918 seconds.
tensor([0.2149], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543696403503418
Time for loss calculation for target: 0.011666536331176758
Time for Loss backward: 1.7875981330871582
Time needed for the batch 2.901939630508423
Time needed for logging 0.007288932800292969
Training epoch 0 | batch 1030
Batch on Device 0 computed in 0.7432408332824707 seconds.
tensor([0.4357], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3548431396484375
Time for loss calculation for target: 0.011823177337646484
Time for Loss backward: 1.7895550727844238
Time needed for the batch 2.907313108444214
Time needed for logging 0.0071947574615478516
Training epoch 0 | batch 1031
Batch on Device 0 computed in 0.7406785488128662 seconds.
tensor([0.4734], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544139862060547
Time for loss calculation for target: 0.011724472045898438
Time for Loss backward: 1.8517677783966064
Time needed for the batch 2.9660136699676514
Time needed for logging 0.007149457931518555
Training epoch 0 | batch 1032
Batch on Device 0 computed in 0.7437808513641357 seconds.
tensor([0.3180], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544020652770996
Time for loss calculation for target: 0.011786222457885742
Time for Loss backward: 1.7912158966064453
Time needed for the batch 2.909041166305542
Time needed for logging 0.007145404815673828
Training epoch 0 | batch 1033
Batch on Device 0 computed in 0.7400979995727539 seconds.
tensor([0.3540], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35485172271728516
Time for loss calculation for target: 0.01195526123046875
Time for Loss backward: 1.791346788406372
Time needed for the batch 2.9063639640808105
Time needed for logging 0.006676673889160156
Training epoch 0 | batch 1034
Batch on Device 0 computed in 0.7402732372283936 seconds.
tensor([0.4222], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440754890441895
Time for loss calculation for target: 0.011708736419677734
Time for Loss backward: 1.7892205715179443
Time needed for the batch 2.9030933380126953
Time needed for logging 0.006604433059692383
Training epoch 0 | batch 1035
Batch on Device 0 computed in 0.7400825023651123 seconds.
tensor([0.4542], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543858528137207
Time for loss calculation for target: 0.011644840240478516
Time for Loss backward: 1.7818641662597656
Time needed for the batch 2.8962926864624023
Time needed for logging 0.006657123565673828
Training epoch 0 | batch 1036
Batch on Device 0 computed in 0.7456789016723633 seconds.
tensor([0.4496], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546440601348877
Time for loss calculation for target: 0.012179374694824219
Time for Loss backward: 1.7895939350128174
Time needed for the batch 2.910930871963501
Time needed for logging 0.007147789001464844
Training epoch 0 | batch 1037
Batch on Device 0 computed in 0.7401542663574219 seconds.
tensor([0.4588], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544137477874756
Time for loss calculation for target: 0.011669158935546875
Time for Loss backward: 1.7912757396697998
Time needed for the batch 2.9074413776397705
Time needed for logging 0.007040739059448242
Training epoch 0 | batch 1038
Batch on Device 0 computed in 0.7401430606842041 seconds.
tensor([0.4883], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546478748321533
Time for loss calculation for target: 0.011974573135375977
Time for Loss backward: 1.790086269378662
Time needed for the batch 2.904890298843384
Time needed for logging 0.007200956344604492
Training epoch 0 | batch 1039
Batch on Device 0 computed in 0.7405731678009033 seconds.
tensor([0.3281], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543534278869629
Time for loss calculation for target: 0.01166677474975586
Time for Loss backward: 1.786980390548706
Time needed for the batch 2.9012773036956787
Time needed for logging 0.007195234298706055
Training epoch 0 | batch 1040
Batch on Device 0 computed in 0.7447435855865479 seconds.
tensor([0.4258], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.355083703994751
Time for loss calculation for target: 0.012466192245483398
Time for Loss backward: 1.7896983623504639
Time needed for the batch 2.910033702850342
Time needed for logging 0.007832527160644531
Training epoch 0 | batch 1041
Batch on Device 0 computed in 0.7401340007781982 seconds.
tensor([0.4190], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544340133666992
Time for loss calculation for target: 0.011870622634887695
Time for Loss backward: 1.7930107116699219
Time needed for the batch 2.909121513366699
Time needed for logging 0.007230997085571289
Training epoch 0 | batch 1042
Batch on Device 0 computed in 0.7400267124176025 seconds.
tensor([0.4464], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35453104972839355
Time for loss calculation for target: 0.011784553527832031
Time for Loss backward: 1.7904882431030273
Time needed for the batch 2.904902219772339
Time needed for logging 0.007158041000366211
Training epoch 0 | batch 1043
Batch on Device 0 computed in 0.7399847507476807 seconds.
tensor([0.3550], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544888496398926
Time for loss calculation for target: 0.011879682540893555
Time for Loss backward: 1.7908165454864502
Time needed for the batch 2.905073404312134
Time needed for logging 0.0072286128997802734
Training epoch 0 | batch 1044
Batch on Device 0 computed in 0.7401831150054932 seconds.
tensor([0.3498], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543741703033447
Time for loss calculation for target: 0.011825799942016602
Time for Loss backward: 1.789757490158081
Time needed for the batch 2.903895854949951
Time needed for logging 0.007277727127075195
Training epoch 0 | batch 1045
Batch on Device 0 computed in 0.7400639057159424 seconds.
tensor([0.5121], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543975353240967
Time for loss calculation for target: 0.011767148971557617
Time for Loss backward: 1.785487413406372
Time needed for the batch 2.8997886180877686
Time needed for logging 0.00733637809753418
Training epoch 0 | batch 1046
Batch on Device 0 computed in 0.7424488067626953 seconds.
tensor([0.2058], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440707206726074
Time for loss calculation for target: 0.011696815490722656
Time for Loss backward: 1.7839136123657227
Time needed for the batch 2.900773763656616
Time needed for logging 0.006565570831298828
Training epoch 0 | batch 1047
Batch on Device 0 computed in 0.746140718460083 seconds.
tensor([0.1442], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35451531410217285
Time for loss calculation for target: 0.011740446090698242
Time for Loss backward: 1.7897188663482666
Time needed for the batch 2.9105606079101562
Time needed for logging 0.00663304328918457
Training epoch 0 | batch 1048
Batch on Device 0 computed in 0.7404208183288574 seconds.
tensor([0.3417], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35451269149780273
Time for loss calculation for target: 0.01181483268737793
Time for Loss backward: 1.7913756370544434
Time needed for the batch 2.9069037437438965
Time needed for logging 0.00673675537109375
Training epoch 0 | batch 1049
Batch on Device 0 computed in 0.7399964332580566 seconds.
tensor([0.7303], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544180393218994
Time for loss calculation for target: 0.011739492416381836
Time for Loss backward: 1.7911508083343506
Time needed for the batch 2.905410051345825
Time needed for logging 0.006574153900146484
Training epoch 0 | batch 1050
Batch on Device 0 computed in 0.7402760982513428 seconds.
tensor([0.3367], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544125556945801
Time for loss calculation for target: 0.011743545532226562
Time for Loss backward: 1.7907090187072754
Time needed for the batch 2.904897928237915
Time needed for logging 0.006610393524169922
Training epoch 0 | batch 1051
Batch on Device 0 computed in 0.7401773929595947 seconds.
tensor([0.3220], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437631607055664
Time for loss calculation for target: 0.011688232421875
Time for Loss backward: 1.7908132076263428
Time needed for the batch 2.9045228958129883
Time needed for logging 0.006676435470581055
Training epoch 0 | batch 1052
Batch on Device 0 computed in 0.7401137351989746 seconds.
tensor([0.3098], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445427894592285
Time for loss calculation for target: 0.01180577278137207
Time for Loss backward: 1.7869324684143066
Time needed for the batch 2.9005162715911865
Time needed for logging 0.007092952728271484
Training epoch 0 | batch 1053
Batch on Device 0 computed in 0.7440435886383057 seconds.
tensor([0.3733], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448765754699707
Time for loss calculation for target: 0.011799335479736328
Time for Loss backward: 1.7843294143676758
Time needed for the batch 2.902512788772583
Time needed for logging 0.007132291793823242
Training epoch 0 | batch 1054
Batch on Device 0 computed in 0.744055986404419 seconds.
tensor([0.3134], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436558723449707
Time for loss calculation for target: 0.011723041534423828
Time for Loss backward: 1.788738489151001
Time needed for the batch 2.9066686630249023
Time needed for logging 0.007107257843017578
Training epoch 0 | batch 1055
Batch on Device 0 computed in 0.7413196563720703 seconds.
tensor([0.4031], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354541540145874
Time for loss calculation for target: 0.011768102645874023
Time for Loss backward: 1.7909257411956787
Time needed for the batch 2.9060251712799072
Time needed for logging 0.0071566104888916016
Training epoch 0 | batch 1056
Batch on Device 0 computed in 0.7402479648590088 seconds.
tensor([0.1053], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439229011535645
Time for loss calculation for target: 0.011821508407592773
Time for Loss backward: 1.7874586582183838
Time needed for the batch 2.9017233848571777
Time needed for logging 0.007267475128173828
Training epoch 0 | batch 1057
Batch on Device 0 computed in 0.7409753799438477 seconds.
tensor([0.2319], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35444021224975586
Time for loss calculation for target: 0.011769533157348633
Time for Loss backward: 1.789907693862915
Time needed for the batch 2.9051077365875244
Time needed for logging 0.007167816162109375
Training epoch 0 | batch 1058
Batch on Device 0 computed in 0.7407057285308838 seconds.
tensor([0.3353], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35447192192077637
Time for loss calculation for target: 0.011878490447998047
Time for Loss backward: 1.789287805557251
Time needed for the batch 2.9042928218841553
Time needed for logging 0.0071828365325927734
Training epoch 0 | batch 1059
Batch on Device 0 computed in 0.7399702072143555 seconds.
tensor([0.3546], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35432004928588867
Time for loss calculation for target: 0.011788368225097656
Time for Loss backward: 1.7901642322540283
Time needed for the batch 2.903771162033081
Time needed for logging 0.007202863693237305
Training epoch 0 | batch 1060
Batch on Device 0 computed in 0.7399885654449463 seconds.
tensor([0.4683], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441160202026367
Time for loss calculation for target: 0.01179647445678711
Time for Loss backward: 1.7893576622009277
Time needed for the batch 2.903801679611206
Time needed for logging 0.007020711898803711
Training epoch 0 | batch 1061
Batch on Device 0 computed in 0.7400350570678711 seconds.
tensor([0.3900], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545358180999756
Time for loss calculation for target: 0.011827468872070312
Time for Loss backward: 1.7937648296356201
Time needed for the batch 2.908094882965088
Time needed for logging 0.007073879241943359
Training epoch 0 | batch 1062
Batch on Device 0 computed in 0.7399945259094238 seconds.
tensor([0.3444], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544323444366455
Time for loss calculation for target: 0.011877298355102539
Time for Loss backward: 1.7898318767547607
Time needed for the batch 2.90596342086792
Time needed for logging 0.007155895233154297
Training epoch 0 | batch 1063
Batch on Device 0 computed in 0.7415919303894043 seconds.
tensor([0.3094], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543403148651123
Time for loss calculation for target: 0.011762380599975586
Time for Loss backward: 1.7917356491088867
Time needed for the batch 2.9072511196136475
Time needed for logging 0.0072591304779052734
Training epoch 0 | batch 1064
Batch on Device 0 computed in 0.7401115894317627 seconds.
tensor([0.5091], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544433116912842
Time for loss calculation for target: 0.011733293533325195
Time for Loss backward: 1.7956335544586182
Time needed for the batch 2.9099152088165283
Time needed for logging 0.0073239803314208984
Training epoch 0 | batch 1065
Batch on Device 0 computed in 0.7400991916656494 seconds.
tensor([0.2587], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543977737426758
Time for loss calculation for target: 0.012673616409301758
Time for Loss backward: 1.791447639465332
Time needed for the batch 2.906790018081665
Time needed for logging 0.007639884948730469
Training epoch 0 | batch 1066
Batch on Device 0 computed in 0.7400569915771484 seconds.
tensor([0.3337], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544588088989258
Time for loss calculation for target: 0.011754035949707031
Time for Loss backward: 1.791015386581421
Time needed for the batch 2.905471086502075
Time needed for logging 0.007285118103027344
Training epoch 0 | batch 1067
Batch on Device 0 computed in 0.7400431632995605 seconds.
tensor([0.5405], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543965816497803
Time for loss calculation for target: 0.01174783706665039
Time for Loss backward: 1.784879207611084
Time needed for the batch 2.8989927768707275
Time needed for logging 0.007658958435058594
Training epoch 0 | batch 1068
Batch on Device 0 computed in 0.7408692836761475 seconds.
tensor([0.3488], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545341491699219
Time for loss calculation for target: 0.011860370635986328
Time for Loss backward: 1.790945291519165
Time needed for the batch 2.9090614318847656
Time needed for logging 0.0073735713958740234
Training epoch 0 | batch 1069
Batch on Device 0 computed in 0.7401974201202393 seconds.
tensor([0.3989], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544435501098633
Time for loss calculation for target: 0.011992454528808594
Time for Loss backward: 1.7912945747375488
Time needed for the batch 2.9062585830688477
Time needed for logging 0.007204294204711914
Training epoch 0 | batch 1070
Batch on Device 0 computed in 0.7400140762329102 seconds.
tensor([0.6561], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544962406158447
Time for loss calculation for target: 0.011820077896118164
Time for Loss backward: 1.7898411750793457
Time needed for the batch 2.904376983642578
Time needed for logging 0.007264137268066406
Training epoch 0 | batch 1071
Batch on Device 0 computed in 0.7400941848754883 seconds.
tensor([0.4315], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443735122680664
Time for loss calculation for target: 0.01180267333984375
Time for Loss backward: 1.786937952041626
Time needed for the batch 2.9012858867645264
Time needed for logging 0.007233381271362305
Training epoch 0 | batch 1072
Batch on Device 0 computed in 0.7436139583587646 seconds.
tensor([0.4316], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35454416275024414
Time for loss calculation for target: 0.011808633804321289
Time for Loss backward: 1.7903831005096436
Time needed for the batch 2.9083309173583984
Time needed for logging 0.007018566131591797
Training epoch 0 | batch 1073
Batch on Device 0 computed in 0.7402644157409668 seconds.
tensor([0.3194], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544807434082031
Time for loss calculation for target: 0.012109756469726562
Time for Loss backward: 1.7913639545440674
Time needed for the batch 2.905799150466919
Time needed for logging 0.007263898849487305
Training epoch 0 | batch 1074
Batch on Device 0 computed in 0.7400860786437988 seconds.
tensor([0.4086], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544282913208008
Time for loss calculation for target: 0.011763572692871094
Time for Loss backward: 1.7916386127471924
Time needed for the batch 2.9060943126678467
Time needed for logging 0.007147073745727539
Training epoch 0 | batch 1075
Batch on Device 0 computed in 0.7400603294372559 seconds.
tensor([0.5307], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35489439964294434
Time for loss calculation for target: 0.011773109436035156
Time for Loss backward: 1.7901151180267334
Time needed for the batch 2.904853105545044
Time needed for logging 0.007096052169799805
Training epoch 0 | batch 1076
Batch on Device 0 computed in 0.7400310039520264 seconds.
tensor([0.4374], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3550267219543457
Time for loss calculation for target: 0.011789798736572266
Time for Loss backward: 1.7915911674499512
Time needed for the batch 2.906874656677246
Time needed for logging 0.006986379623413086
Training epoch 0 | batch 1077
Batch on Device 0 computed in 0.7402105331420898 seconds.
tensor([0.2763], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545057773590088
Time for loss calculation for target: 0.011682748794555664
Time for Loss backward: 1.7860989570617676
Time needed for the batch 2.9000887870788574
Time needed for logging 0.007181644439697266
Training epoch 0 | batch 1078
Batch on Device 0 computed in 0.7406342029571533 seconds.
tensor([0.5131], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35485410690307617
Time for loss calculation for target: 0.011945247650146484
Time for Loss backward: 1.785470724105835
Time needed for the batch 2.9057390689849854
Time needed for logging 0.007134675979614258
Training epoch 0 | batch 1079
Batch on Device 0 computed in 0.7451109886169434 seconds.
tensor([0.6057], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545222282409668
Time for loss calculation for target: 0.011815309524536133
Time for Loss backward: 1.7838242053985596
Time needed for the batch 2.9032318592071533
Time needed for logging 0.0072154998779296875
Training epoch 0 | batch 1080
Batch on Device 0 computed in 0.7447948455810547 seconds.
tensor([0.6341], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544332981109619
Time for loss calculation for target: 0.011803388595581055
Time for Loss backward: 1.7855520248413086
Time needed for the batch 2.9047257900238037
Time needed for logging 0.0071430206298828125
Training epoch 0 | batch 1081
Batch on Device 0 computed in 0.7464206218719482 seconds.
tensor([0.3029], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35481953620910645
Time for loss calculation for target: 0.011978626251220703
Time for Loss backward: 1.7858967781066895
Time needed for the batch 2.9070684909820557
Time needed for logging 0.007175445556640625
Training epoch 0 | batch 1082
Batch on Device 0 computed in 0.7407608032226562 seconds.
tensor([0.3207], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544273376464844
Time for loss calculation for target: 0.011858701705932617
Time for Loss backward: 1.7853927612304688
Time needed for the batch 2.900346040725708
Time needed for logging 0.007074594497680664
Training epoch 0 | batch 1083
Batch on Device 0 computed in 0.7448770999908447 seconds.
tensor([0.3774], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442280769348145
Time for loss calculation for target: 0.011880159378051758
Time for Loss backward: 1.7896573543548584
Time needed for the batch 2.9086625576019287
Time needed for logging 0.00722193717956543
Training epoch 0 | batch 1084
Batch on Device 0 computed in 0.7401092052459717 seconds.
tensor([0.5015], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439276695251465
Time for loss calculation for target: 0.011759281158447266
Time for Loss backward: 1.7907094955444336
Time needed for the batch 2.904977798461914
Time needed for logging 0.0072863101959228516
Training epoch 0 | batch 1085
Batch on Device 0 computed in 0.7412898540496826 seconds.
tensor([0.5376], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441160202026367
Time for loss calculation for target: 0.0118255615234375
Time for Loss backward: 1.792860507965088
Time needed for the batch 2.9084630012512207
Time needed for logging 0.006874799728393555
Training epoch 0 | batch 1086
Batch on Device 0 computed in 0.7399253845214844 seconds.
tensor([0.2881], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442137718200684
Time for loss calculation for target: 0.01251983642578125
Time for Loss backward: 1.7891838550567627
Time needed for the batch 2.904020309448242
Time needed for logging 0.007020473480224609
Training epoch 0 | batch 1087
Batch on Device 0 computed in 0.7398862838745117 seconds.
tensor([0.5226], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442066192626953
Time for loss calculation for target: 0.01171875
Time for Loss backward: 1.790764331817627
Time needed for the batch 2.904496908187866
Time needed for logging 0.007131099700927734
Training epoch 0 | batch 1088
Batch on Device 0 computed in 0.7398314476013184 seconds.
tensor([0.4541], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440516471862793
Time for loss calculation for target: 0.011741399765014648
Time for Loss backward: 1.7907495498657227
Time needed for the batch 2.904566526412964
Time needed for logging 0.00707244873046875
Training epoch 0 | batch 1089
Batch on Device 0 computed in 0.7403943538665771 seconds.
tensor([0.1866], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437893867492676
Time for loss calculation for target: 0.011793851852416992
Time for Loss backward: 1.7904307842254639
Time needed for the batch 2.9047024250030518
Time needed for logging 0.00715184211730957
Training epoch 0 | batch 1090
Batch on Device 0 computed in 0.740159273147583 seconds.
tensor([0.4532], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35466718673706055
Time for loss calculation for target: 0.012156486511230469
Time for Loss backward: 1.7892370223999023
Time needed for the batch 2.903745651245117
Time needed for logging 0.007071495056152344
Training epoch 0 | batch 1091
Batch on Device 0 computed in 0.7402181625366211 seconds.
tensor([0.5174], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545193672180176
Time for loss calculation for target: 0.011846542358398438
Time for Loss backward: 1.7855119705200195
Time needed for the batch 2.899973154067993
Time needed for logging 0.0072460174560546875
Training epoch 0 | batch 1092
Batch on Device 0 computed in 0.7436120510101318 seconds.
tensor([0.1482], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439157485961914
Time for loss calculation for target: 0.011905431747436523
Time for Loss backward: 1.784742832183838
Time needed for the batch 2.902728796005249
Time needed for logging 0.0071985721588134766
Training epoch 0 | batch 1093
Batch on Device 0 computed in 0.7459759712219238 seconds.
tensor([0.3444], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3547220230102539
Time for loss calculation for target: 0.011854171752929688
Time for Loss backward: 1.7908692359924316
Time needed for the batch 2.9116642475128174
Time needed for logging 0.006966829299926758
Training epoch 0 | batch 1094
Batch on Device 0 computed in 0.7400732040405273 seconds.
tensor([0.4234], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35478854179382324
Time for loss calculation for target: 0.012155294418334961
Time for Loss backward: 1.7885947227478027
Time needed for the batch 2.903634786605835
Time needed for logging 0.007025480270385742
Training epoch 0 | batch 1095
Batch on Device 0 computed in 0.7399356365203857 seconds.
tensor([0.4443], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443615913391113
Time for loss calculation for target: 0.011814355850219727
Time for Loss backward: 1.7911643981933594
Time needed for the batch 2.9053268432617188
Time needed for logging 0.007101297378540039
Training epoch 0 | batch 1096
Batch on Device 0 computed in 0.7399430274963379 seconds.
tensor([0.3764], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543822765350342
Time for loss calculation for target: 0.011762380599975586
Time for Loss backward: 1.7852683067321777
Time needed for the batch 2.899231433868408
Time needed for logging 0.0073816776275634766
Training epoch 0 | batch 1097
Batch on Device 0 computed in 0.7467207908630371 seconds.
tensor([0.4014], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543713092803955
Time for loss calculation for target: 0.011802911758422852
Time for Loss backward: 1.7917149066925049
Time needed for the batch 2.9126498699188232
Time needed for logging 0.0070078372955322266
Training epoch 0 | batch 1098
Batch on Device 0 computed in 0.7400431632995605 seconds.
tensor([0.3815], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35453343391418457
Time for loss calculation for target: 0.011881828308105469
Time for Loss backward: 1.7902839183807373
Time needed for the batch 2.9046876430511475
Time needed for logging 0.0072116851806640625
Training epoch 0 | batch 1099
Batch on Device 0 computed in 0.7398836612701416 seconds.
tensor([0.4248], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544454574584961
Time for loss calculation for target: 0.011752605438232422
Time for Loss backward: 1.7901904582977295
Time needed for the batch 2.9043567180633545
Time needed for logging 0.007384777069091797
Training epoch 0 | batch 1100
Batch on Device 0 computed in 0.7400257587432861 seconds.
tensor([0.5378], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544299602508545
Time for loss calculation for target: 0.011838912963867188
Time for Loss backward: 1.789271354675293
Time needed for the batch 2.903783082962036
Time needed for logging 0.00717616081237793
Training epoch 0 | batch 1101
Batch on Device 0 computed in 0.7414233684539795 seconds.
tensor([0.4736], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544168472290039
Time for loss calculation for target: 0.011888504028320312
Time for Loss backward: 1.7922084331512451
Time needed for the batch 2.9077751636505127
Time needed for logging 0.007042407989501953
Training epoch 0 | batch 1102
Batch on Device 0 computed in 0.7409482002258301 seconds.
tensor([0.2837], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443639755249023
Time for loss calculation for target: 0.011770963668823242
Time for Loss backward: 1.7930612564086914
Time needed for the batch 2.9082090854644775
Time needed for logging 0.007226467132568359
Training epoch 0 | batch 1103
Batch on Device 0 computed in 0.740239143371582 seconds.
tensor([0.4644], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448241233825684
Time for loss calculation for target: 0.011827945709228516
Time for Loss backward: 1.7903978824615479
Time needed for the batch 2.9079365730285645
Time needed for logging 0.007261991500854492
Training epoch 0 | batch 1104
Batch on Device 0 computed in 0.73996901512146 seconds.
tensor([0.2953], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442399978637695
Time for loss calculation for target: 0.011833667755126953
Time for Loss backward: 1.793931007385254
Time needed for the batch 2.9081311225891113
Time needed for logging 0.007249593734741211
Training epoch 0 | batch 1105
Batch on Device 0 computed in 0.740032434463501 seconds.
tensor([0.3920], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544471263885498
Time for loss calculation for target: 0.011759757995605469
Time for Loss backward: 1.7902417182922363
Time needed for the batch 2.9060657024383545
Time needed for logging 0.007025241851806641
Training epoch 0 | batch 1106
Batch on Device 0 computed in 0.74005126953125 seconds.
tensor([0.3256], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544325828552246
Time for loss calculation for target: 0.011797189712524414
Time for Loss backward: 1.7889890670776367
Time needed for the batch 2.907677412033081
Time needed for logging 0.00713658332824707
Training epoch 0 | batch 1107
Batch on Device 0 computed in 0.7400405406951904 seconds.
tensor([0.1959], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545539379119873
Time for loss calculation for target: 0.01180577278137207
Time for Loss backward: 1.7905206680297852
Time needed for the batch 2.904857873916626
Time needed for logging 0.007299900054931641
Training epoch 0 | batch 1108
Batch on Device 0 computed in 0.7397046089172363 seconds.
tensor([0.4495], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543362617492676
Time for loss calculation for target: 0.011771917343139648
Time for Loss backward: 1.7899930477142334
Time needed for the batch 2.9040095806121826
Time needed for logging 0.007118940353393555
Training epoch 0 | batch 1109
Batch on Device 0 computed in 0.739948034286499 seconds.
tensor([0.3168], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443615913391113
Time for loss calculation for target: 0.011853933334350586
Time for Loss backward: 1.787109136581421
Time needed for the batch 2.9015839099884033
Time needed for logging 0.007178068161010742
Training epoch 0 | batch 1110
Batch on Device 0 computed in 0.743743896484375 seconds.
tensor([0.5092], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354433536529541
Time for loss calculation for target: 0.011831283569335938
Time for Loss backward: 1.7914018630981445
Time needed for the batch 2.9102916717529297
Time needed for logging 0.0071964263916015625
Training epoch 0 | batch 1111
Batch on Device 0 computed in 0.7399799823760986 seconds.
tensor([0.3133], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35446906089782715
Time for loss calculation for target: 0.011761665344238281
Time for Loss backward: 1.7921254634857178
Time needed for the batch 2.906325578689575
Time needed for logging 0.007307767868041992
Training epoch 0 | batch 1112
Batch on Device 0 computed in 0.7400262355804443 seconds.
tensor([0.4790], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543121814727783
Time for loss calculation for target: 0.011998414993286133
Time for Loss backward: 1.789020299911499
Time needed for the batch 2.903489589691162
Time needed for logging 0.007108211517333984
Training epoch 0 | batch 1113
Batch on Device 0 computed in 0.7400662899017334 seconds.
tensor([0.3337], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35447239875793457
Time for loss calculation for target: 0.011797428131103516
Time for Loss backward: 1.7927703857421875
Time needed for the batch 2.9071176052093506
Time needed for logging 0.007182598114013672
Training epoch 0 | batch 1114
Batch on Device 0 computed in 0.7401001453399658 seconds.
tensor([0.1401], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354433536529541
Time for loss calculation for target: 0.011797904968261719
Time for Loss backward: 1.7909250259399414
Time needed for the batch 2.9047529697418213
Time needed for logging 0.007230043411254883
Training epoch 0 | batch 1115
Batch on Device 0 computed in 0.7400498390197754 seconds.
tensor([0.4606], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543884754180908
Time for loss calculation for target: 0.011875391006469727
Time for Loss backward: 1.7896449565887451
Time needed for the batch 2.9040708541870117
Time needed for logging 0.0071277618408203125
Training epoch 0 | batch 1116
Batch on Device 0 computed in 0.740001916885376 seconds.
tensor([0.3034], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544619083404541
Time for loss calculation for target: 0.011841535568237305
Time for Loss backward: 1.7911720275878906
Time needed for the batch 2.905616521835327
Time needed for logging 0.007197380065917969
Training epoch 0 | batch 1117
Batch on Device 0 computed in 0.7400166988372803 seconds.
tensor([0.3331], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436177253723145
Time for loss calculation for target: 0.01171565055847168
Time for Loss backward: 1.7892341613769531
Time needed for the batch 2.903528928756714
Time needed for logging 0.0076160430908203125
Training epoch 0 | batch 1118
Batch on Device 0 computed in 0.740196704864502 seconds.
tensor([0.3542], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544309139251709
Time for loss calculation for target: 0.011836051940917969
Time for Loss backward: 1.7898547649383545
Time needed for the batch 2.9041459560394287
Time needed for logging 0.007294893264770508
Training epoch 0 | batch 1119
Batch on Device 0 computed in 0.7400891780853271 seconds.
tensor([0.5064], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35494446754455566
Time for loss calculation for target: 0.011890411376953125
Time for Loss backward: 1.7851009368896484
Time needed for the batch 2.9001681804656982
Time needed for logging 0.007283449172973633
Training epoch 0 | batch 1120
Batch on Device 0 computed in 0.7428250312805176 seconds.
tensor([0.5558], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35445523262023926
Time for loss calculation for target: 0.01175379753112793
Time for Loss backward: 1.787391185760498
Time needed for the batch 2.9045145511627197
Time needed for logging 0.007335662841796875
Training epoch 0 | batch 1121
Batch on Device 0 computed in 0.7402911186218262 seconds.
tensor([0.4511], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543977737426758
Time for loss calculation for target: 0.011803865432739258
Time for Loss backward: 1.792064905166626
Time needed for the batch 2.907360553741455
Time needed for logging 0.007125377655029297
Training epoch 0 | batch 1122
Batch on Device 0 computed in 0.7400269508361816 seconds.
tensor([0.4151], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443568229675293
Time for loss calculation for target: 0.011834859848022461
Time for Loss backward: 1.7908744812011719
Time needed for the batch 2.90864896774292
Time needed for logging 0.00683903694152832
Training epoch 0 | batch 1123
Batch on Device 0 computed in 0.7400727272033691 seconds.
tensor([0.4736], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35431647300720215
Time for loss calculation for target: 0.01193690299987793
Time for Loss backward: 1.7901370525360107
Time needed for the batch 2.904510736465454
Time needed for logging 0.007228851318359375
Training epoch 0 | batch 1124
Batch on Device 0 computed in 0.740004301071167 seconds.
tensor([0.4740], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544011116027832
Time for loss calculation for target: 0.011878013610839844
Time for Loss backward: 1.785874366760254
Time needed for the batch 2.9011690616607666
Time needed for logging 0.007294893264770508
Training epoch 0 | batch 1125
Batch on Device 0 computed in 0.7419528961181641 seconds.
tensor([0.2856], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544273376464844
Time for loss calculation for target: 0.011800527572631836
Time for Loss backward: 1.7934749126434326
Time needed for the batch 2.9109554290771484
Time needed for logging 0.007395029067993164
Training epoch 0 | batch 1126
Batch on Device 0 computed in 0.7401413917541504 seconds.
tensor([0.4249], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35441064834594727
Time for loss calculation for target: 0.011790275573730469
Time for Loss backward: 1.7905805110931396
Time needed for the batch 2.9052047729492188
Time needed for logging 0.007167339324951172
Training epoch 0 | batch 1127
Batch on Device 0 computed in 0.7402851581573486 seconds.
tensor([0.1321], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544280529022217
Time for loss calculation for target: 0.011841773986816406
Time for Loss backward: 1.7904469966888428
Time needed for the batch 2.904980421066284
Time needed for logging 0.007220268249511719
Training epoch 0 | batch 1128
Batch on Device 0 computed in 0.739936351776123 seconds.
tensor([0.3247], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440874099731445
Time for loss calculation for target: 0.01184391975402832
Time for Loss backward: 1.789442777633667
Time needed for the batch 2.903507709503174
Time needed for logging 0.0071315765380859375
Training epoch 0 | batch 1129
Batch on Device 0 computed in 0.7403900623321533 seconds.
tensor([0.5180], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544013500213623
Time for loss calculation for target: 0.011794567108154297
Time for Loss backward: 1.791034460067749
Time needed for the batch 2.905515670776367
Time needed for logging 0.007157802581787109
Training epoch 0 | batch 1130
Batch on Device 0 computed in 0.755272388458252 seconds.
tensor([0.5562], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544797897338867
Time for loss calculation for target: 0.011871099472045898
Time for Loss backward: 1.790686845779419
Time needed for the batch 2.9201760292053223
Time needed for logging 0.007238149642944336
Training epoch 0 | batch 1131
Batch on Device 0 computed in 0.7401554584503174 seconds.
tensor([0.4065], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544425964355469
Time for loss calculation for target: 0.011747598648071289
Time for Loss backward: 1.790332317352295
Time needed for the batch 2.904639959335327
Time needed for logging 0.0069391727447509766
Training epoch 0 | batch 1132
Batch on Device 0 computed in 0.7408955097198486 seconds.
tensor([0.6656], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544323444366455
Time for loss calculation for target: 0.01179361343383789
Time for Loss backward: 1.7894964218139648
Time needed for the batch 2.9046380519866943
Time needed for logging 0.007237434387207031
Training epoch 0 | batch 1133
Batch on Device 0 computed in 0.7399897575378418 seconds.
tensor([0.3395], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544325828552246
Time for loss calculation for target: 0.011940240859985352
Time for Loss backward: 1.7894651889801025
Time needed for the batch 2.903898239135742
Time needed for logging 0.007054328918457031
Training epoch 0 | batch 1134
Batch on Device 0 computed in 0.7399380207061768 seconds.
tensor([0.7131], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439038276672363
Time for loss calculation for target: 0.01191568374633789
Time for Loss backward: 1.7925915718078613
Time needed for the batch 2.906921148300171
Time needed for logging 0.007192373275756836
Training epoch 0 | batch 1135
Batch on Device 0 computed in 0.7411060333251953 seconds.
tensor([0.3843], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544299602508545
Time for loss calculation for target: 0.011865854263305664
Time for Loss backward: 1.7901084423065186
Time needed for the batch 2.9056167602539062
Time needed for logging 0.00709843635559082
Training epoch 0 | batch 1136
Batch on Device 0 computed in 0.7401731014251709 seconds.
tensor([0.2470], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35479235649108887
Time for loss calculation for target: 0.012013673782348633
Time for Loss backward: 1.7903544902801514
Time needed for the batch 2.9055562019348145
Time needed for logging 0.007273435592651367
Training epoch 0 | batch 1137
Batch on Device 0 computed in 0.7400004863739014 seconds.
tensor([0.4295], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3545107841491699
Time for loss calculation for target: 0.011650800704956055
Time for Loss backward: 1.7846345901489258
Time needed for the batch 2.8995065689086914
Time needed for logging 0.007075309753417969
Training epoch 0 | batch 1138
Batch on Device 0 computed in 0.7442939281463623 seconds.
tensor([0.2999], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448551177978516
Time for loss calculation for target: 0.011693000793457031
Time for Loss backward: 1.784571647644043
Time needed for the batch 2.9031612873077393
Time needed for logging 0.007211923599243164
Training epoch 0 | batch 1139
Batch on Device 0 computed in 0.7446489334106445 seconds.
tensor([0.6137], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544623851776123
Time for loss calculation for target: 0.011975765228271484
Time for Loss backward: 1.7904534339904785
Time needed for the batch 2.909392833709717
Time needed for logging 0.007000446319580078
Training epoch 0 | batch 1140
Batch on Device 0 computed in 0.7401845455169678 seconds.
tensor([0.4746], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35442638397216797
Time for loss calculation for target: 0.011812925338745117
Time for Loss backward: 1.7899188995361328
Time needed for the batch 2.9041013717651367
Time needed for logging 0.0074062347412109375
Training epoch 0 | batch 1141
Batch on Device 0 computed in 0.7405381202697754 seconds.
tensor([0.5036], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544135093688965
Time for loss calculation for target: 0.01166844367980957
Time for Loss backward: 1.790363073348999
Time needed for the batch 2.9051156044006348
Time needed for logging 0.0071561336517333984
Training epoch 0 | batch 1142
Batch on Device 0 computed in 0.7404570579528809 seconds.
tensor([0.4553], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35448360443115234
Time for loss calculation for target: 0.011664152145385742
Time for Loss backward: 1.789428949356079
Time needed for the batch 2.904040575027466
Time needed for logging 0.007243633270263672
Training epoch 0 | batch 1143
Batch on Device 0 computed in 0.7400434017181396 seconds.
tensor([0.4464], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544166088104248
Time for loss calculation for target: 0.011669635772705078
Time for Loss backward: 1.7868165969848633
Time needed for the batch 2.901132583618164
Time needed for logging 0.007181406021118164
Training epoch 0 | batch 1144
Batch on Device 0 computed in 0.7455861568450928 seconds.
tensor([0.3072], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437560081481934
Time for loss calculation for target: 0.011698722839355469
Time for Loss backward: 1.7849218845367432
Time needed for the batch 2.904514789581299
Time needed for logging 0.007035493850708008
Training epoch 0 | batch 1145
Batch on Device 0 computed in 0.7449295520782471 seconds.
tensor([0.4310], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440707206726074
Time for loss calculation for target: 0.011800527572631836
Time for Loss backward: 1.7846295833587646
Time needed for the batch 2.903533697128296
Time needed for logging 0.007205486297607422
Training epoch 0 | batch 1146
Batch on Device 0 computed in 0.7441060543060303 seconds.
tensor([0.3879], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544423580169678
Time for loss calculation for target: 0.011734485626220703
Time for Loss backward: 1.7905080318450928
Time needed for the batch 2.9086833000183105
Time needed for logging 0.007030010223388672
Training epoch 0 | batch 1147
Batch on Device 0 computed in 0.7407455444335938 seconds.
tensor([0.4186], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544321060180664
Time for loss calculation for target: 0.01166987419128418
Time for Loss backward: 1.789137840270996
Time needed for the batch 2.903886079788208
Time needed for logging 0.007289409637451172
Training epoch 0 | batch 1148
Batch on Device 0 computed in 0.7408642768859863 seconds.
tensor([0.3145], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.354428768157959
Time for loss calculation for target: 0.01168203353881836
Time for Loss backward: 1.7893428802490234
Time needed for the batch 2.9040918350219727
Time needed for logging 0.007161617279052734
Training epoch 0 | batch 1149
Batch on Device 0 computed in 0.7401258945465088 seconds.
tensor([0.3194], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35449886322021484
Time for loss calculation for target: 0.01166677474975586
Time for Loss backward: 1.7936320304870605
Time needed for the batch 2.9073846340179443
Time needed for logging 0.0070476531982421875
Training epoch 0 | batch 1150
Batch on Device 0 computed in 0.7402737140655518 seconds.
tensor([0.3985], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35436439514160156
Time for loss calculation for target: 0.011672496795654297
Time for Loss backward: 1.8511388301849365
Time needed for the batch 2.9654629230499268
Time needed for logging 0.006947755813598633
Training epoch 0 | batch 1151
Batch on Device 0 computed in 0.740246057510376 seconds.
tensor([0.2982], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543965816497803
Time for loss calculation for target: 0.01163482666015625
Time for Loss backward: 1.7885475158691406
Time needed for the batch 2.9025542736053467
Time needed for logging 0.006935834884643555
Training epoch 0 | batch 1152
Batch on Device 0 computed in 0.7416529655456543 seconds.
tensor([0.2988], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544313907623291
Time for loss calculation for target: 0.011717081069946289
Time for Loss backward: 1.7910199165344238
Time needed for the batch 2.9067680835723877
Time needed for logging 0.0071527957916259766
Training epoch 0 | batch 1153
Batch on Device 0 computed in 0.7402019500732422 seconds.
tensor([0.3071], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544602394104004
Time for loss calculation for target: 0.011696577072143555
Time for Loss backward: 1.789515495300293
Time needed for the batch 2.9036998748779297
Time needed for logging 0.0070040225982666016
Training epoch 0 | batch 1154
Batch on Device 0 computed in 0.7400639057159424 seconds.
tensor([0.0734], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35446977615356445
Time for loss calculation for target: 0.011680841445922852
Time for Loss backward: 1.7882895469665527
Time needed for the batch 2.902435541152954
Time needed for logging 0.006963253021240234
Training epoch 0 | batch 1155
Batch on Device 0 computed in 0.7401382923126221 seconds.
tensor([0.3844], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439467430114746
Time for loss calculation for target: 0.011761665344238281
Time for Loss backward: 1.7856621742248535
Time needed for the batch 2.899773359298706
Time needed for logging 0.0073010921478271484
Training epoch 0 | batch 1156
Batch on Device 0 computed in 0.7429091930389404 seconds.
tensor([0.5199], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439229011535645
Time for loss calculation for target: 0.011699914932250977
Time for Loss backward: 1.784372329711914
Time needed for the batch 2.9014506340026855
Time needed for logging 0.007482290267944336
Training epoch 0 | batch 1157
Batch on Device 0 computed in 0.7424166202545166 seconds.
tensor([0.4046], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440587997436523
Time for loss calculation for target: 0.011673688888549805
Time for Loss backward: 1.7868964672088623
Time needed for the batch 2.9033143520355225
Time needed for logging 0.007016420364379883
Training epoch 0 | batch 1158
Batch on Device 0 computed in 0.7449855804443359 seconds.
tensor([0.4696], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440826416015625
Time for loss calculation for target: 0.011675119400024414
Time for Loss backward: 1.7895474433898926
Time needed for the batch 2.908435583114624
Time needed for logging 0.0072231292724609375
Training epoch 0 | batch 1159
Batch on Device 0 computed in 0.7400753498077393 seconds.
tensor([0.3747], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3548445701599121
Time for loss calculation for target: 0.011806726455688477
Time for Loss backward: 1.7910871505737305
Time needed for the batch 2.906177043914795
Time needed for logging 0.0070037841796875
Training epoch 0 | batch 1160
Batch on Device 0 computed in 0.7401573657989502 seconds.
tensor([0.4160], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544182777404785
Time for loss calculation for target: 0.011940717697143555
Time for Loss backward: 1.7903642654418945
Time needed for the batch 2.904615879058838
Time needed for logging 0.006770133972167969
Training epoch 0 | batch 1161
Batch on Device 0 computed in 0.740060567855835 seconds.
tensor([0.1884], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35447168350219727
Time for loss calculation for target: 0.011729001998901367
Time for Loss backward: 1.7906174659729004
Time needed for the batch 2.904517412185669
Time needed for logging 0.006542205810546875
Training epoch 0 | batch 1162
Batch on Device 0 computed in 0.7429811954498291 seconds.
tensor([0.5603], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546316623687744
Time for loss calculation for target: 0.011817216873168945
Time for Loss backward: 1.7866370677947998
Time needed for the batch 2.903498888015747
Time needed for logging 0.0066356658935546875
Training epoch 0 | batch 1163
Batch on Device 0 computed in 0.7405741214752197 seconds.
tensor([0.1716], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439181327819824
Time for loss calculation for target: 0.011744976043701172
Time for Loss backward: 1.8481426239013672
Time needed for the batch 2.9631848335266113
Time needed for logging 0.00662684440612793
Training epoch 0 | batch 1164
Batch on Device 0 computed in 0.746077299118042 seconds.
tensor([0.5800], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35439467430114746
Time for loss calculation for target: 0.012322187423706055
Time for Loss backward: 1.7878694534301758
Time needed for the batch 2.9083101749420166
Time needed for logging 0.006598949432373047
Training epoch 0 | batch 1165
Batch on Device 0 computed in 0.739995002746582 seconds.
tensor([0.4142], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3546466827392578
Time for loss calculation for target: 0.011827468872070312
Time for Loss backward: 1.7888782024383545
Time needed for the batch 2.9031991958618164
Time needed for logging 0.007097721099853516
Training epoch 0 | batch 1166
Batch on Device 0 computed in 0.7401680946350098 seconds.
tensor([0.5237], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35440731048583984
Time for loss calculation for target: 0.011659860610961914
Time for Loss backward: 1.7874562740325928
Time needed for the batch 2.902142286300659
Time needed for logging 0.006625652313232422
Training epoch 0 | batch 1167
Batch on Device 0 computed in 0.7429149150848389 seconds.
tensor([0.5639], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35443544387817383
Time for loss calculation for target: 0.011629343032836914
Time for Loss backward: 1.7871265411376953
Time needed for the batch 2.903841733932495
Time needed for logging 0.006583690643310547
Training epoch 0 | batch 1168
Batch on Device 0 computed in 0.7403421401977539 seconds.
tensor([0.4107], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543975353240967
Time for loss calculation for target: 0.012041568756103516
Time for Loss backward: 1.7912514209747314
Time needed for the batch 2.906636953353882
Time needed for logging 0.006754159927368164
Training epoch 0 | batch 1169
Batch on Device 0 computed in 0.7400302886962891 seconds.
tensor([0.1473], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543076515197754
Time for loss calculation for target: 0.011670589447021484
Time for Loss backward: 1.7919933795928955
Time needed for the batch 2.905385971069336
Time needed for logging 0.006675243377685547
Training epoch 0 | batch 1170
Batch on Device 0 computed in 0.7399532794952393 seconds.
tensor([0.4150], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3543877601623535
Time for loss calculation for target: 0.011748790740966797
Time for Loss backward: 1.7885725498199463
Time needed for the batch 2.9021499156951904
Time needed for logging 0.006787300109863281
Training epoch 0 | batch 1171
Batch on Device 0 computed in 0.7399919033050537 seconds.
tensor([0.4853], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35437607765197754
Time for loss calculation for target: 0.011762380599975586
Time for Loss backward: 1.7896690368652344
Time needed for the batch 2.905013084411621
Time needed for logging 0.006669044494628906
Training epoch 0 | batch 1172
Batch on Device 0 computed in 0.7408361434936523 seconds.
tensor([0.0955], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.35449814796447754
Time for loss calculation for target: 0.012016534805297852
Time for Loss backward: 1.7904140949249268
Time needed for the batch 2.906437873840332
Time needed for logging 0.006621599197387695
Training epoch 0 | batch 1173
Batch on Device 0 computed in 0.7399821281433105 seconds.
tensor([0.4932], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544495105743408
Time for loss calculation for target: 0.011713266372680664
Time for Loss backward: 1.7911205291748047
Time needed for the batch 2.904933452606201
Time needed for logging 0.006646394729614258
Training epoch 0 | batch 1174
Batch on Device 0 computed in 0.7400522232055664 seconds.
tensor([0.1022], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3544166088104248
Time for loss calculation for target: 0.011630058288574219
Time for Loss backward: 1.788559913635254
Time needed for the batch 2.9022490978240967
Time needed for logging 0.007700443267822266
Validation
/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/site-packages/torch/nn/functional.py:4003: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
