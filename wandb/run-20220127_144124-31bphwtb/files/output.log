Length Target Train Loader: 44625
Length Target Validation Loader: 250
Length Source Train Loader: 4700
No checkpoint is used. Training from scratch!
[{'silog_depth': {'weight': 0.85}, 'bce': {'r': 0.3, 'ignore_index': 250}, 'snr': 'None'}]
[{'silog_depth': 1, 'bce': 0.001, 'snr': 0.01}]
Training supervised on source dataset using dense depth!
Training supervised on source dataset using semantic annotations!
Source ground truth scale is used for computing depth errors while training.
Source ground truth scale is used for computing depth errors while validating.
Training unsupervised on target dataset using self supervised depth!
Training started...
Training epoch 0 | batch 0
Batch on Device 0 computed in 3.308948278427124 seconds.
tensor([7.3924], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.036827802658081055
Time for loss calculation for target: 0.02461981773376465
Time for Loss backward: 4.947432518005371
Time needed for the batch 8.536113023757935
Time needed for logging 4.935264587402344e-05
Training epoch 0 | batch 1
Batch on Device 0 computed in 0.7096660137176514 seconds.
tensor([11.1432], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34278392791748047
Time for loss calculation for target: 0.03741312026977539
Time for Loss backward: 1.5836107730865479
Time needed for the batch 2.686650514602661
Time needed for logging 0.04995417594909668
Training epoch 0 | batch 2
Batch on Device 0 computed in 0.7097246646881104 seconds.
tensor([8.8898], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34087586402893066
Time for loss calculation for target: 0.01166081428527832
Time for Loss backward: 1.5786044597625732
Time needed for the batch 2.648949384689331
Time needed for logging 0.006856203079223633
Training epoch 0 | batch 3
Batch on Device 0 computed in 0.7097585201263428 seconds.
tensor([8.2989], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34083056449890137
Time for loss calculation for target: 0.01173543930053711
Time for Loss backward: 1.579366683959961
Time needed for the batch 2.651474714279175
Time needed for logging 0.007028341293334961
Training epoch 0 | batch 4
Batch on Device 0 computed in 0.7097673416137695 seconds.
tensor([8.5417], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3408496379852295
Time for loss calculation for target: 0.012039899826049805
Time for Loss backward: 1.5778107643127441
Time needed for the batch 2.6491239070892334
Time needed for logging 0.007100105285644531
Training epoch 0 | batch 5
Batch on Device 0 computed in 0.709667444229126 seconds.
tensor([6.3363], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34084415435791016
Time for loss calculation for target: 0.011803865432739258
Time for Loss backward: 1.5826592445373535
Time needed for the batch 2.6532063484191895
Time needed for logging 0.006910085678100586
Training epoch 0 | batch 6
Batch on Device 0 computed in 0.7096447944641113 seconds.
tensor([7.9545], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.340848445892334
Time for loss calculation for target: 0.011677265167236328
Time for Loss backward: 1.5809266567230225
Time needed for the batch 2.6515302658081055
Time needed for logging 0.007420539855957031
Training epoch 0 | batch 7
Batch on Device 0 computed in 0.709742546081543 seconds.
tensor([9.6316], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3408365249633789
Time for loss calculation for target: 0.011795997619628906
Time for Loss backward: 1.5777647495269775
Time needed for the batch 2.6486098766326904
Time needed for logging 0.007337808609008789
Training epoch 0 | batch 8
Batch on Device 0 computed in 0.7095851898193359 seconds.
tensor([7.8928], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34084057807922363
Time for loss calculation for target: 0.012078285217285156
Time for Loss backward: 1.5809714794158936
Time needed for the batch 2.6521706581115723
Time needed for logging 0.007181882858276367
Training epoch 0 | batch 9
Batch on Device 0 computed in 0.7110695838928223 seconds.
tensor([7.5066], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3409388065338135
Time for loss calculation for target: 0.01166987419128418
Time for Loss backward: 1.577605962753296
Time needed for the batch 2.6498725414276123
Time needed for logging 0.007241964340209961
Total time for 10 batches 59.970088958740234
Training epoch 0 | batch 10
Batch on Device 0 computed in 0.7152588367462158 seconds.
tensor([8.7947], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3434417247772217
Time for loss calculation for target: 0.01156306266784668
Time for Loss backward: 1.590851068496704
Time needed for the batch 2.670869827270508
Time needed for logging 0.0070037841796875
Training epoch 0 | batch 11
Batch on Device 0 computed in 0.7151679992675781 seconds.
tensor([8.0085], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3435060977935791
Time for loss calculation for target: 0.011861085891723633
Time for Loss backward: 1.592336893081665
Time needed for the batch 2.6705868244171143
Time needed for logging 0.007460832595825195
Training epoch 0 | batch 12
Batch on Device 0 computed in 0.7152173519134521 seconds.
tensor([6.6457], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34349751472473145
Time for loss calculation for target: 0.011701583862304688
Time for Loss backward: 1.5891954898834229
Time needed for the batch 2.6695737838745117
Time needed for logging 0.007088661193847656
Training epoch 0 | batch 13
Batch on Device 0 computed in 0.7152528762817383 seconds.
tensor([6.4549], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.343656063079834
Time for loss calculation for target: 0.011907577514648438
Time for Loss backward: 1.5858042240142822
Time needed for the batch 2.668778419494629
Time needed for logging 0.007280826568603516
Training epoch 0 | batch 14
Batch on Device 0 computed in 0.7151713371276855 seconds.
tensor([7.3678], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3434574604034424
Time for loss calculation for target: 0.011963129043579102
Time for Loss backward: 1.590444803237915
Time needed for the batch 2.669706106185913
Time needed for logging 0.0066797733306884766
Training epoch 0 | batch 15
Batch on Device 0 computed in 0.7151410579681396 seconds.
tensor([6.1737], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34351205825805664
Time for loss calculation for target: 0.011768579483032227
Time for Loss backward: 1.5917489528656006
Time needed for the batch 2.6717488765716553
Time needed for logging 0.006933927536010742
Training epoch 0 | batch 16
Batch on Device 0 computed in 0.7151980400085449 seconds.
tensor([6.5454], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3434915542602539
Time for loss calculation for target: 0.011690855026245117
Time for Loss backward: 1.589219570159912
Time needed for the batch 2.6689188480377197
Time needed for logging 0.008135557174682617
Training epoch 0 | batch 17
Batch on Device 0 computed in 0.7151615619659424 seconds.
tensor([6.0542], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3434576988220215
Time for loss calculation for target: 0.011682987213134766
Time for Loss backward: 1.5907483100891113
Time needed for the batch 2.6690170764923096
Time needed for logging 0.00701904296875
Training epoch 0 | batch 18
Batch on Device 0 computed in 0.7151894569396973 seconds.
tensor([6.2811], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34346461296081543
Time for loss calculation for target: 0.011889219284057617
Time for Loss backward: 1.5901241302490234
Time needed for the batch 2.6705799102783203
Time needed for logging 0.007096767425537109
Training epoch 0 | batch 19
Batch on Device 0 computed in 0.7153403759002686 seconds.
tensor([5.0021], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3435378074645996
Time for loss calculation for target: 0.01166677474975586
Time for Loss backward: 1.5832767486572266
Time needed for the batch 2.663728952407837
Time needed for logging 0.007050752639770508
Training epoch 0 | batch 20
Batch on Device 0 computed in 0.7192568778991699 seconds.
tensor([4.1835], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3435676097869873
Time for loss calculation for target: 0.011701583862304688
Time for Loss backward: 1.591480016708374
Time needed for the batch 2.6741037368774414
Time needed for logging 0.007431745529174805
Training epoch 0 | batch 21
Batch on Device 0 computed in 0.7150647640228271 seconds.
tensor([6.2172], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3434326648712158
Time for loss calculation for target: 0.012478113174438477
Time for Loss backward: 1.59306001663208
Time needed for the batch 2.671767473220825
Time needed for logging 0.007055759429931641
Training epoch 0 | batch 22
Batch on Device 0 computed in 0.7150845527648926 seconds.
tensor([5.1960], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3434634208679199
Time for loss calculation for target: 0.011658191680908203
Time for Loss backward: 1.5864059925079346
Time needed for the batch 2.6650962829589844
Time needed for logging 0.007048606872558594
Training epoch 0 | batch 23
Batch on Device 0 computed in 0.7152595520019531 seconds.
tensor([3.0951], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3435640335083008
Time for loss calculation for target: 0.011647224426269531
Time for Loss backward: 1.58925199508667
Time needed for the batch 2.672933340072632
Time needed for logging 0.0071375370025634766
Training epoch 0 | batch 24
Batch on Device 0 computed in 0.7150657176971436 seconds.
tensor([3.9966], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3434715270996094
Time for loss calculation for target: 0.011670589447021484
Time for Loss backward: 1.5919456481933594
Time needed for the batch 2.6703896522521973
Time needed for logging 0.00711822509765625
Training epoch 0 | batch 25
Batch on Device 0 computed in 0.7150628566741943 seconds.
tensor([3.1802], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3435535430908203
Time for loss calculation for target: 0.012045145034790039
Time for Loss backward: 1.5860741138458252
Time needed for the batch 2.6648099422454834
Time needed for logging 0.006969451904296875
Training epoch 0 | batch 26
Batch on Device 0 computed in 0.7194209098815918 seconds.
tensor([4.2501], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34343719482421875
Time for loss calculation for target: 0.011661529541015625
Time for Loss backward: 1.5876824855804443
Time needed for the batch 2.670325756072998
Time needed for logging 0.00801396369934082
Training epoch 0 | batch 27
Batch on Device 0 computed in 0.715118408203125 seconds.
tensor([4.2512], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34347105026245117
Time for loss calculation for target: 0.011720895767211914
Time for Loss backward: 1.5943448543548584
Time needed for the batch 2.6749844551086426
Time needed for logging 0.007737159729003906
Training epoch 0 | batch 28
Batch on Device 0 computed in 0.7208576202392578 seconds.
tensor([2.3707], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3461599349975586
Time for loss calculation for target: 0.011783838272094727
Time for Loss backward: 1.6021575927734375
Time needed for the batch 2.691345691680908
Time needed for logging 0.0071718692779541016
Training epoch 0 | batch 29
Batch on Device 0 computed in 0.7208948135375977 seconds.
tensor([3.9899], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34615254402160645
Time for loss calculation for target: 0.012018918991088867
Time for Loss backward: 1.5983471870422363
Time needed for the batch 2.6858601570129395
Time needed for logging 0.007493257522583008
Training epoch 0 | batch 30
Batch on Device 0 computed in 0.722050666809082 seconds.
tensor([2.5607], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34624600410461426
Time for loss calculation for target: 0.011607170104980469
Time for Loss backward: 1.598621129989624
Time needed for the batch 2.6864876747131348
Time needed for logging 0.007131338119506836
Training epoch 0 | batch 31
Batch on Device 0 computed in 0.7207012176513672 seconds.
tensor([2.2153], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3461620807647705
Time for loss calculation for target: 0.011638402938842773
Time for Loss backward: 1.598879337310791
Time needed for the batch 2.6858646869659424
Time needed for logging 0.007359981536865234
Training epoch 0 | batch 32
Batch on Device 0 computed in 0.720820426940918 seconds.
tensor([1.7947], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34609246253967285
Time for loss calculation for target: 0.011815786361694336
Time for Loss backward: 1.59818696975708
Time needed for the batch 2.687180519104004
Time needed for logging 0.007126331329345703
Training epoch 0 | batch 33
Batch on Device 0 computed in 0.722679853439331 seconds.
tensor([2.1554], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3460671901702881
Time for loss calculation for target: 0.011621713638305664
Time for Loss backward: 1.6003015041351318
Time needed for the batch 2.688833475112915
Time needed for logging 0.007149219512939453
Training epoch 0 | batch 34
Batch on Device 0 computed in 0.720665454864502 seconds.
tensor([1.1075], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34619808197021484
Time for loss calculation for target: 0.011842966079711914
Time for Loss backward: 1.670008659362793
Time needed for the batch 2.7572436332702637
Time needed for logging 0.0070531368255615234
Training epoch 0 | batch 35
Batch on Device 0 computed in 0.7205862998962402 seconds.
tensor([1.4443], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3460240364074707
Time for loss calculation for target: 0.011901140213012695
Time for Loss backward: 1.6004462242126465
Time needed for the batch 2.688265323638916
Time needed for logging 0.007012605667114258
Training epoch 0 | batch 36
Batch on Device 0 computed in 0.7206523418426514 seconds.
tensor([1.4089], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34619665145874023
Time for loss calculation for target: 0.011865377426147461
Time for Loss backward: 1.6017467975616455
Time needed for the batch 2.688983201980591
Time needed for logging 0.008312225341796875
Training epoch 0 | batch 37
Batch on Device 0 computed in 0.720632791519165 seconds.
tensor([1.2206], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.346149206161499
Time for loss calculation for target: 0.011691570281982422
Time for Loss backward: 1.5992364883422852
Time needed for the batch 2.685687303543091
Time needed for logging 0.006880044937133789
Training epoch 0 | batch 38
Batch on Device 0 computed in 0.7207167148590088 seconds.
tensor([1.0525], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.345994234085083
Time for loss calculation for target: 0.011687278747558594
Time for Loss backward: 1.5972418785095215
Time needed for the batch 2.6845788955688477
Time needed for logging 0.007195711135864258
Training epoch 0 | batch 39
Batch on Device 0 computed in 0.7214009761810303 seconds.
tensor([1.1455], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34607815742492676
Time for loss calculation for target: 0.011840581893920898
Time for Loss backward: 1.5972599983215332
Time needed for the batch 2.6865649223327637
Time needed for logging 0.00722193717956543
Training epoch 0 | batch 40
Batch on Device 0 computed in 0.7206466197967529 seconds.
tensor([1.1326], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34615135192871094
Time for loss calculation for target: 0.011682748794555664
Time for Loss backward: 1.6010894775390625
Time needed for the batch 2.687986373901367
Time needed for logging 0.0070323944091796875
Training epoch 0 | batch 41
Batch on Device 0 computed in 0.7206640243530273 seconds.
tensor([1.2228], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3461270332336426
Time for loss calculation for target: 0.01178741455078125
Time for Loss backward: 1.6018786430358887
Time needed for the batch 2.6886415481567383
Time needed for logging 0.00788569450378418
Training epoch 0 | batch 42
Batch on Device 0 computed in 0.7206692695617676 seconds.
tensor([1.8297], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3461267948150635
Time for loss calculation for target: 0.01181483268737793
Time for Loss backward: 1.5989034175872803
Time needed for the batch 2.6867878437042236
Time needed for logging 0.0071980953216552734
Training epoch 0 | batch 43
Batch on Device 0 computed in 0.7206165790557861 seconds.
tensor([0.6514], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34604549407958984
Time for loss calculation for target: 0.011842727661132812
Time for Loss backward: 1.5980665683746338
Time needed for the batch 2.6850714683532715
Time needed for logging 0.006996870040893555
Training epoch 0 | batch 44
Batch on Device 0 computed in 0.7209250926971436 seconds.
tensor([0.6379], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3464813232421875
Time for loss calculation for target: 0.011794328689575195
Time for Loss backward: 1.5949499607086182
Time needed for the batch 2.6844940185546875
Time needed for logging 0.00720977783203125
Training epoch 0 | batch 45
Batch on Device 0 computed in 0.7206957340240479 seconds.
tensor([0.5736], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3461325168609619
Time for loss calculation for target: 0.011600494384765625
Time for Loss backward: 1.5996050834655762
Time needed for the batch 2.6878678798675537
Time needed for logging 0.007253885269165039
Training epoch 0 | batch 46
Batch on Device 0 computed in 0.7206442356109619 seconds.
tensor([0.5382], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34603238105773926
Time for loss calculation for target: 0.01165318489074707
Time for Loss backward: 1.5976481437683105
Time needed for the batch 2.6846578121185303
Time needed for logging 0.007611989974975586
Training epoch 0 | batch 47
Batch on Device 0 computed in 0.7207331657409668 seconds.
tensor([0.4247], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3462507724761963
Time for loss calculation for target: 0.011871099472045898
Time for Loss backward: 1.5981383323669434
Time needed for the batch 2.68825101852417
Time needed for logging 0.006928443908691406
Training epoch 0 | batch 48
Batch on Device 0 computed in 0.7207798957824707 seconds.
tensor([0.5989], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.346635103225708
Time for loss calculation for target: 0.011855363845825195
Time for Loss backward: 1.5982749462127686
Time needed for the batch 2.6873011589050293
Time needed for logging 0.007523775100708008
Training epoch 0 | batch 49
Batch on Device 0 computed in 0.7208809852600098 seconds.
tensor([0.6630], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34609246253967285
Time for loss calculation for target: 0.011742115020751953
Time for Loss backward: 1.593322515487671
Time needed for the batch 2.6798224449157715
Time needed for logging 0.007218837738037109
Training epoch 0 | batch 50
Batch on Device 0 computed in 0.7250616550445557 seconds.
tensor([0.3385], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34610557556152344
Time for loss calculation for target: 0.011727333068847656
Time for Loss backward: 1.5961451530456543
Time needed for the batch 2.6874592304229736
Time needed for logging 0.007285356521606445
Training epoch 0 | batch 51
Batch on Device 0 computed in 0.7206034660339355 seconds.
tensor([0.8721], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3461453914642334
Time for loss calculation for target: 0.011563539505004883
Time for Loss backward: 1.5989341735839844
Time needed for the batch 2.6903510093688965
Time needed for logging 0.007449626922607422
Training epoch 0 | batch 52
Batch on Device 0 computed in 0.7206623554229736 seconds.
tensor([0.8149], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3464353084564209
Time for loss calculation for target: 0.01177215576171875
Time for Loss backward: 1.5924575328826904
Time needed for the batch 2.681920051574707
Time needed for logging 0.007239341735839844
Training epoch 0 | batch 53
Batch on Device 0 computed in 0.7206070423126221 seconds.
tensor([0.4943], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34618592262268066
Time for loss calculation for target: 0.011639118194580078
Time for Loss backward: 1.593571424484253
Time needed for the batch 2.6809284687042236
Time needed for logging 0.007430076599121094
Training epoch 0 | batch 54
Batch on Device 0 computed in 0.7217512130737305 seconds.
tensor([0.5407], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3461625576019287
Time for loss calculation for target: 0.01166391372680664
Time for Loss backward: 1.597475290298462
Time needed for the batch 2.686013698577881
Time needed for logging 0.0073544979095458984
Training epoch 0 | batch 55
Batch on Device 0 computed in 0.7207961082458496 seconds.
tensor([0.3205], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3461148738861084
Time for loss calculation for target: 0.011660337448120117
Time for Loss backward: 1.597869873046875
Time needed for the batch 2.684757947921753
Time needed for logging 0.007149696350097656
Training epoch 0 | batch 56
Batch on Device 0 computed in 0.7208359241485596 seconds.
tensor([0.8747], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3462345600128174
Time for loss calculation for target: 0.011772871017456055
Time for Loss backward: 1.5931077003479004
Time needed for the batch 2.680539131164551
Time needed for logging 0.007748126983642578
Training epoch 0 | batch 57
Batch on Device 0 computed in 0.7207260131835938 seconds.
tensor([1.0505], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3461320400238037
Time for loss calculation for target: 0.011870861053466797
Time for Loss backward: 1.6000006198883057
Time needed for the batch 2.6917684078216553
Time needed for logging 0.00722503662109375
Training epoch 0 | batch 58
Batch on Device 0 computed in 0.72076416015625 seconds.
tensor([0.7381], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34609389305114746
Time for loss calculation for target: 0.011692047119140625
Time for Loss backward: 1.600825548171997
Time needed for the batch 2.6878933906555176
Time needed for logging 0.0072286128997802734
Training epoch 0 | batch 59
