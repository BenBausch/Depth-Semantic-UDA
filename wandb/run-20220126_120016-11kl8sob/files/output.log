Length Target Train Loader: 89250
Length Target Validation Loader: 500
Length Source Train Loader: 89250
No checkpoint is used. Training from scratch!
[{'silog_depth': {'weight': 0.85}, 'bce': {'r': 0.3, 'ignore_index': 250}, 'snr': 'None'}]
[{'silog_depth': 1, 'bce': 0.001, 'snr': 0.01}]
Training supervised on source dataset using dense depth!
Training supervised on source dataset using semantic annotations!
Source ground truth scale is used for computing depth errors while training.
Source ground truth scale is used for computing depth errors while validating.
Training unsupervised on target dataset using self supervised depth!
Training started...
Training epoch 0 | batch 0
Batch on Device 0 computed in 4.301247596740723 seconds.
Time for loss calculation for source: 0.19172191619873047
Batch on Device 0 computed in 0.4438974857330322 seconds.
Time for loss calculation for target: 0.03186297416687012
tensor(8.1635, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 5.154731035232544
Time needed for the batch 10.343929529190063
Time needed for logging 3.2901763916015625e-05
Training epoch 0 | batch 1
Batch on Device 0 computed in 0.02129077911376953 seconds.
Time for loss calculation for source: 0.5753498077392578
Batch on Device 0 computed in 0.023448944091796875 seconds.
Time for loss calculation for target: 0.3656008243560791
tensor(9.8063, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4825537204742432
Time needed for the batch 2.4885361194610596
Time needed for logging 0.05475354194641113
Training epoch 0 | batch 2
Batch on Device 0 computed in 0.017197132110595703 seconds.
Time for loss calculation for source: 0.5818691253662109
Batch on Device 0 computed in 0.02056407928466797 seconds.
Time for loss calculation for target: 0.36984920501708984
tensor(7.9542, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4855680465698242
Time needed for the batch 2.491497755050659
Time needed for logging 0.007390499114990234
Training epoch 0 | batch 3
Batch on Device 0 computed in 0.022545576095581055 seconds.
Time for loss calculation for source: 0.5766096115112305
Batch on Device 0 computed in 0.0207521915435791 seconds.
Time for loss calculation for target: 0.3696286678314209
tensor(7.6120, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4837899208068848
Time needed for the batch 2.4894919395446777
Time needed for logging 0.007440328598022461
Training epoch 0 | batch 4
Batch on Device 0 computed in 0.016464710235595703 seconds.
Time for loss calculation for source: 0.5825197696685791
Batch on Device 0 computed in 0.020409822463989258 seconds.
Time for loss calculation for target: 0.3699517250061035
tensor(7.9304, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4803082942962646
Time needed for the batch 2.4860739707946777
Time needed for logging 0.007571697235107422
Training epoch 0 | batch 5
Batch on Device 0 computed in 0.016448497772216797 seconds.
Time for loss calculation for source: 0.582444429397583
Batch on Device 0 computed in 0.020320892333984375 seconds.
Time for loss calculation for target: 0.3699944019317627
tensor(6.9247, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4833121299743652
Time needed for the batch 2.4888293743133545
Time needed for logging 0.007668256759643555
Training epoch 0 | batch 6
Batch on Device 0 computed in 0.02145862579345703 seconds.
Time for loss calculation for source: 0.5773880481719971
Batch on Device 0 computed in 0.020308256149291992 seconds.
Time for loss calculation for target: 0.3700072765350342
tensor(7.1458, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.484633445739746
Time needed for the batch 2.4904348850250244
Time needed for logging 0.00774073600769043
Training epoch 0 | batch 7
Batch on Device 0 computed in 0.01703929901123047 seconds.
Time for loss calculation for source: 0.5818037986755371
Batch on Device 0 computed in 0.02028656005859375 seconds.
Time for loss calculation for target: 0.370023250579834
tensor(8.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.48417329788208
Time needed for the batch 2.489258289337158
Time needed for logging 0.007645130157470703
Training epoch 0 | batch 8
Batch on Device 0 computed in 0.016165733337402344 seconds.
Time for loss calculation for source: 0.582775354385376
Batch on Device 0 computed in 0.020357847213745117 seconds.
Time for loss calculation for target: 0.3699662685394287
tensor(7.7055, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4794082641601562
Time needed for the batch 2.4849612712860107
Time needed for logging 0.007632732391357422
Training epoch 0 | batch 9
Batch on Device 0 computed in 0.016198396682739258 seconds.
Time for loss calculation for source: 0.5882189273834229
Batch on Device 0 computed in 0.02035999298095703 seconds.
Time for loss calculation for target: 0.37300777435302734
tensor(9.4437, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4955878257751465
Time needed for the batch 2.509953260421753
Time needed for logging 0.007700443267822266
Total time for 10 batches 35.63872456550598
Training epoch 0 | batch 10
Batch on Device 0 computed in 0.0160675048828125 seconds.
Time for loss calculation for source: 0.5872151851654053
Batch on Device 0 computed in 0.02022409439086914 seconds.
Time for loss calculation for target: 0.37313342094421387
tensor(9.6451, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4951763153076172
Time needed for the batch 2.5081541538238525
Time needed for logging 0.007613658905029297
Training epoch 0 | batch 11
Batch on Device 0 computed in 0.01616525650024414 seconds.
Time for loss calculation for source: 0.5875346660614014
Batch on Device 0 computed in 0.022529125213623047 seconds.
Time for loss calculation for target: 0.3708314895629883
tensor(9.2545, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.494546890258789
Time needed for the batch 2.5077719688415527
Time needed for logging 0.00786137580871582
Training epoch 0 | batch 12
Batch on Device 0 computed in 0.017037153244018555 seconds.
Time for loss calculation for source: 0.5862870216369629
Batch on Device 0 computed in 0.020282983779907227 seconds.
Time for loss calculation for target: 0.3730812072753906
tensor(7.8081, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4945342540740967
Time needed for the batch 2.507478713989258
Time needed for logging 0.007862329483032227
Training epoch 0 | batch 13
Batch on Device 0 computed in 0.01690959930419922 seconds.
Time for loss calculation for source: 0.5866286754608154
Batch on Device 0 computed in 0.02035689353942871 seconds.
Time for loss calculation for target: 0.3730168342590332
tensor(5.6764, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4889187812805176
Time needed for the batch 2.502326726913452
Time needed for logging 0.007773637771606445
Training epoch 0 | batch 14
Batch on Device 0 computed in 0.015817880630493164 seconds.
Time for loss calculation for source: 0.5875356197357178
Batch on Device 0 computed in 0.02036762237548828 seconds.
Time for loss calculation for target: 0.37300539016723633
tensor(5.2002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4955074787139893
Time needed for the batch 2.508399248123169
Time needed for logging 0.00781559944152832
Training epoch 0 | batch 15
Batch on Device 0 computed in 0.015926599502563477 seconds.
Time for loss calculation for source: 0.5875496864318848
Batch on Device 0 computed in 0.020370960235595703 seconds.
Time for loss calculation for target: 0.3729884624481201
tensor(5.2303, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4953112602233887
Time needed for the batch 2.5086472034454346
Time needed for logging 0.00797724723815918
Training epoch 0 | batch 16
Batch on Device 0 computed in 0.016924381256103516 seconds.
Time for loss calculation for source: 0.5867269039154053
Batch on Device 0 computed in 0.020654678344726562 seconds.
Time for loss calculation for target: 0.37273097038269043
tensor(3.4903, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4947283267974854
Time needed for the batch 2.5078227519989014
Time needed for logging 0.0075795650482177734
Training epoch 0 | batch 17
Batch on Device 0 computed in 0.01680779457092285 seconds.
Time for loss calculation for source: 0.586761474609375
Batch on Device 0 computed in 0.022902488708496094 seconds.
Time for loss calculation for target: 0.37035322189331055
tensor(4.5879, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4887418746948242
Time needed for the batch 2.501991033554077
Time needed for logging 0.007790088653564453
Training epoch 0 | batch 18
Batch on Device 0 computed in 0.01601696014404297 seconds.
Time for loss calculation for source: 0.5875780582427979
Batch on Device 0 computed in 0.020231962203979492 seconds.
Time for loss calculation for target: 0.3731505870819092
tensor(4.5484, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4960229396820068
Time needed for the batch 2.50946307182312
Time needed for logging 0.007782697677612305
Training epoch 0 | batch 19
Batch on Device 0 computed in 0.016062021255493164 seconds.
Time for loss calculation for source: 0.5875253677368164
Batch on Device 0 computed in 0.0201718807220459 seconds.
Time for loss calculation for target: 0.3732271194458008
tensor(2.4860, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.495560646057129
Time needed for the batch 2.508986473083496
Time needed for logging 0.007769584655761719
Training epoch 0 | batch 20
Batch on Device 0 computed in 0.016280412673950195 seconds.
Time for loss calculation for source: 0.5874266624450684
Batch on Device 0 computed in 0.020294904708862305 seconds.
Time for loss calculation for target: 0.3730907440185547
tensor(3.0469, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4952738285064697
Time needed for the batch 2.5086443424224854
Time needed for logging 0.007689237594604492
Training epoch 0 | batch 21
Batch on Device 0 computed in 0.017061471939086914 seconds.
Time for loss calculation for source: 0.5876750946044922
Batch on Device 0 computed in 0.02028822898864746 seconds.
Time for loss calculation for target: 0.37308669090270996
tensor(2.3763, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.49552321434021
Time needed for the batch 2.5101094245910645
Time needed for logging 0.007972002029418945
Training epoch 0 | batch 22
Batch on Device 0 computed in 0.017240285873413086 seconds.
Time for loss calculation for source: 0.5865178108215332
Batch on Device 0 computed in 0.020228862762451172 seconds.
Time for loss calculation for target: 0.3731377124786377
tensor(2.7743, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.496809959411621
Time needed for the batch 2.510150909423828
Time needed for logging 0.007934331893920898
Training epoch 0 | batch 23
Batch on Device 0 computed in 0.01604437828063965 seconds.
Time for loss calculation for source: 0.5874598026275635
Batch on Device 0 computed in 0.020450830459594727 seconds.
Time for loss calculation for target: 0.3729233741760254
tensor(3.2307, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4961416721343994
Time needed for the batch 2.509079694747925
Time needed for logging 0.007710695266723633
Training epoch 0 | batch 24
Batch on Device 0 computed in 0.01601409912109375 seconds.
Time for loss calculation for source: 0.5875494480133057
Batch on Device 0 computed in 0.020254135131835938 seconds.
Time for loss calculation for target: 0.3731257915496826
tensor(2.2670, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4959096908569336
Time needed for the batch 2.509183168411255
Time needed for logging 0.007696866989135742
Training epoch 0 | batch 25
Batch on Device 0 computed in 0.01601552963256836 seconds.
Time for loss calculation for source: 0.5875406265258789
Batch on Device 0 computed in 0.020325183868408203 seconds.
Time for loss calculation for target: 0.37305545806884766
tensor(2.0368, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.4956800937652588
Time needed for the batch 2.5089263916015625
Time needed for logging 0.007940292358398438
Training epoch 0 | batch 26
Batch on Device 0 computed in 0.01700282096862793 seconds.
Time for loss calculation for source: 0.5920605659484863
Batch on Device 0 computed in 0.020218849182128906 seconds.
Time for loss calculation for target: 0.3762333393096924
tensor(1.7608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.5066218376159668
Time needed for the batch 2.528799533843994
Time needed for logging 0.0077533721923828125
Training epoch 0 | batch 27
Batch on Device 0 computed in 0.017138004302978516 seconds.
Time for loss calculation for source: 0.5911412239074707
Batch on Device 0 computed in 0.020486831665039062 seconds.
Time for loss calculation for target: 0.375948429107666
tensor(1.5676, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.5049152374267578
Time needed for the batch 2.526069402694702
Time needed for logging 0.007950067520141602
Training epoch 0 | batch 28
Batch on Device 0 computed in 0.015854835510253906 seconds.
Time for loss calculation for source: 0.5921707153320312
Batch on Device 0 computed in 0.020398855209350586 seconds.
Time for loss calculation for target: 0.37603044509887695
tensor(1.1560, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.505462408065796
Time needed for the batch 2.526244640350342
Time needed for logging 0.007892847061157227
Training epoch 0 | batch 29
Batch on Device 0 computed in 0.01673436164855957 seconds.
Time for loss calculation for source: 0.5913803577423096
Batch on Device 0 computed in 0.02012348175048828 seconds.
Time for loss calculation for target: 0.3763108253479004
tensor(1.1278, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.5055286884307861
Time needed for the batch 2.526560068130493
Time needed for logging 0.007714033126831055
Training epoch 0 | batch 30
Batch on Device 0 computed in 0.01730036735534668 seconds.
Time for loss calculation for source: 0.591055154800415
Batch on Device 0 computed in 0.020337581634521484 seconds.
Time for loss calculation for target: 0.3761413097381592
tensor(1.4309, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.5072741508483887
Time needed for the batch 2.5287139415740967
Time needed for logging 0.007901191711425781
Training epoch 0 | batch 31
Batch on Device 0 computed in 0.01710057258605957 seconds.
Time for loss calculation for source: 0.5912141799926758
Batch on Device 0 computed in 0.020564794540405273 seconds.
Time for loss calculation for target: 0.3758671283721924
tensor(1.3105, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.5002892017364502
Time needed for the batch 2.5214412212371826
Time needed for logging 0.007704973220825195
Training epoch 0 | batch 32
Batch on Device 0 computed in 0.021834850311279297 seconds.
Time for loss calculation for source: 0.5876376628875732
Batch on Device 0 computed in 0.022460222244262695 seconds.
Time for loss calculation for target: 0.3739645481109619
tensor(1.8657, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.5061655044555664
Time needed for the batch 2.5286436080932617
Time needed for logging 0.007670402526855469
Training epoch 0 | batch 33
Batch on Device 0 computed in 0.016008853912353516 seconds.
Time for loss calculation for source: 0.5921642780303955
Batch on Device 0 computed in 0.02028346061706543 seconds.
Time for loss calculation for target: 0.3761467933654785
tensor(1.0784, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for Loss backward: 1.5059788227081299
Time needed for the batch 2.526623249053955
Time needed for logging 0.007811307907104492
Training epoch 0 | batch 34
Batch on Device 0 computed in 0.01706671714782715 seconds.
Time for loss calculation for source: 0.5912370681762695
Batch on Device 0 computed in 0.028192758560180664 seconds.
Time for loss calculation for target: 0.3682844638824463
