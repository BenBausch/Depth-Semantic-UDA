Length Target Train Loader: 44625
Length Target Validation Loader: 250
Length Source Train Loader: 44625
No checkpoint is used. Training from scratch!
[{'silog_depth': {'weight': 0.85}, 'bce': {'r': 0.3, 'ignore_index': 250}, 'snr': 'None'}]
[{'silog_depth': 1, 'bce': 0.001, 'snr': 0.01}]
Training supervised on source dataset using dense depth!
Training supervised on source dataset using semantic annotations!
Source ground truth scale is used for computing depth errors while training.
Source ground truth scale is used for computing depth errors while validating.
Training unsupervised on target dataset using self supervised depth!
Training started...
/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/site-packages/torch/nn/functional.py:4003: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
Training epoch 0 | batch 0
Batch on Device 0 computed in 3.2912323474884033 seconds.
tensor([10.3966], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 8.445926904678345
Time for Loss backward: 4.87968635559082
Training epoch 0 | batch 1
Batch on Device 0 computed in 0.7103481292724609 seconds.
tensor([11.1754], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.688340187072754
Time for Loss backward: 1.5833666324615479
Training epoch 0 | batch 2
Batch on Device 0 computed in 0.7100222110748291 seconds.
tensor([8.3659], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.659306049346924
Time for Loss backward: 1.5868864059448242
Training epoch 0 | batch 3
Batch on Device 0 computed in 0.7107594013214111 seconds.
tensor([9.0052], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.660773754119873
Time for Loss backward: 1.5894477367401123
Training epoch 0 | batch 4
Batch on Device 0 computed in 0.7152438163757324 seconds.
tensor([8.0499], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.676197052001953
Time for Loss backward: 1.597522497177124
Training epoch 0 | batch 5
Batch on Device 0 computed in 0.7151896953582764 seconds.
tensor([7.5481], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.68062424659729
Time for Loss backward: 1.5972919464111328
Training epoch 0 | batch 6
Batch on Device 0 computed in 0.7151048183441162 seconds.
tensor([10.9939], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.6758739948272705
Time for Loss backward: 1.5915043354034424
Training epoch 0 | batch 7
Batch on Device 0 computed in 0.7179114818572998 seconds.
tensor([7.9209], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.6720407009124756
Time for Loss backward: 1.590440273284912
Training epoch 0 | batch 8
Batch on Device 0 computed in 0.7199649810791016 seconds.
tensor([10.3671], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.677874803543091
Time for Loss backward: 1.5945987701416016
Training epoch 0 | batch 9
Batch on Device 0 computed in 0.7157802581787109 seconds.
tensor([9.0632], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.675957202911377
Time for Loss backward: 1.5949511528015137
Total time for 10 batches 60.53716325759888
Validation
set eval mode
set eval mode
set eval mode
set eval mode
