Length Target Train Loader: 44625
Length Target Validation Loader: 250
Length Source Train Loader: 4700
No checkpoint is used. Training from scratch!
[{'silog_depth': {'weight': 0.85}, 'bce': {'r': 0.3, 'ignore_index': 250}, 'snr': 'None'}]
[{'silog_depth': 1, 'bce': 0.001, 'snr': 0.01}]
Training supervised on source dataset using dense depth!
Training supervised on source dataset using semantic annotations!
Source ground truth scale is used for computing depth errors while training.
Source ground truth scale is used for computing depth errors while validating.
Training unsupervised on target dataset using self supervised depth!
Training started...
[W python_anomaly_mode.cpp:104] Warning: Error detected in torch::autograd::AccumulateGrad. Traceback of forward call that caused the error:
  File "<string>", line 1, in <module>
  File "/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/home/bauschb/Masterthesis/Depth-Semantic-UDA/train/base/train_base.py", line 35, in run_trainer
    trainer = TrainerClass(device_id, cfg, world_size)
  File "/home/bauschb/Masterthesis/Depth-Semantic-UDA/train/guda/train_synthia_to_cityscapes.py", line 25, in __init__
    super(GUDATrainer, self).__init__(device_id=device_id, cfg=cfg, world_size=world_size)
  File "/home/bauschb/Masterthesis/Depth-Semantic-UDA/train/base/train_base.py", line 245, in __init__
    super(TrainSourceTargetDatasetBase, self).__init__(cfg=cfg, device_id=device_id, world_size=world_size)
  File "/home/bauschb/Masterthesis/Depth-Semantic-UDA/train/base/train_base.py", line 72, in __init__
    self.model = CustomDistributedDataParallel(self.model, device_ids=[device_id], find_unused_parameters=True)
  File "/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 587, in __init__
    self._ddp_init_helper(parameters, expect_sparse_gradient, param_to_name_mapping)
  File "/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 632, in _ddp_init_helper
    self.reducer = dist.Reducer(
