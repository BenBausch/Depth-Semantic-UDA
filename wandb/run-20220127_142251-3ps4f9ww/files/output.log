Length Target Train Loader: 44625
Length Target Validation Loader: 250
Length Source Train Loader: 4700
No checkpoint is used. Training from scratch!
[{'silog_depth': {'weight': 0.85}, 'bce': {'r': 0.3, 'ignore_index': 250}, 'snr': 'None'}]
[{'silog_depth': 1, 'bce': 0.001, 'snr': 0.01}]
Training supervised on source dataset using dense depth!
Training supervised on source dataset using semantic annotations!
Source ground truth scale is used for computing depth errors while training.
Source ground truth scale is used for computing depth errors while validating.
Training unsupervised on target dataset using self supervised depth!
Training started...
Training epoch 0 | batch 0
Batch on Device 0 computed in 3.3749167919158936 seconds.
tensor([7.3924], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.015595674514770508
Time for loss calculation for target: 0.09372305870056152
Time for Loss backward: 5.232672691345215
Time needed for the batch 8.946847438812256
Time needed for logging 5.316734313964844e-05
Training epoch 0 | batch 1
Batch on Device 0 computed in 0.7411072254180908 seconds.
tensor([11.1432], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.32582926750183105
Time for loss calculation for target: 0.09936690330505371
Time for Loss backward: 1.8776862621307373
Time needed for the batch 3.063652515411377
Time needed for logging 0.05220961570739746
Training epoch 0 | batch 2
Batch on Device 0 computed in 0.7263932228088379 seconds.
tensor([8.8898], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33623838424682617
Time for loss calculation for target: 0.0843954086303711
Time for Loss backward: 1.872126579284668
Time needed for the batch 3.0297000408172607
Time needed for logging 0.008268117904663086
Training epoch 0 | batch 3
Batch on Device 0 computed in 0.7285373210906982 seconds.
tensor([8.2989], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.32997775077819824
Time for loss calculation for target: 0.08366608619689941
Time for Loss backward: 1.8778374195098877
Time needed for the batch 3.0295536518096924
Time needed for logging 0.008828401565551758
Training epoch 0 | batch 4
Batch on Device 0 computed in 0.726588249206543 seconds.
tensor([8.5417], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.331066370010376
Time for loss calculation for target: 0.0821070671081543
Time for Loss backward: 1.8881707191467285
Time needed for the batch 3.0377655029296875
Time needed for logging 0.009121417999267578
Training epoch 0 | batch 5
Batch on Device 0 computed in 0.7233765125274658 seconds.
tensor([6.3363], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.333601713180542
Time for loss calculation for target: 0.08245086669921875
Time for Loss backward: 1.9530515670776367
Time needed for the batch 3.1019532680511475
Time needed for logging 0.008744001388549805
Training epoch 0 | batch 6
Batch on Device 0 computed in 0.7278509140014648 seconds.
tensor([7.9545], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3301432132720947
Time for loss calculation for target: 0.08391380310058594
Time for Loss backward: 1.8967485427856445
Time needed for the batch 3.048187255859375
Time needed for logging 0.008800506591796875
Training epoch 0 | batch 7
Batch on Device 0 computed in 0.7292144298553467 seconds.
tensor([9.6316], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33188724517822266
Time for loss calculation for target: 0.08312773704528809
Time for Loss backward: 1.8667993545532227
Time needed for the batch 3.020620584487915
Time needed for logging 0.008865118026733398
Training epoch 0 | batch 8
Batch on Device 0 computed in 0.7234759330749512 seconds.
tensor([7.8928], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33378124237060547
Time for loss calculation for target: 0.08243775367736816
Time for Loss backward: 1.8868522644042969
Time needed for the batch 3.035757541656494
Time needed for logging 0.00878000259399414
Training epoch 0 | batch 9
Batch on Device 0 computed in 0.7236387729644775 seconds.
tensor([7.5066], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3325538635253906
Time for loss calculation for target: 0.08144545555114746
Time for Loss backward: 1.8604393005371094
Time needed for the batch 3.0078189373016357
Time needed for logging 0.009089469909667969
Total time for 10 batches 63.50154256820679
Training epoch 0 | batch 10
Batch on Device 0 computed in 0.7352218627929688 seconds.
tensor([8.7947], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33175158500671387
Time for loss calculation for target: 0.08105063438415527
Time for Loss backward: 1.8969783782958984
Time needed for the batch 3.0547080039978027
Time needed for logging 0.009400606155395508
Training epoch 0 | batch 11
Batch on Device 0 computed in 0.7374870777130127 seconds.
tensor([8.0085], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3353092670440674
Time for loss calculation for target: 0.08253765106201172
Time for Loss backward: 1.897599220275879
Time needed for the batch 3.062152862548828
Time needed for logging 0.008573055267333984
Training epoch 0 | batch 12
Batch on Device 0 computed in 0.7271065711975098 seconds.
tensor([6.6457], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3391714096069336
Time for loss calculation for target: 0.08329582214355469
Time for Loss backward: 1.865628957748413
Time needed for the batch 3.024998903274536
Time needed for logging 0.008246183395385742
Training epoch 0 | batch 13
Batch on Device 0 computed in 0.7310726642608643 seconds.
tensor([6.4549], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3339381217956543
Time for loss calculation for target: 0.09224367141723633
Time for Loss backward: 1.9052534103393555
Time needed for the batch 3.0771987438201904
Time needed for logging 0.009460926055908203
Training epoch 0 | batch 14
Batch on Device 0 computed in 0.7416303157806396 seconds.
tensor([7.3678], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3270900249481201
Time for loss calculation for target: 0.08151006698608398
Time for Loss backward: 1.9054124355316162
Time needed for the batch 3.0661139488220215
Time needed for logging 0.009206771850585938
Training epoch 0 | batch 15
Batch on Device 0 computed in 0.7328901290893555 seconds.
tensor([6.1737], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.334414005279541
Time for loss calculation for target: 0.08232641220092773
Time for Loss backward: 1.8935494422912598
Time needed for the batch 3.0529987812042236
Time needed for logging 0.009302377700805664
Training epoch 0 | batch 16
Batch on Device 0 computed in 0.731381893157959 seconds.
tensor([6.5454], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33458900451660156
Time for loss calculation for target: 0.09712719917297363
Time for Loss backward: 1.8844988346099854
Time needed for the batch 3.057135581970215
Time needed for logging 0.009157180786132812
Training epoch 0 | batch 17
Batch on Device 0 computed in 0.7277960777282715 seconds.
tensor([6.0542], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3375377655029297
Time for loss calculation for target: 0.08395838737487793
Time for Loss backward: 1.854468584060669
Time needed for the batch 3.013354778289795
Time needed for logging 0.00952768325805664
Training epoch 0 | batch 18
Batch on Device 0 computed in 0.7366549968719482 seconds.
tensor([6.2811], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3296201229095459
Time for loss calculation for target: 0.08153295516967773
Time for Loss backward: 1.900947093963623
Time needed for the batch 3.0584969520568848
Time needed for logging 0.009618520736694336
Training epoch 0 | batch 19
Batch on Device 0 computed in 0.7916228771209717 seconds.
tensor([5.0021], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3326432704925537
Time for loss calculation for target: 0.08162832260131836
Time for Loss backward: 1.9009487628936768
Time needed for the batch 3.1167681217193604
Time needed for logging 0.009644508361816406
Training epoch 0 | batch 20
Batch on Device 0 computed in 0.7321264743804932 seconds.
tensor([4.1835], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3322155475616455
Time for loss calculation for target: 0.08293294906616211
Time for Loss backward: 1.8972349166870117
Time needed for the batch 3.0587542057037354
Time needed for logging 0.009149551391601562
Training epoch 0 | batch 21
Batch on Device 0 computed in 0.7287988662719727 seconds.
tensor([6.2172], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33684802055358887
Time for loss calculation for target: 0.08501482009887695
Time for Loss backward: 1.860884666442871
Time needed for the batch 3.02107834815979
Time needed for logging 0.009574651718139648
Training epoch 0 | batch 22
Batch on Device 0 computed in 0.7251646518707275 seconds.
tensor([5.1960], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3405284881591797
Time for loss calculation for target: 0.08183836936950684
Time for Loss backward: 1.8692021369934082
Time needed for the batch 3.0267493724823
Time needed for logging 0.007806539535522461
Training epoch 0 | batch 23
Batch on Device 0 computed in 0.7238004207611084 seconds.
tensor([3.0951], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3412148952484131
Time for loss calculation for target: 0.08165979385375977
Time for Loss backward: 1.8736443519592285
Time needed for the batch 3.030193328857422
Time needed for logging 0.009868860244750977
Training epoch 0 | batch 24
Batch on Device 0 computed in 0.7320461273193359 seconds.
tensor([3.9966], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33414149284362793
Time for loss calculation for target: 0.08216094970703125
Time for Loss backward: 1.891467571258545
Time needed for the batch 3.050048828125
Time needed for logging 0.00948953628540039
Training epoch 0 | batch 25
Batch on Device 0 computed in 0.7298505306243896 seconds.
tensor([3.1802], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33701276779174805
Time for loss calculation for target: 0.08440876007080078
Time for Loss backward: 1.8916141986846924
Time needed for the batch 3.0524744987487793
Time needed for logging 0.009269237518310547
Training epoch 0 | batch 26
Batch on Device 0 computed in 0.732593297958374 seconds.
tensor([4.2501], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33274030685424805
Time for loss calculation for target: 0.08223533630371094
Time for Loss backward: 1.8735837936401367
Time needed for the batch 3.031106948852539
Time needed for logging 0.009248495101928711
Training epoch 0 | batch 27
Batch on Device 0 computed in 0.7281076908111572 seconds.
tensor([4.2511], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3407723903656006
Time for loss calculation for target: 0.08308529853820801
Time for Loss backward: 1.908959150314331
Time needed for the batch 3.0704681873321533
Time needed for logging 0.009379148483276367
Training epoch 0 | batch 28
Batch on Device 0 computed in 0.7310836315155029 seconds.
tensor([2.3707], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3428933620452881
Time for loss calculation for target: 0.08199596405029297
Time for Loss backward: 1.9602515697479248
Time needed for the batch 3.125885486602783
Time needed for logging 0.009224176406860352
Training epoch 0 | batch 29
Batch on Device 0 computed in 0.7326052188873291 seconds.
tensor([3.9897], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34090757369995117
Time for loss calculation for target: 0.08419108390808105
Time for Loss backward: 1.8783273696899414
Time needed for the batch 3.0458269119262695
Time needed for logging 0.009004592895507812
Training epoch 0 | batch 30
Batch on Device 0 computed in 0.736126184463501 seconds.
tensor([2.5606], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3367187976837158
Time for loss calculation for target: 0.08117103576660156
Time for Loss backward: 1.8848788738250732
Time needed for the batch 3.0495543479919434
Time needed for logging 0.009596109390258789
Training epoch 0 | batch 31
Batch on Device 0 computed in 0.7337443828582764 seconds.
tensor([2.2154], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3420426845550537
Time for loss calculation for target: 0.08217549324035645
Time for Loss backward: 1.9047801494598389
Time needed for the batch 3.072126626968384
Time needed for logging 0.008980035781860352
Training epoch 0 | batch 32
Batch on Device 0 computed in 0.7316465377807617 seconds.
tensor([1.7949], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34172916412353516
Time for loss calculation for target: 0.1570425033569336
Time for Loss backward: 1.9010324478149414
Time needed for the batch 3.1412482261657715
Time needed for logging 0.009088993072509766
Training epoch 0 | batch 33
Batch on Device 0 computed in 0.735929012298584 seconds.
tensor([2.1545], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33710598945617676
Time for loss calculation for target: 0.08200311660766602
Time for Loss backward: 1.8952031135559082
Time needed for the batch 3.0608839988708496
Time needed for logging 0.008998870849609375
Training epoch 0 | batch 34
Batch on Device 0 computed in 0.7310729026794434 seconds.
tensor([1.1074], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34299278259277344
Time for loss calculation for target: 0.08248424530029297
Time for Loss backward: 1.903419017791748
Time needed for the batch 3.0697576999664307
Time needed for logging 0.008877038955688477
Training epoch 0 | batch 35
Batch on Device 0 computed in 0.7381610870361328 seconds.
tensor([1.4442], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3373408317565918
Time for loss calculation for target: 0.082305908203125
Time for Loss backward: 1.8914172649383545
Time needed for the batch 3.058955430984497
Time needed for logging 0.009012699127197266
Training epoch 0 | batch 36
Batch on Device 0 computed in 0.7406294345855713 seconds.
tensor([1.4078], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3321809768676758
Time for loss calculation for target: 0.08395862579345703
Time for Loss backward: 1.9234528541564941
Time needed for the batch 3.090588092803955
Time needed for logging 0.009928464889526367
Training epoch 0 | batch 37
Batch on Device 0 computed in 0.7364096641540527 seconds.
tensor([1.2203], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.339780330657959
Time for loss calculation for target: 0.08254003524780273
Time for Loss backward: 1.905200481414795
Time needed for the batch 3.076638698577881
Time needed for logging 0.009343624114990234
Training epoch 0 | batch 38
Batch on Device 0 computed in 0.7372555732727051 seconds.
tensor([1.0542], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.343674898147583
Time for loss calculation for target: 0.08090043067932129
Time for Loss backward: 1.8896887302398682
Time needed for the batch 3.0612902641296387
Time needed for logging 0.009828805923461914
Training epoch 0 | batch 39
Batch on Device 0 computed in 0.7416703701019287 seconds.
tensor([1.1434], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33753228187561035
Time for loss calculation for target: 0.08214306831359863
Time for Loss backward: 1.888115644454956
Time needed for the batch 3.059788227081299
Time needed for logging 0.00904226303100586
Training epoch 0 | batch 40
Batch on Device 0 computed in 0.7384979724884033 seconds.
tensor([1.1282], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33425331115722656
Time for loss calculation for target: 0.08302450180053711
Time for Loss backward: 1.8870062828063965
Time needed for the batch 3.052257776260376
Time needed for logging 0.008814096450805664
Training epoch 0 | batch 41
Batch on Device 0 computed in 0.7308356761932373 seconds.
tensor([1.2244], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3427164554595947
Time for loss calculation for target: 0.08275985717773438
Time for Loss backward: 1.867591381072998
Time needed for the batch 3.0342941284179688
Time needed for logging 0.009085655212402344
Training epoch 0 | batch 42
Batch on Device 0 computed in 0.7398638725280762 seconds.
tensor([1.7938], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33338260650634766
Time for loss calculation for target: 0.08229708671569824
Time for Loss backward: 1.8942513465881348
Time needed for the batch 3.0604045391082764
Time needed for logging 0.00876927375793457
Training epoch 0 | batch 43
Batch on Device 0 computed in 0.7349052429199219 seconds.
tensor([0.6591], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3383967876434326
Time for loss calculation for target: 0.0821692943572998
Time for Loss backward: 1.9118154048919678
Time needed for the batch 3.077841281890869
Time needed for logging 0.009000778198242188
Training epoch 0 | batch 44
Batch on Device 0 computed in 0.7373497486114502 seconds.
tensor([0.6320], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.338977575302124
Time for loss calculation for target: 0.08489751815795898
Time for Loss backward: 1.9121723175048828
Time needed for the batch 3.0832271575927734
Time needed for logging 0.00952768325805664
Training epoch 0 | batch 45
Batch on Device 0 computed in 0.7370741367340088 seconds.
tensor([0.5732], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3376138210296631
Time for loss calculation for target: 0.08362722396850586
Time for Loss backward: 1.8980631828308105
Time needed for the batch 3.068969964981079
Time needed for logging 0.009180307388305664
Training epoch 0 | batch 46
Batch on Device 0 computed in 0.792564868927002 seconds.
tensor([0.5400], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3384842872619629
Time for loss calculation for target: 0.08239388465881348
Time for Loss backward: 1.9071226119995117
Time needed for the batch 3.1299328804016113
Time needed for logging 0.008832454681396484
Training epoch 0 | batch 47
Batch on Device 0 computed in 0.7354319095611572 seconds.
tensor([0.4355], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3384842872619629
Time for loss calculation for target: 0.08479094505310059
Time for Loss backward: 1.9687755107879639
Time needed for the batch 3.137049674987793
Time needed for logging 0.009821653366088867
Training epoch 0 | batch 48
Batch on Device 0 computed in 0.7470450401306152 seconds.
tensor([0.6044], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33953142166137695
Time for loss calculation for target: 0.08463692665100098
Time for Loss backward: 1.899022102355957
Time needed for the batch 3.080310583114624
Time needed for logging 0.009106159210205078
Training epoch 0 | batch 49
Batch on Device 0 computed in 0.731856107711792 seconds.
tensor([0.6628], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3410677909851074
Time for loss calculation for target: 0.08272409439086914
Time for Loss backward: 1.882051944732666
Time needed for the batch 3.046750068664551
Time needed for logging 0.009122371673583984
Training epoch 0 | batch 50
Batch on Device 0 computed in 0.7450478076934814 seconds.
tensor([0.3373], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3310830593109131
Time for loss calculation for target: 0.08253812789916992
Time for Loss backward: 1.907933235168457
Time needed for the batch 3.0762245655059814
Time needed for logging 0.009346961975097656
Training epoch 0 | batch 51
Batch on Device 0 computed in 0.7465693950653076 seconds.
tensor([0.8825], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.32843971252441406
Time for loss calculation for target: 0.08181118965148926
Time for Loss backward: 1.9043431282043457
Time needed for the batch 3.0704846382141113
Time needed for logging 0.00988459587097168
Training epoch 0 | batch 52
Batch on Device 0 computed in 0.7412805557250977 seconds.
tensor([0.8261], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.33393359184265137
Time for loss calculation for target: 0.08418393135070801
Time for Loss backward: 1.9008474349975586
Time needed for the batch 3.0705385208129883
Time needed for logging 0.009566783905029297
Training epoch 0 | batch 53
Batch on Device 0 computed in 0.7309253215789795 seconds.
tensor([0.4941], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34181880950927734
Time for loss calculation for target: 0.08148813247680664
Time for Loss backward: 1.8685784339904785
Time needed for the batch 3.0329811573028564
Time needed for logging 0.009071826934814453
Training epoch 0 | batch 54
Batch on Device 0 computed in 0.7397541999816895 seconds.
tensor([0.5379], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3383004665374756
Time for loss calculation for target: 0.08143901824951172
Time for Loss backward: 1.872394323348999
Time needed for the batch 3.0419821739196777
Time needed for logging 0.010170698165893555
Training epoch 0 | batch 55
Batch on Device 0 computed in 0.7359902858734131 seconds.
tensor([0.3292], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3367466926574707
Time for loss calculation for target: 0.08196473121643066
Time for Loss backward: 1.9145610332489014
Time needed for the batch 3.082138776779175
Time needed for logging 0.007174253463745117
Training epoch 0 | batch 56
Batch on Device 0 computed in 0.7299225330352783 seconds.
tensor([0.8637], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.34474778175354004
Time for loss calculation for target: 0.08386087417602539
Time for Loss backward: 1.8677453994750977
Time needed for the batch 3.0365397930145264
Time needed for logging 0.009931802749633789
Training epoch 0 | batch 57
Batch on Device 0 computed in 0.7308309078216553 seconds.
tensor([1.0589], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3455376625061035
Time for loss calculation for target: 0.08235955238342285
Time for Loss backward: 1.8976049423217773
Time needed for the batch 3.0671677589416504
Time needed for logging 0.009206533432006836
Training epoch 0 | batch 58
Batch on Device 0 computed in 0.7326743602752686 seconds.
tensor([0.7419], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time for loss calculation for source: 0.3432931900024414
Time for loss calculation for target: 0.08278465270996094
Time for Loss backward: 1.8798027038574219
Time needed for the batch 3.0504846572875977
Time needed for logging 0.00899958610534668
Training epoch 0 | batch 59
Batch on Device 0 computed in 0.7368457317352295 seconds.
