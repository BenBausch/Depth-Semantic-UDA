Length Target Train Loader: 44625
Length Target Validation Loader: 250
Length Source Train Loader: 44625
No checkpoint is used. Training from scratch!
[{'silog_depth': {'weight': 0.85}, 'bce': {'r': 0.3, 'ignore_index': 250}, 'snr': 'None'}]
[{'silog_depth': 1, 'bce': 0.001, 'snr': 0.01}]
Training supervised on source dataset using dense depth!
Training supervised on source dataset using semantic annotations!
Source ground truth scale is used for computing depth errors while training.
Source ground truth scale is used for computing depth errors while validating.
Training unsupervised on target dataset using self supervised depth!
Training started...
Training epoch 0 | batch 0
Batch on Device 0 computed in 3.324216604232788 seconds.
tensor([10.3966], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 8.467973709106445
Time for Loss backward: 4.87234354019165
Training epoch 0 | batch 1
Batch on Device 0 computed in 0.715217113494873 seconds.
tensor([11.1754], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.694545269012451
Time for Loss backward: 1.5860626697540283
Training epoch 0 | batch 2
Batch on Device 0 computed in 0.7153334617614746 seconds.
tensor([8.3659], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.6723825931549072
Time for Loss backward: 1.5890421867370605
Training epoch 0 | batch 3
Batch on Device 0 computed in 0.7152905464172363 seconds.
tensor([9.0052], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.6692912578582764
Time for Loss backward: 1.58837890625
Training epoch 0 | batch 4
Batch on Device 0 computed in 0.7152025699615479 seconds.
tensor([8.0499], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.6673083305358887
Time for Loss backward: 1.5885839462280273
Training epoch 0 | batch 5
Batch on Device 0 computed in 0.7151901721954346 seconds.
tensor([7.5481], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.6738297939300537
Time for Loss backward: 1.5953834056854248
Training epoch 0 | batch 6
Batch on Device 0 computed in 0.715242862701416 seconds.
tensor([10.9939], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.673112392425537
Time for Loss backward: 1.5941135883331299
Training epoch 0 | batch 7
Batch on Device 0 computed in 0.715341329574585 seconds.
tensor([7.9209], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.67085862159729
Time for Loss backward: 1.589991807937622
Training epoch 0 | batch 8
Batch on Device 0 computed in 0.7151548862457275 seconds.
tensor([10.3671], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.6670734882354736
Time for Loss backward: 1.588379144668579
Training epoch 0 | batch 9
Batch on Device 0 computed in 0.7168338298797607 seconds.
tensor([9.0632], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
Time needed for the batch 2.6676723957061768
Time for Loss backward: 1.5873007774353027
Total time for 10 batches 59.42949652671814
Validation
/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/home/bauschb/miniconda3/envs/Masterthesis/lib/python3.8/site-packages/torch/nn/functional.py:4003: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
WARNING:root:device cuda:0
WARNING:root:device cuda:0
WARNING:root:device cuda:0
WARNING:root:device cuda:0
